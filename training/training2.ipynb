{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load data in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/pasquale/git/recommender/\"\n",
    "training_data_folder = [\n",
    "    '%straining_data/web-radio/output/list' % root,\n",
    "    '%straining_data/spotify/output/playlists/list' % root,\n",
    "    '%straining_data/concerts/output/list/Philharmonie_de_Paris' % root,\n",
    "    '%straining_data/concerts/output/list/Radio_France' % root\n",
    "    ]\n",
    "embDir = '/Users/pasquale/git/music-embeddings'\n",
    "what = 'artist'\n",
    "\n",
    "uri_file = '%s/%s.emb.u' % (embDir, what)\n",
    "vector_file = '%s/%s.emb.v' % (embDir, what)\n",
    "header_file = '%s/%s.emb.h' % (embDir, what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "vectors = np.array([line.strip().split(' ') for line in codecs.open(vector_file, 'r', 'utf-8')])\n",
    "heads = np.array([line.strip() for line in codecs.open(header_file, 'r', 'utf-8')])\n",
    "uris = np.array([line.strip() for line in codecs.open(uri_file, 'r', 'utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mop -> 80\n",
      "birth_date -> 1\n",
      "death_date -> 1\n",
      "casting -> 80\n",
      "genre -> 80\n",
      "key -> 100\n"
     ]
    }
   ],
   "source": [
    "head_label = heads[0].split()\n",
    "head_val = heads[1].split()\n",
    "head_dim = []\n",
    "for i in range(0, len(head_val)):\n",
    "    print(head_label[i] + ' -> ' + head_val[i])\n",
    "    for j in range(0, int(head_val[i])):\n",
    "        head_dim.append(head_label[i])\n",
    "        \n",
    "# head_dim.append('fake')\n",
    "# head_dim.append('fake')\n",
    "# head_dim.append('fake')\n",
    "# head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training\n",
    "train_array = []\n",
    "for folder in training_data_folder:\n",
    "    training_folder = '%s/%s' % (folder, what)\n",
    "    for f in os.listdir(training_folder):\n",
    "        file= '%s/%s' % (training_folder, f)\n",
    "        train_array.append(np.array([line.strip() for line in codecs.open(file, 'r', 'utf-8')]))\n",
    "\n",
    "len(train_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs(x):\n",
    "    # uri to embedding\n",
    "    v = vectors[np.argwhere(uris == x)]\n",
    "    if v.size == 0:\n",
    "        result = -2. * np.ones_like(vectors[0], dtype=np.float32)\n",
    "    else:\n",
    "        result = np.array(v[0][0])\n",
    "    return result.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatches_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_vector_all = []\n",
    "for t in train_array:\n",
    "    if(len(t) < minibatches_len):\n",
    "        continue\n",
    "    training_vector_all.append(np.array([get_embs(xi) for xi in t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I divide the playlists in minibatches of 2X songs (X seeds and X targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4254, 8, 342)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vector = []\n",
    "\n",
    "for t in training_vector_all:\n",
    "    for x in range(1, len(t) - minibatches_len):\n",
    "        training_vector.append(t[0:minibatches_len])\n",
    "        \n",
    "training_vector = np.array(training_vector)\n",
    "training_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label[399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_mean(a):\n",
    "    b = np.where(a < -1., 0., a)\n",
    "    s = np.sum(b, axis=1)\n",
    "    c = np.count_nonzero(b, axis=1)\n",
    "    d = np.divide(s, c)\n",
    "    return np.where(np.isnan(d), 0, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pasquale/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/pasquale/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(training_vector, train_size=0.7)\n",
    "\n",
    "train_seed, train_target = np.split(train, 2, axis=1)\n",
    "train_vector = smart_mean(train_seed)\n",
    "train_label = smart_mean(train_target)\n",
    "\n",
    "test_seed, test_target = np.split(test, 2, axis=1)\n",
    "test_vector = smart_mean(test_seed)\n",
    "test_label = smart_mean(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(2977, 342)\n",
      "(2977, 342)\n",
      "Test\n",
      "(1277, 342)\n",
      "(1277, 342)\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "print(train_vector.shape)\n",
    "print(train_label.shape)\n",
    "print('Test')\n",
    "print(test_vector.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256  # 1st layer number of neurons\n",
    "n_hidden_2 = 256  # 2nd layer number of neurons\n",
    "num_input = train_vector[0].size\n",
    "num_output = train_label[0].size\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input], name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [None, num_output], name=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    with tf.name_scope('hidden_1') as scope:\n",
    "        # Hidden fully connected layer with 256 neurons\n",
    "        w1 = tf.Variable(tf.random_normal([num_input, n_hidden_1]), name='w')\n",
    "        b1 = tf.Variable(tf.random_normal([n_hidden_1]), name='b')\n",
    "        layer_1 = tf.add(tf.matmul(x, w1), b1, name='o')\n",
    "    with tf.name_scope('hidden_2') as scope:\n",
    "        # Hidden fully connected layer with 256 neurons\n",
    "        w2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='w')\n",
    "        b2 = tf.Variable(tf.random_normal([n_hidden_2]), name='b')\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, w2), b2, name='o')\n",
    "    with tf.name_scope('out_layer') as scope:\n",
    "        # Output fully connected layer with a neuron for each class\n",
    "        wo = tf.Variable(tf.random_normal([n_hidden_2, num_output]), name='w')\n",
    "        bo = tf.Variable(tf.random_normal([num_output]), name='b')\n",
    "        out_layer = tf.add(tf.matmul(layer_2, wo), bo, name=\"o\")\n",
    "    return out_layer\n",
    "#         return tf.nn.softmax(out_layer, name = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_l2(a, b, w):\n",
    "    with tf.name_scope('weighted_l2') as scope:\n",
    "        # https://stackoverflow.com/a/8861999/1218213\n",
    "        q = tf.subtract(a, b, name=\"q\")\n",
    "        # return np.sqrt((w * q * q).sum())\n",
    "        pow_q = tf.cast(tf.pow(q, 2), tf.float32, name=\"q-power\")\n",
    "\n",
    "        return tf.reduce_sum(tf.multiply(w, pow_q), axis=1, name=\"o\", keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_penalty(expected, taken, total):\n",
    "    with tf.name_scope('penalty') as scope:\n",
    "        penalty = tf.divide(tf.subtract(expected, taken), total)\n",
    "        return tf.cast(penalty, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(342)])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "# loss_op = MSE\n",
    "loss_op = tf.reduce_mean(tf.square(tf.subtract(logits, Y)), name='loss_op')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='optimizer')\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "error_summary = tf.summary.scalar('error', loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(logits, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "merged = tf.summary.merge([error_summary, accuracy_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    \"\"\"\n",
    "    Return a total of `num` random samples and labels. \n",
    "    \"\"\"\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = data[idx]\n",
    "    labels_shuffle = labels[idx]\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning\n",
      "Step 1, Minibatch Loss= 586542.2500, Training Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 636334.6250, Training Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 328609.6875, Training Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 109718.1953, Training Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 145589.8906, Training Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 92217.3750, Training Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 82512.9844, Training Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 78164.0781, Training Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 75039.8047, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 53330.7031, Training Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 35251.9766, Training Accuracy= 0.000\n",
      "Step 12, Minibatch Loss= 38458.5664, Training Accuracy= 0.000\n",
      "Step 13, Minibatch Loss= 51147.0977, Training Accuracy= 0.000\n",
      "Step 14, Minibatch Loss= 44290.9883, Training Accuracy= 0.000\n",
      "Step 15, Minibatch Loss= 26655.2598, Training Accuracy= 0.000\n",
      "Step 16, Minibatch Loss= 18531.7129, Training Accuracy= 0.000\n",
      "Step 17, Minibatch Loss= 34029.1680, Training Accuracy= 0.000\n",
      "Step 18, Minibatch Loss= 20753.3770, Training Accuracy= 0.000\n",
      "Step 19, Minibatch Loss= 12684.3477, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 16698.5371, Training Accuracy= 0.000\n",
      "Step 21, Minibatch Loss= 16016.7139, Training Accuracy= 0.000\n",
      "Step 22, Minibatch Loss= 10414.0918, Training Accuracy= 0.000\n",
      "Step 23, Minibatch Loss= 9505.9912, Training Accuracy= 0.000\n",
      "Step 24, Minibatch Loss= 12056.6172, Training Accuracy= 0.000\n",
      "Step 25, Minibatch Loss= 7963.0850, Training Accuracy= 0.000\n",
      "Step 26, Minibatch Loss= 7156.1826, Training Accuracy= 0.000\n",
      "Step 27, Minibatch Loss= 9885.8799, Training Accuracy= 0.000\n",
      "Step 28, Minibatch Loss= 5719.1587, Training Accuracy= 0.000\n",
      "Step 29, Minibatch Loss= 7477.4966, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 6767.2783, Training Accuracy= 0.000\n",
      "Step 31, Minibatch Loss= 4880.3257, Training Accuracy= 0.000\n",
      "Step 32, Minibatch Loss= 6516.3237, Training Accuracy= 0.000\n",
      "Step 33, Minibatch Loss= 5143.2637, Training Accuracy= 0.000\n",
      "Step 34, Minibatch Loss= 4357.6958, Training Accuracy= 0.000\n",
      "Step 35, Minibatch Loss= 5633.5732, Training Accuracy= 0.000\n",
      "Step 36, Minibatch Loss= 3040.6201, Training Accuracy= 0.000\n",
      "Step 37, Minibatch Loss= 4865.3276, Training Accuracy= 0.000\n",
      "Step 38, Minibatch Loss= 3267.9346, Training Accuracy= 0.000\n",
      "Step 39, Minibatch Loss= 3724.1162, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 2897.3784, Training Accuracy= 0.000\n",
      "Step 41, Minibatch Loss= 2683.3552, Training Accuracy= 0.000\n",
      "Step 42, Minibatch Loss= 3151.0891, Training Accuracy= 0.000\n",
      "Step 43, Minibatch Loss= 2712.7075, Training Accuracy= 0.000\n",
      "Step 44, Minibatch Loss= 2658.9712, Training Accuracy= 0.000\n",
      "Step 45, Minibatch Loss= 2665.0471, Training Accuracy= 0.000\n",
      "Step 46, Minibatch Loss= 2174.4470, Training Accuracy= 0.000\n",
      "Step 47, Minibatch Loss= 2757.3508, Training Accuracy= 0.000\n",
      "Step 48, Minibatch Loss= 1885.8378, Training Accuracy= 0.000\n",
      "Step 49, Minibatch Loss= 2290.2131, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1623.5939, Training Accuracy= 0.000\n",
      "Step 51, Minibatch Loss= 1933.0957, Training Accuracy= 0.000\n",
      "Step 52, Minibatch Loss= 1831.4021, Training Accuracy= 0.000\n",
      "Step 53, Minibatch Loss= 1404.3186, Training Accuracy= 0.000\n",
      "Step 54, Minibatch Loss= 1789.9613, Training Accuracy= 0.000\n",
      "Step 55, Minibatch Loss= 1475.3547, Training Accuracy= 0.000\n",
      "Step 56, Minibatch Loss= 1788.2375, Training Accuracy= 0.000\n",
      "Step 57, Minibatch Loss= 1585.0713, Training Accuracy= 0.000\n",
      "Step 58, Minibatch Loss= 1703.0081, Training Accuracy= 0.000\n",
      "Step 59, Minibatch Loss= 1224.8156, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1366.3284, Training Accuracy= 0.000\n",
      "Step 61, Minibatch Loss= 1270.3008, Training Accuracy= 0.000\n",
      "Step 62, Minibatch Loss= 1585.7018, Training Accuracy= 0.000\n",
      "Step 63, Minibatch Loss= 1201.9606, Training Accuracy= 0.000\n",
      "Step 64, Minibatch Loss= 1127.8600, Training Accuracy= 0.000\n",
      "Step 65, Minibatch Loss= 1331.3916, Training Accuracy= 0.000\n",
      "Step 66, Minibatch Loss= 1157.7461, Training Accuracy= 0.000\n",
      "Step 67, Minibatch Loss= 1187.8799, Training Accuracy= 0.000\n",
      "Step 68, Minibatch Loss= 1124.3765, Training Accuracy= 0.000\n",
      "Step 69, Minibatch Loss= 1110.0881, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1269.8993, Training Accuracy= 0.000\n",
      "Step 71, Minibatch Loss= 884.3459, Training Accuracy= 0.000\n",
      "Step 72, Minibatch Loss= 1136.5179, Training Accuracy= 0.000\n",
      "Step 73, Minibatch Loss= 957.2697, Training Accuracy= 0.000\n",
      "Step 74, Minibatch Loss= 1042.8834, Training Accuracy= 0.000\n",
      "Step 75, Minibatch Loss= 928.3287, Training Accuracy= 0.000\n",
      "Step 76, Minibatch Loss= 906.1882, Training Accuracy= 0.000\n",
      "Step 77, Minibatch Loss= 1073.7318, Training Accuracy= 0.000\n",
      "Step 78, Minibatch Loss= 1018.4594, Training Accuracy= 0.000\n",
      "Step 79, Minibatch Loss= 1000.0809, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 911.0684, Training Accuracy= 0.000\n",
      "Step 81, Minibatch Loss= 856.6696, Training Accuracy= 0.000\n",
      "Step 82, Minibatch Loss= 986.8807, Training Accuracy= 0.000\n",
      "Step 83, Minibatch Loss= 867.8323, Training Accuracy= 0.000\n",
      "Step 84, Minibatch Loss= 1030.4412, Training Accuracy= 0.000\n",
      "Step 85, Minibatch Loss= 763.1722, Training Accuracy= 0.000\n",
      "Step 86, Minibatch Loss= 765.3809, Training Accuracy= 0.000\n",
      "Step 87, Minibatch Loss= 829.1961, Training Accuracy= 0.000\n",
      "Step 88, Minibatch Loss= 755.6583, Training Accuracy= 0.000\n",
      "Step 89, Minibatch Loss= 791.2664, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 778.3825, Training Accuracy= 0.000\n",
      "Step 91, Minibatch Loss= 747.6259, Training Accuracy= 0.000\n",
      "Step 92, Minibatch Loss= 704.7686, Training Accuracy= 0.000\n",
      "Step 93, Minibatch Loss= 698.3893, Training Accuracy= 0.000\n",
      "Step 94, Minibatch Loss= 735.2518, Training Accuracy= 0.000\n",
      "Step 95, Minibatch Loss= 957.9543, Training Accuracy= 0.000\n",
      "Step 96, Minibatch Loss= 623.0912, Training Accuracy= 0.000\n",
      "Step 97, Minibatch Loss= 677.4453, Training Accuracy= 0.000\n",
      "Step 98, Minibatch Loss= 792.3755, Training Accuracy= 0.000\n",
      "Step 99, Minibatch Loss= 701.7457, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 745.1062, Training Accuracy= 0.000\n",
      "Step 101, Minibatch Loss= 712.7715, Training Accuracy= 0.000\n",
      "Step 102, Minibatch Loss= 678.1020, Training Accuracy= 0.000\n",
      "Step 103, Minibatch Loss= 593.4600, Training Accuracy= 0.000\n",
      "Step 104, Minibatch Loss= 815.0195, Training Accuracy= 0.000\n",
      "Step 105, Minibatch Loss= 675.9004, Training Accuracy= 0.000\n",
      "Step 106, Minibatch Loss= 650.9835, Training Accuracy= 0.000\n",
      "Step 107, Minibatch Loss= 597.7296, Training Accuracy= 0.000\n",
      "Step 108, Minibatch Loss= 691.2318, Training Accuracy= 0.000\n",
      "Step 109, Minibatch Loss= 599.0532, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 603.7101, Training Accuracy= 0.000\n",
      "Step 111, Minibatch Loss= 649.2451, Training Accuracy= 0.000\n",
      "Step 112, Minibatch Loss= 624.7664, Training Accuracy= 0.000\n",
      "Step 113, Minibatch Loss= 635.5220, Training Accuracy= 0.000\n",
      "Step 114, Minibatch Loss= 575.6176, Training Accuracy= 0.000\n",
      "Step 115, Minibatch Loss= 599.2020, Training Accuracy= 0.000\n",
      "Step 116, Minibatch Loss= 596.7827, Training Accuracy= 0.000\n",
      "Step 117, Minibatch Loss= 661.4020, Training Accuracy= 0.000\n",
      "Step 118, Minibatch Loss= 619.1298, Training Accuracy= 0.000\n",
      "Step 119, Minibatch Loss= 574.0035, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 603.5069, Training Accuracy= 0.000\n",
      "Step 121, Minibatch Loss= 567.7419, Training Accuracy= 0.000\n",
      "Step 122, Minibatch Loss= 545.0543, Training Accuracy= 0.000\n",
      "Step 123, Minibatch Loss= 577.4715, Training Accuracy= 0.000\n",
      "Step 124, Minibatch Loss= 631.5718, Training Accuracy= 0.000\n",
      "Step 125, Minibatch Loss= 597.6432, Training Accuracy= 0.000\n",
      "Step 126, Minibatch Loss= 496.7482, Training Accuracy= 0.000\n",
      "Step 127, Minibatch Loss= 425.8389, Training Accuracy= 0.000\n",
      "Step 128, Minibatch Loss= 508.6803, Training Accuracy= 0.000\n",
      "Step 129, Minibatch Loss= 521.6728, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 547.1140, Training Accuracy= 0.000\n",
      "Step 131, Minibatch Loss= 442.5710, Training Accuracy= 0.000\n",
      "Step 132, Minibatch Loss= 556.3203, Training Accuracy= 0.000\n",
      "Step 133, Minibatch Loss= 504.7728, Training Accuracy= 0.000\n",
      "Step 134, Minibatch Loss= 521.5452, Training Accuracy= 0.000\n",
      "Step 135, Minibatch Loss= 547.0052, Training Accuracy= 0.000\n",
      "Step 136, Minibatch Loss= 554.7188, Training Accuracy= 0.000\n",
      "Step 137, Minibatch Loss= 450.6115, Training Accuracy= 0.000\n",
      "Step 138, Minibatch Loss= 439.2277, Training Accuracy= 0.000\n",
      "Step 139, Minibatch Loss= 445.5713, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 462.8944, Training Accuracy= 0.000\n",
      "Step 141, Minibatch Loss= 497.2546, Training Accuracy= 0.000\n",
      "Step 142, Minibatch Loss= 442.6024, Training Accuracy= 0.000\n",
      "Step 143, Minibatch Loss= 606.7828, Training Accuracy= 0.000\n",
      "Step 144, Minibatch Loss= 490.3022, Training Accuracy= 0.000\n",
      "Step 145, Minibatch Loss= 461.9965, Training Accuracy= 0.000\n",
      "Step 146, Minibatch Loss= 452.0703, Training Accuracy= 0.000\n",
      "Step 147, Minibatch Loss= 454.7334, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 148, Minibatch Loss= 423.4542, Training Accuracy= 0.000\n",
      "Step 149, Minibatch Loss= 399.6558, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 421.3452, Training Accuracy= 0.000\n",
      "Step 151, Minibatch Loss= 491.2576, Training Accuracy= 0.000\n",
      "Step 152, Minibatch Loss= 399.0494, Training Accuracy= 0.000\n",
      "Step 153, Minibatch Loss= 454.1473, Training Accuracy= 0.000\n",
      "Step 154, Minibatch Loss= 454.3094, Training Accuracy= 0.000\n",
      "Step 155, Minibatch Loss= 377.3164, Training Accuracy= 0.000\n",
      "Step 156, Minibatch Loss= 567.5637, Training Accuracy= 0.000\n",
      "Step 157, Minibatch Loss= 429.3218, Training Accuracy= 0.000\n",
      "Step 158, Minibatch Loss= 406.5860, Training Accuracy= 0.000\n",
      "Step 159, Minibatch Loss= 445.5957, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 544.9349, Training Accuracy= 0.000\n",
      "Step 161, Minibatch Loss= 435.1767, Training Accuracy= 0.000\n",
      "Step 162, Minibatch Loss= 431.1855, Training Accuracy= 0.000\n",
      "Step 163, Minibatch Loss= 380.3553, Training Accuracy= 0.000\n",
      "Step 164, Minibatch Loss= 494.7717, Training Accuracy= 0.000\n",
      "Step 165, Minibatch Loss= 451.8825, Training Accuracy= 0.000\n",
      "Step 166, Minibatch Loss= 440.9094, Training Accuracy= 0.000\n",
      "Step 167, Minibatch Loss= 456.1630, Training Accuracy= 0.000\n",
      "Step 168, Minibatch Loss= 460.5420, Training Accuracy= 0.000\n",
      "Step 169, Minibatch Loss= 423.6161, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 342.9496, Training Accuracy= 0.000\n",
      "Step 171, Minibatch Loss= 335.3883, Training Accuracy= 0.000\n",
      "Step 172, Minibatch Loss= 398.1576, Training Accuracy= 0.000\n",
      "Step 173, Minibatch Loss= 329.8760, Training Accuracy= 0.000\n",
      "Step 174, Minibatch Loss= 450.4482, Training Accuracy= 0.000\n",
      "Step 175, Minibatch Loss= 401.9907, Training Accuracy= 0.000\n",
      "Step 176, Minibatch Loss= 360.2919, Training Accuracy= 0.000\n",
      "Step 177, Minibatch Loss= 370.5025, Training Accuracy= 0.000\n",
      "Step 178, Minibatch Loss= 349.4794, Training Accuracy= 0.000\n",
      "Step 179, Minibatch Loss= 353.5465, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 446.2716, Training Accuracy= 0.000\n",
      "Step 181, Minibatch Loss= 350.4230, Training Accuracy= 0.000\n",
      "Step 182, Minibatch Loss= 328.9978, Training Accuracy= 0.000\n",
      "Step 183, Minibatch Loss= 351.5479, Training Accuracy= 0.000\n",
      "Step 184, Minibatch Loss= 372.0416, Training Accuracy= 0.000\n",
      "Step 185, Minibatch Loss= 465.3289, Training Accuracy= 0.000\n",
      "Step 186, Minibatch Loss= 492.9173, Training Accuracy= 0.000\n",
      "Step 187, Minibatch Loss= 425.0602, Training Accuracy= 0.000\n",
      "Step 188, Minibatch Loss= 365.1420, Training Accuracy= 0.000\n",
      "Step 189, Minibatch Loss= 336.8156, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 359.4212, Training Accuracy= 0.000\n",
      "Step 191, Minibatch Loss= 337.8262, Training Accuracy= 0.000\n",
      "Step 192, Minibatch Loss= 338.6002, Training Accuracy= 0.000\n",
      "Step 193, Minibatch Loss= 339.9368, Training Accuracy= 0.000\n",
      "Step 194, Minibatch Loss= 333.4369, Training Accuracy= 0.000\n",
      "Step 195, Minibatch Loss= 420.3658, Training Accuracy= 0.000\n",
      "Step 196, Minibatch Loss= 351.4866, Training Accuracy= 0.000\n",
      "Step 197, Minibatch Loss= 344.9608, Training Accuracy= 0.000\n",
      "Step 198, Minibatch Loss= 369.7233, Training Accuracy= 0.000\n",
      "Step 199, Minibatch Loss= 331.4928, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 327.8855, Training Accuracy= 0.000\n",
      "Step 201, Minibatch Loss= 289.2282, Training Accuracy= 0.000\n",
      "Step 202, Minibatch Loss= 273.8608, Training Accuracy= 0.000\n",
      "Step 203, Minibatch Loss= 333.8119, Training Accuracy= 0.000\n",
      "Step 204, Minibatch Loss= 373.2318, Training Accuracy= 0.000\n",
      "Step 205, Minibatch Loss= 256.7802, Training Accuracy= 0.000\n",
      "Step 206, Minibatch Loss= 296.3125, Training Accuracy= 0.000\n",
      "Step 207, Minibatch Loss= 289.1526, Training Accuracy= 0.000\n",
      "Step 208, Minibatch Loss= 334.2128, Training Accuracy= 0.000\n",
      "Step 209, Minibatch Loss= 344.1309, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 321.9479, Training Accuracy= 0.000\n",
      "Step 211, Minibatch Loss= 368.0234, Training Accuracy= 0.000\n",
      "Step 212, Minibatch Loss= 348.3617, Training Accuracy= 0.000\n",
      "Step 213, Minibatch Loss= 287.0557, Training Accuracy= 0.000\n",
      "Step 214, Minibatch Loss= 323.4022, Training Accuracy= 0.000\n",
      "Step 215, Minibatch Loss= 257.4089, Training Accuracy= 0.000\n",
      "Step 216, Minibatch Loss= 244.3189, Training Accuracy= 0.000\n",
      "Step 217, Minibatch Loss= 285.2869, Training Accuracy= 0.000\n",
      "Step 218, Minibatch Loss= 255.8968, Training Accuracy= 0.000\n",
      "Step 219, Minibatch Loss= 322.1177, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 285.0721, Training Accuracy= 0.000\n",
      "Step 221, Minibatch Loss= 321.8486, Training Accuracy= 0.000\n",
      "Step 222, Minibatch Loss= 235.8212, Training Accuracy= 0.000\n",
      "Step 223, Minibatch Loss= 274.8336, Training Accuracy= 0.000\n",
      "Step 224, Minibatch Loss= 324.7157, Training Accuracy= 0.000\n",
      "Step 225, Minibatch Loss= 315.4571, Training Accuracy= 0.000\n",
      "Step 226, Minibatch Loss= 353.4187, Training Accuracy= 0.000\n",
      "Step 227, Minibatch Loss= 411.8933, Training Accuracy= 0.000\n",
      "Step 228, Minibatch Loss= 364.5373, Training Accuracy= 0.000\n",
      "Step 229, Minibatch Loss= 292.7451, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 272.0853, Training Accuracy= 0.000\n",
      "Step 231, Minibatch Loss= 291.4802, Training Accuracy= 0.000\n",
      "Step 232, Minibatch Loss= 343.5845, Training Accuracy= 0.000\n",
      "Step 233, Minibatch Loss= 303.0710, Training Accuracy= 0.000\n",
      "Step 234, Minibatch Loss= 316.6188, Training Accuracy= 0.000\n",
      "Step 235, Minibatch Loss= 297.0188, Training Accuracy= 0.000\n",
      "Step 236, Minibatch Loss= 267.8523, Training Accuracy= 0.000\n",
      "Step 237, Minibatch Loss= 257.2410, Training Accuracy= 0.000\n",
      "Step 238, Minibatch Loss= 262.7422, Training Accuracy= 0.000\n",
      "Step 239, Minibatch Loss= 269.3191, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 332.3945, Training Accuracy= 0.000\n",
      "Step 241, Minibatch Loss= 267.2358, Training Accuracy= 0.000\n",
      "Step 242, Minibatch Loss= 267.8617, Training Accuracy= 0.000\n",
      "Step 243, Minibatch Loss= 266.9879, Training Accuracy= 0.000\n",
      "Step 244, Minibatch Loss= 295.2704, Training Accuracy= 0.000\n",
      "Step 245, Minibatch Loss= 230.4496, Training Accuracy= 0.000\n",
      "Step 246, Minibatch Loss= 214.5839, Training Accuracy= 0.000\n",
      "Step 247, Minibatch Loss= 265.4089, Training Accuracy= 0.000\n",
      "Step 248, Minibatch Loss= 278.6973, Training Accuracy= 0.000\n",
      "Step 249, Minibatch Loss= 256.9829, Training Accuracy= 0.000\n",
      "Step 250, Minibatch Loss= 222.0077, Training Accuracy= 0.000\n",
      "Step 251, Minibatch Loss= 198.4897, Training Accuracy= 0.000\n",
      "Step 252, Minibatch Loss= 240.0228, Training Accuracy= 0.000\n",
      "Step 253, Minibatch Loss= 199.9365, Training Accuracy= 0.000\n",
      "Step 254, Minibatch Loss= 218.0333, Training Accuracy= 0.000\n",
      "Step 255, Minibatch Loss= 264.8787, Training Accuracy= 0.000\n",
      "Step 256, Minibatch Loss= 241.9752, Training Accuracy= 0.000\n",
      "Step 257, Minibatch Loss= 241.1323, Training Accuracy= 0.000\n",
      "Step 258, Minibatch Loss= 211.7769, Training Accuracy= 0.000\n",
      "Step 259, Minibatch Loss= 233.9402, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 280.0245, Training Accuracy= 0.000\n",
      "Step 261, Minibatch Loss= 232.7891, Training Accuracy= 0.000\n",
      "Step 262, Minibatch Loss= 227.4055, Training Accuracy= 0.000\n",
      "Step 263, Minibatch Loss= 243.4357, Training Accuracy= 0.000\n",
      "Step 264, Minibatch Loss= 239.3147, Training Accuracy= 0.000\n",
      "Step 265, Minibatch Loss= 244.3816, Training Accuracy= 0.000\n",
      "Step 266, Minibatch Loss= 234.2389, Training Accuracy= 0.000\n",
      "Step 267, Minibatch Loss= 250.0224, Training Accuracy= 0.000\n",
      "Step 268, Minibatch Loss= 244.3594, Training Accuracy= 0.000\n",
      "Step 269, Minibatch Loss= 281.9328, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 224.4559, Training Accuracy= 0.000\n",
      "Step 271, Minibatch Loss= 262.2766, Training Accuracy= 0.000\n",
      "Step 272, Minibatch Loss= 280.9434, Training Accuracy= 0.000\n",
      "Step 273, Minibatch Loss= 280.7052, Training Accuracy= 0.000\n",
      "Step 274, Minibatch Loss= 336.4789, Training Accuracy= 0.000\n",
      "Step 275, Minibatch Loss= 412.7923, Training Accuracy= 0.000\n",
      "Step 276, Minibatch Loss= 475.2672, Training Accuracy= 0.000\n",
      "Step 277, Minibatch Loss= 659.8704, Training Accuracy= 0.000\n",
      "Step 278, Minibatch Loss= 956.7343, Training Accuracy= 0.000\n",
      "Step 279, Minibatch Loss= 1256.3829, Training Accuracy= 0.000\n",
      "Step 280, Minibatch Loss= 980.7036, Training Accuracy= 0.000\n",
      "Step 281, Minibatch Loss= 470.7649, Training Accuracy= 0.000\n",
      "Step 282, Minibatch Loss= 218.3742, Training Accuracy= 0.000\n",
      "Step 283, Minibatch Loss= 454.1050, Training Accuracy= 0.000\n",
      "Step 284, Minibatch Loss= 787.6406, Training Accuracy= 0.000\n",
      "Step 285, Minibatch Loss= 679.5737, Training Accuracy= 0.000\n",
      "Step 286, Minibatch Loss= 273.8098, Training Accuracy= 0.000\n",
      "Step 287, Minibatch Loss= 323.6219, Training Accuracy= 0.000\n",
      "Step 288, Minibatch Loss= 705.2346, Training Accuracy= 0.000\n",
      "Step 289, Minibatch Loss= 507.6283, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 264.1480, Training Accuracy= 0.000\n",
      "Step 291, Minibatch Loss= 419.0813, Training Accuracy= 0.000\n",
      "Step 292, Minibatch Loss= 511.2092, Training Accuracy= 0.000\n",
      "Step 293, Minibatch Loss= 233.1573, Training Accuracy= 0.000\n",
      "Step 294, Minibatch Loss= 333.8769, Training Accuracy= 0.000\n",
      "Step 295, Minibatch Loss= 406.1430, Training Accuracy= 0.000\n",
      "Step 296, Minibatch Loss= 212.6745, Training Accuracy= 0.000\n",
      "Step 297, Minibatch Loss= 298.4153, Training Accuracy= 0.000\n",
      "Step 298, Minibatch Loss= 286.5924, Training Accuracy= 0.000\n",
      "Step 299, Minibatch Loss= 251.0668, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 285.8705, Training Accuracy= 0.000\n",
      "Step 301, Minibatch Loss= 211.6744, Training Accuracy= 0.000\n",
      "Step 302, Minibatch Loss= 228.7355, Training Accuracy= 0.000\n",
      "Step 303, Minibatch Loss= 223.1168, Training Accuracy= 0.000\n",
      "Step 304, Minibatch Loss= 213.8639, Training Accuracy= 0.000\n",
      "Step 305, Minibatch Loss= 273.2180, Training Accuracy= 0.000\n",
      "Step 306, Minibatch Loss= 192.2703, Training Accuracy= 0.000\n",
      "Step 307, Minibatch Loss= 172.9196, Training Accuracy= 0.000\n",
      "Step 308, Minibatch Loss= 247.4915, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 309, Minibatch Loss= 192.3443, Training Accuracy= 0.000\n",
      "Step 310, Minibatch Loss= 214.6926, Training Accuracy= 0.000\n",
      "Step 311, Minibatch Loss= 193.5460, Training Accuracy= 0.000\n",
      "Step 312, Minibatch Loss= 214.0906, Training Accuracy= 0.000\n",
      "Step 313, Minibatch Loss= 231.3479, Training Accuracy= 0.000\n",
      "Step 314, Minibatch Loss= 160.1876, Training Accuracy= 0.000\n",
      "Step 315, Minibatch Loss= 223.1429, Training Accuracy= 0.000\n",
      "Step 316, Minibatch Loss= 191.3077, Training Accuracy= 0.000\n",
      "Step 317, Minibatch Loss= 202.0752, Training Accuracy= 0.000\n",
      "Step 318, Minibatch Loss= 210.9043, Training Accuracy= 0.000\n",
      "Step 319, Minibatch Loss= 195.7049, Training Accuracy= 0.000\n",
      "Step 320, Minibatch Loss= 201.1633, Training Accuracy= 0.000\n",
      "Step 321, Minibatch Loss= 180.5786, Training Accuracy= 0.000\n",
      "Step 322, Minibatch Loss= 188.0965, Training Accuracy= 0.000\n",
      "Step 323, Minibatch Loss= 170.3281, Training Accuracy= 0.000\n",
      "Step 324, Minibatch Loss= 170.7802, Training Accuracy= 0.000\n",
      "Step 325, Minibatch Loss= 224.5955, Training Accuracy= 0.000\n",
      "Step 326, Minibatch Loss= 187.8617, Training Accuracy= 0.000\n",
      "Step 327, Minibatch Loss= 179.1784, Training Accuracy= 0.000\n",
      "Step 328, Minibatch Loss= 167.8096, Training Accuracy= 0.000\n",
      "Step 329, Minibatch Loss= 168.8712, Training Accuracy= 0.000\n",
      "Step 330, Minibatch Loss= 168.6241, Training Accuracy= 0.000\n",
      "Step 331, Minibatch Loss= 160.8412, Training Accuracy= 0.000\n",
      "Step 332, Minibatch Loss= 185.1168, Training Accuracy= 0.000\n",
      "Step 333, Minibatch Loss= 218.2674, Training Accuracy= 0.000\n",
      "Step 334, Minibatch Loss= 166.6608, Training Accuracy= 0.000\n",
      "Step 335, Minibatch Loss= 191.5524, Training Accuracy= 0.000\n",
      "Step 336, Minibatch Loss= 192.0510, Training Accuracy= 0.000\n",
      "Step 337, Minibatch Loss= 160.2380, Training Accuracy= 0.000\n",
      "Step 338, Minibatch Loss= 205.8894, Training Accuracy= 0.000\n",
      "Step 339, Minibatch Loss= 147.6095, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 197.4706, Training Accuracy= 0.000\n",
      "Step 341, Minibatch Loss= 211.4962, Training Accuracy= 0.000\n",
      "Step 342, Minibatch Loss= 189.5090, Training Accuracy= 0.000\n",
      "Step 343, Minibatch Loss= 185.0052, Training Accuracy= 0.000\n",
      "Step 344, Minibatch Loss= 173.2840, Training Accuracy= 0.000\n",
      "Step 345, Minibatch Loss= 175.3391, Training Accuracy= 0.000\n",
      "Step 346, Minibatch Loss= 162.8555, Training Accuracy= 0.000\n",
      "Step 347, Minibatch Loss= 187.5583, Training Accuracy= 0.000\n",
      "Step 348, Minibatch Loss= 162.8034, Training Accuracy= 0.000\n",
      "Step 349, Minibatch Loss= 222.7413, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 183.8269, Training Accuracy= 0.000\n",
      "Step 351, Minibatch Loss= 145.0727, Training Accuracy= 0.000\n",
      "Step 352, Minibatch Loss= 148.3008, Training Accuracy= 0.000\n",
      "Step 353, Minibatch Loss= 163.2830, Training Accuracy= 0.000\n",
      "Step 354, Minibatch Loss= 183.5206, Training Accuracy= 0.000\n",
      "Step 355, Minibatch Loss= 162.1767, Training Accuracy= 0.000\n",
      "Step 356, Minibatch Loss= 161.5220, Training Accuracy= 0.000\n",
      "Step 357, Minibatch Loss= 189.3409, Training Accuracy= 0.000\n",
      "Step 358, Minibatch Loss= 158.4968, Training Accuracy= 0.000\n",
      "Step 359, Minibatch Loss= 157.2308, Training Accuracy= 0.000\n",
      "Step 360, Minibatch Loss= 146.6064, Training Accuracy= 0.000\n",
      "Step 361, Minibatch Loss= 163.0650, Training Accuracy= 0.000\n",
      "Step 362, Minibatch Loss= 165.1342, Training Accuracy= 0.000\n",
      "Step 363, Minibatch Loss= 154.5198, Training Accuracy= 0.000\n",
      "Step 364, Minibatch Loss= 153.3598, Training Accuracy= 0.000\n",
      "Step 365, Minibatch Loss= 145.8849, Training Accuracy= 0.000\n",
      "Step 366, Minibatch Loss= 157.9818, Training Accuracy= 0.000\n",
      "Step 367, Minibatch Loss= 174.6848, Training Accuracy= 0.000\n",
      "Step 368, Minibatch Loss= 146.4197, Training Accuracy= 0.000\n",
      "Step 369, Minibatch Loss= 138.9300, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 168.2019, Training Accuracy= 0.000\n",
      "Step 371, Minibatch Loss= 174.7218, Training Accuracy= 0.000\n",
      "Step 372, Minibatch Loss= 158.6742, Training Accuracy= 0.000\n",
      "Step 373, Minibatch Loss= 158.0503, Training Accuracy= 0.000\n",
      "Step 374, Minibatch Loss= 153.4170, Training Accuracy= 0.000\n",
      "Step 375, Minibatch Loss= 153.4440, Training Accuracy= 0.000\n",
      "Step 376, Minibatch Loss= 145.5532, Training Accuracy= 0.000\n",
      "Step 377, Minibatch Loss= 154.0628, Training Accuracy= 0.000\n",
      "Step 378, Minibatch Loss= 171.6990, Training Accuracy= 0.000\n",
      "Step 379, Minibatch Loss= 142.6272, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 158.5237, Training Accuracy= 0.000\n",
      "Step 381, Minibatch Loss= 147.6965, Training Accuracy= 0.000\n",
      "Step 382, Minibatch Loss= 162.0030, Training Accuracy= 0.000\n",
      "Step 383, Minibatch Loss= 144.8693, Training Accuracy= 0.000\n",
      "Step 384, Minibatch Loss= 134.9202, Training Accuracy= 0.000\n",
      "Step 385, Minibatch Loss= 130.2078, Training Accuracy= 0.000\n",
      "Step 386, Minibatch Loss= 128.4830, Training Accuracy= 0.000\n",
      "Step 387, Minibatch Loss= 163.3880, Training Accuracy= 0.000\n",
      "Step 388, Minibatch Loss= 143.7956, Training Accuracy= 0.000\n",
      "Step 389, Minibatch Loss= 213.8413, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 168.4949, Training Accuracy= 0.000\n",
      "Step 391, Minibatch Loss= 162.1740, Training Accuracy= 0.000\n",
      "Step 392, Minibatch Loss= 170.8748, Training Accuracy= 0.000\n",
      "Step 393, Minibatch Loss= 182.6334, Training Accuracy= 0.000\n",
      "Step 394, Minibatch Loss= 202.6732, Training Accuracy= 0.000\n",
      "Step 395, Minibatch Loss= 276.7200, Training Accuracy= 0.000\n",
      "Step 396, Minibatch Loss= 326.8243, Training Accuracy= 0.000\n",
      "Step 397, Minibatch Loss= 351.6371, Training Accuracy= 0.000\n",
      "Step 398, Minibatch Loss= 333.4787, Training Accuracy= 0.000\n",
      "Step 399, Minibatch Loss= 209.1406, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 134.3087, Training Accuracy= 0.000\n",
      "Step 401, Minibatch Loss= 135.1943, Training Accuracy= 0.000\n",
      "Step 402, Minibatch Loss= 175.2964, Training Accuracy= 0.000\n",
      "Step 403, Minibatch Loss= 280.6470, Training Accuracy= 0.000\n",
      "Step 404, Minibatch Loss= 276.3287, Training Accuracy= 0.000\n",
      "Step 405, Minibatch Loss= 223.6226, Training Accuracy= 0.000\n",
      "Step 406, Minibatch Loss= 163.9186, Training Accuracy= 0.000\n",
      "Step 407, Minibatch Loss= 132.6995, Training Accuracy= 0.000\n",
      "Step 408, Minibatch Loss= 165.0544, Training Accuracy= 0.000\n",
      "Step 409, Minibatch Loss= 154.9633, Training Accuracy= 0.000\n",
      "Step 410, Minibatch Loss= 140.5325, Training Accuracy= 0.000\n",
      "Step 411, Minibatch Loss= 135.3950, Training Accuracy= 0.000\n",
      "Step 412, Minibatch Loss= 126.5093, Training Accuracy= 0.000\n",
      "Step 413, Minibatch Loss= 124.7473, Training Accuracy= 0.000\n",
      "Step 414, Minibatch Loss= 130.5140, Training Accuracy= 0.000\n",
      "Step 415, Minibatch Loss= 158.0159, Training Accuracy= 0.000\n",
      "Step 416, Minibatch Loss= 172.2497, Training Accuracy= 0.000\n",
      "Step 417, Minibatch Loss= 157.3967, Training Accuracy= 0.000\n",
      "Step 418, Minibatch Loss= 128.0914, Training Accuracy= 0.000\n",
      "Step 419, Minibatch Loss= 166.4933, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 139.5431, Training Accuracy= 0.000\n",
      "Step 421, Minibatch Loss= 147.6232, Training Accuracy= 0.000\n",
      "Step 422, Minibatch Loss= 145.9619, Training Accuracy= 0.000\n",
      "Step 423, Minibatch Loss= 116.5030, Training Accuracy= 0.000\n",
      "Step 424, Minibatch Loss= 140.6347, Training Accuracy= 0.000\n",
      "Step 425, Minibatch Loss= 147.6591, Training Accuracy= 0.000\n",
      "Step 426, Minibatch Loss= 152.4795, Training Accuracy= 0.000\n",
      "Step 427, Minibatch Loss= 138.4521, Training Accuracy= 0.000\n",
      "Step 428, Minibatch Loss= 131.6488, Training Accuracy= 0.000\n",
      "Step 429, Minibatch Loss= 133.8653, Training Accuracy= 0.000\n",
      "Step 430, Minibatch Loss= 130.4357, Training Accuracy= 0.000\n",
      "Step 431, Minibatch Loss= 122.0892, Training Accuracy= 0.000\n",
      "Step 432, Minibatch Loss= 129.0004, Training Accuracy= 0.000\n",
      "Step 433, Minibatch Loss= 127.2292, Training Accuracy= 0.000\n",
      "Step 434, Minibatch Loss= 132.6973, Training Accuracy= 0.000\n",
      "Step 435, Minibatch Loss= 133.8850, Training Accuracy= 0.000\n",
      "Step 436, Minibatch Loss= 129.1188, Training Accuracy= 0.000\n",
      "Step 437, Minibatch Loss= 127.1151, Training Accuracy= 0.000\n",
      "Step 438, Minibatch Loss= 130.2534, Training Accuracy= 0.000\n",
      "Step 439, Minibatch Loss= 127.8004, Training Accuracy= 0.000\n",
      "Step 440, Minibatch Loss= 103.6708, Training Accuracy= 0.000\n",
      "Step 441, Minibatch Loss= 121.7974, Training Accuracy= 0.000\n",
      "Step 442, Minibatch Loss= 114.9641, Training Accuracy= 0.000\n",
      "Step 443, Minibatch Loss= 107.2709, Training Accuracy= 0.000\n",
      "Step 444, Minibatch Loss= 115.5037, Training Accuracy= 0.000\n",
      "Step 445, Minibatch Loss= 136.5794, Training Accuracy= 0.000\n",
      "Step 446, Minibatch Loss= 98.3809, Training Accuracy= 0.000\n",
      "Step 447, Minibatch Loss= 122.8007, Training Accuracy= 0.000\n",
      "Step 448, Minibatch Loss= 115.7752, Training Accuracy= 0.000\n",
      "Step 449, Minibatch Loss= 120.7898, Training Accuracy= 0.000\n",
      "Step 450, Minibatch Loss= 124.2514, Training Accuracy= 0.000\n",
      "Step 451, Minibatch Loss= 114.4825, Training Accuracy= 0.000\n",
      "Step 452, Minibatch Loss= 118.6591, Training Accuracy= 0.000\n",
      "Step 453, Minibatch Loss= 114.2457, Training Accuracy= 0.000\n",
      "Step 454, Minibatch Loss= 107.5437, Training Accuracy= 0.000\n",
      "Step 455, Minibatch Loss= 133.0785, Training Accuracy= 0.000\n",
      "Step 456, Minibatch Loss= 110.9531, Training Accuracy= 0.000\n",
      "Step 457, Minibatch Loss= 116.4670, Training Accuracy= 0.000\n",
      "Step 458, Minibatch Loss= 119.1751, Training Accuracy= 0.000\n",
      "Step 459, Minibatch Loss= 98.3256, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 135.8198, Training Accuracy= 0.000\n",
      "Step 461, Minibatch Loss= 123.5391, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 462, Minibatch Loss= 109.1729, Training Accuracy= 0.000\n",
      "Step 463, Minibatch Loss= 121.9055, Training Accuracy= 0.000\n",
      "Step 464, Minibatch Loss= 113.6557, Training Accuracy= 0.000\n",
      "Step 465, Minibatch Loss= 111.5426, Training Accuracy= 0.000\n",
      "Step 466, Minibatch Loss= 128.7601, Training Accuracy= 0.000\n",
      "Step 467, Minibatch Loss= 110.7627, Training Accuracy= 0.000\n",
      "Step 468, Minibatch Loss= 96.0053, Training Accuracy= 0.000\n",
      "Step 469, Minibatch Loss= 111.1928, Training Accuracy= 0.000\n",
      "Step 470, Minibatch Loss= 131.8285, Training Accuracy= 0.000\n",
      "Step 471, Minibatch Loss= 94.1236, Training Accuracy= 0.000\n",
      "Step 472, Minibatch Loss= 110.4928, Training Accuracy= 0.000\n",
      "Step 473, Minibatch Loss= 117.3497, Training Accuracy= 0.000\n",
      "Step 474, Minibatch Loss= 105.6119, Training Accuracy= 0.000\n",
      "Step 475, Minibatch Loss= 121.7638, Training Accuracy= 0.000\n",
      "Step 476, Minibatch Loss= 101.9188, Training Accuracy= 0.000\n",
      "Step 477, Minibatch Loss= 99.2958, Training Accuracy= 0.000\n",
      "Step 478, Minibatch Loss= 95.7584, Training Accuracy= 0.000\n",
      "Step 479, Minibatch Loss= 94.8053, Training Accuracy= 0.000\n",
      "Step 480, Minibatch Loss= 106.1208, Training Accuracy= 0.000\n",
      "Step 481, Minibatch Loss= 92.9625, Training Accuracy= 0.000\n",
      "Step 482, Minibatch Loss= 97.2727, Training Accuracy= 0.000\n",
      "Step 483, Minibatch Loss= 87.1998, Training Accuracy= 0.000\n",
      "Step 484, Minibatch Loss= 106.9447, Training Accuracy= 0.000\n",
      "Step 485, Minibatch Loss= 95.3985, Training Accuracy= 0.000\n",
      "Step 486, Minibatch Loss= 95.7250, Training Accuracy= 0.000\n",
      "Step 487, Minibatch Loss= 100.6571, Training Accuracy= 0.000\n",
      "Step 488, Minibatch Loss= 106.0655, Training Accuracy= 0.000\n",
      "Step 489, Minibatch Loss= 109.5764, Training Accuracy= 0.000\n",
      "Step 490, Minibatch Loss= 101.9179, Training Accuracy= 0.000\n",
      "Step 491, Minibatch Loss= 110.9302, Training Accuracy= 0.000\n",
      "Step 492, Minibatch Loss= 95.4993, Training Accuracy= 0.000\n",
      "Step 493, Minibatch Loss= 89.5622, Training Accuracy= 0.000\n",
      "Step 494, Minibatch Loss= 96.4759, Training Accuracy= 0.000\n",
      "Step 495, Minibatch Loss= 111.9096, Training Accuracy= 0.000\n",
      "Step 496, Minibatch Loss= 109.7590, Training Accuracy= 0.000\n",
      "Step 497, Minibatch Loss= 110.1909, Training Accuracy= 0.000\n",
      "Step 498, Minibatch Loss= 118.8446, Training Accuracy= 0.000\n",
      "Step 499, Minibatch Loss= 99.9142, Training Accuracy= 0.000\n",
      "Step 500, Minibatch Loss= 107.0257, Training Accuracy= 0.000\n",
      "Step 501, Minibatch Loss= 115.7025, Training Accuracy= 0.000\n",
      "Step 502, Minibatch Loss= 97.9738, Training Accuracy= 0.000\n",
      "Step 503, Minibatch Loss= 110.1833, Training Accuracy= 0.000\n",
      "Step 504, Minibatch Loss= 99.8390, Training Accuracy= 0.000\n",
      "Step 505, Minibatch Loss= 103.6454, Training Accuracy= 0.000\n",
      "Step 506, Minibatch Loss= 96.2402, Training Accuracy= 0.000\n",
      "Step 507, Minibatch Loss= 95.5075, Training Accuracy= 0.000\n",
      "Step 508, Minibatch Loss= 102.0679, Training Accuracy= 0.000\n",
      "Step 509, Minibatch Loss= 103.1453, Training Accuracy= 0.000\n",
      "Step 510, Minibatch Loss= 85.9698, Training Accuracy= 0.000\n",
      "Step 511, Minibatch Loss= 102.9718, Training Accuracy= 0.000\n",
      "Step 512, Minibatch Loss= 96.1240, Training Accuracy= 0.000\n",
      "Step 513, Minibatch Loss= 97.9329, Training Accuracy= 0.000\n",
      "Step 514, Minibatch Loss= 85.1750, Training Accuracy= 0.000\n",
      "Step 515, Minibatch Loss= 105.1586, Training Accuracy= 0.000\n",
      "Step 516, Minibatch Loss= 113.6858, Training Accuracy= 0.000\n",
      "Step 517, Minibatch Loss= 92.8028, Training Accuracy= 0.000\n",
      "Step 518, Minibatch Loss= 100.3371, Training Accuracy= 0.000\n",
      "Step 519, Minibatch Loss= 101.4156, Training Accuracy= 0.000\n",
      "Step 520, Minibatch Loss= 99.1971, Training Accuracy= 0.000\n",
      "Step 521, Minibatch Loss= 96.2976, Training Accuracy= 0.000\n",
      "Step 522, Minibatch Loss= 109.7405, Training Accuracy= 0.000\n",
      "Step 523, Minibatch Loss= 104.8633, Training Accuracy= 0.000\n",
      "Step 524, Minibatch Loss= 103.6149, Training Accuracy= 0.000\n",
      "Step 525, Minibatch Loss= 103.7789, Training Accuracy= 0.000\n",
      "Step 526, Minibatch Loss= 112.2567, Training Accuracy= 0.000\n",
      "Step 527, Minibatch Loss= 109.4324, Training Accuracy= 0.000\n",
      "Step 528, Minibatch Loss= 99.8148, Training Accuracy= 0.000\n",
      "Step 529, Minibatch Loss= 97.5234, Training Accuracy= 0.000\n",
      "Step 530, Minibatch Loss= 122.5894, Training Accuracy= 0.000\n",
      "Step 531, Minibatch Loss= 140.7724, Training Accuracy= 0.000\n",
      "Step 532, Minibatch Loss= 215.3585, Training Accuracy= 0.000\n",
      "Step 533, Minibatch Loss= 241.2767, Training Accuracy= 0.000\n",
      "Step 534, Minibatch Loss= 206.0448, Training Accuracy= 0.000\n",
      "Step 535, Minibatch Loss= 138.7950, Training Accuracy= 0.000\n",
      "Step 536, Minibatch Loss= 94.3800, Training Accuracy= 0.000\n",
      "Step 537, Minibatch Loss= 101.2490, Training Accuracy= 0.000\n",
      "Step 538, Minibatch Loss= 121.2949, Training Accuracy= 0.000\n",
      "Step 539, Minibatch Loss= 191.4637, Training Accuracy= 0.000\n",
      "Step 540, Minibatch Loss= 203.7795, Training Accuracy= 0.000\n",
      "Step 541, Minibatch Loss= 157.2394, Training Accuracy= 0.000\n",
      "Step 542, Minibatch Loss= 101.4849, Training Accuracy= 0.000\n",
      "Step 543, Minibatch Loss= 104.9125, Training Accuracy= 0.000\n",
      "Step 544, Minibatch Loss= 122.3978, Training Accuracy= 0.000\n",
      "Step 545, Minibatch Loss= 134.0596, Training Accuracy= 0.000\n",
      "Step 546, Minibatch Loss= 128.6952, Training Accuracy= 0.000\n",
      "Step 547, Minibatch Loss= 102.2284, Training Accuracy= 0.000\n",
      "Step 548, Minibatch Loss= 103.4740, Training Accuracy= 0.000\n",
      "Step 549, Minibatch Loss= 105.2693, Training Accuracy= 0.000\n",
      "Step 550, Minibatch Loss= 123.3223, Training Accuracy= 0.000\n",
      "Step 551, Minibatch Loss= 124.9666, Training Accuracy= 0.000\n",
      "Step 552, Minibatch Loss= 113.5451, Training Accuracy= 0.000\n",
      "Step 553, Minibatch Loss= 111.3188, Training Accuracy= 0.000\n",
      "Step 554, Minibatch Loss= 96.1540, Training Accuracy= 0.000\n",
      "Step 555, Minibatch Loss= 93.9461, Training Accuracy= 0.000\n",
      "Step 556, Minibatch Loss= 105.6809, Training Accuracy= 0.000\n",
      "Step 557, Minibatch Loss= 104.9071, Training Accuracy= 0.000\n",
      "Step 558, Minibatch Loss= 89.4548, Training Accuracy= 0.000\n",
      "Step 559, Minibatch Loss= 87.1033, Training Accuracy= 0.000\n",
      "Step 560, Minibatch Loss= 95.5107, Training Accuracy= 0.000\n",
      "Step 561, Minibatch Loss= 95.9065, Training Accuracy= 0.000\n",
      "Step 562, Minibatch Loss= 101.4372, Training Accuracy= 0.000\n",
      "Step 563, Minibatch Loss= 90.5041, Training Accuracy= 0.000\n",
      "Step 564, Minibatch Loss= 88.4682, Training Accuracy= 0.000\n",
      "Step 565, Minibatch Loss= 92.0178, Training Accuracy= 0.000\n",
      "Step 566, Minibatch Loss= 106.8502, Training Accuracy= 0.000\n",
      "Step 567, Minibatch Loss= 83.8771, Training Accuracy= 0.000\n",
      "Step 568, Minibatch Loss= 83.3775, Training Accuracy= 0.000\n",
      "Step 569, Minibatch Loss= 90.2884, Training Accuracy= 0.000\n",
      "Step 570, Minibatch Loss= 85.4784, Training Accuracy= 0.000\n",
      "Step 571, Minibatch Loss= 78.8388, Training Accuracy= 0.000\n",
      "Step 572, Minibatch Loss= 82.4089, Training Accuracy= 0.000\n",
      "Step 573, Minibatch Loss= 97.1695, Training Accuracy= 0.000\n",
      "Step 574, Minibatch Loss= 96.2279, Training Accuracy= 0.000\n",
      "Step 575, Minibatch Loss= 92.0249, Training Accuracy= 0.000\n",
      "Step 576, Minibatch Loss= 117.2258, Training Accuracy= 0.000\n",
      "Step 577, Minibatch Loss= 119.0009, Training Accuracy= 0.000\n",
      "Step 578, Minibatch Loss= 162.8166, Training Accuracy= 0.000\n",
      "Step 579, Minibatch Loss= 265.1872, Training Accuracy= 0.000\n",
      "Step 580, Minibatch Loss= 342.0279, Training Accuracy= 0.000\n",
      "Step 581, Minibatch Loss= 292.6983, Training Accuracy= 0.000\n",
      "Step 582, Minibatch Loss= 373.7350, Training Accuracy= 0.000\n",
      "Step 583, Minibatch Loss= 391.1236, Training Accuracy= 0.000\n",
      "Step 584, Minibatch Loss= 400.9810, Training Accuracy= 0.000\n",
      "Step 585, Minibatch Loss= 395.9619, Training Accuracy= 0.000\n",
      "Step 586, Minibatch Loss= 266.8682, Training Accuracy= 0.000\n",
      "Step 587, Minibatch Loss= 119.8540, Training Accuracy= 0.000\n",
      "Step 588, Minibatch Loss= 121.9806, Training Accuracy= 0.000\n",
      "Step 589, Minibatch Loss= 232.7766, Training Accuracy= 0.000\n",
      "Step 590, Minibatch Loss= 237.4332, Training Accuracy= 0.000\n",
      "Step 591, Minibatch Loss= 137.3624, Training Accuracy= 0.000\n",
      "Step 592, Minibatch Loss= 100.1454, Training Accuracy= 0.000\n",
      "Step 593, Minibatch Loss= 245.9944, Training Accuracy= 0.000\n",
      "Step 594, Minibatch Loss= 222.7392, Training Accuracy= 0.000\n",
      "Step 595, Minibatch Loss= 91.4484, Training Accuracy= 0.000\n",
      "Step 596, Minibatch Loss= 144.7535, Training Accuracy= 0.000\n",
      "Step 597, Minibatch Loss= 213.7289, Training Accuracy= 0.000\n",
      "Step 598, Minibatch Loss= 123.3105, Training Accuracy= 0.000\n",
      "Step 599, Minibatch Loss= 93.9502, Training Accuracy= 0.000\n",
      "Step 600, Minibatch Loss= 162.7885, Training Accuracy= 0.000\n",
      "Step 601, Minibatch Loss= 120.2130, Training Accuracy= 0.000\n",
      "Step 602, Minibatch Loss= 86.0120, Training Accuracy= 0.000\n",
      "Step 603, Minibatch Loss= 126.2538, Training Accuracy= 0.000\n",
      "Step 604, Minibatch Loss= 105.7910, Training Accuracy= 0.000\n",
      "Step 605, Minibatch Loss= 98.5192, Training Accuracy= 0.000\n",
      "Step 606, Minibatch Loss= 127.7256, Training Accuracy= 0.000\n",
      "Step 607, Minibatch Loss= 87.5315, Training Accuracy= 0.000\n",
      "Step 608, Minibatch Loss= 93.6455, Training Accuracy= 0.000\n",
      "Step 609, Minibatch Loss= 111.0526, Training Accuracy= 0.000\n",
      "Step 610, Minibatch Loss= 78.7922, Training Accuracy= 0.000\n",
      "Step 611, Minibatch Loss= 94.9909, Training Accuracy= 0.000\n",
      "Step 612, Minibatch Loss= 78.9965, Training Accuracy= 0.000\n",
      "Step 613, Minibatch Loss= 117.6865, Training Accuracy= 0.000\n",
      "Step 614, Minibatch Loss= 78.1583, Training Accuracy= 0.000\n",
      "Step 615, Minibatch Loss= 76.7934, Training Accuracy= 0.000\n",
      "Step 616, Minibatch Loss= 109.5576, Training Accuracy= 0.000\n",
      "Step 617, Minibatch Loss= 80.4229, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 618, Minibatch Loss= 90.7785, Training Accuracy= 0.000\n",
      "Step 619, Minibatch Loss= 78.9304, Training Accuracy= 0.000\n",
      "Step 620, Minibatch Loss= 95.2037, Training Accuracy= 0.000\n",
      "Step 621, Minibatch Loss= 67.7971, Training Accuracy= 0.000\n",
      "Step 622, Minibatch Loss= 85.0441, Training Accuracy= 0.000\n",
      "Step 623, Minibatch Loss= 83.6742, Training Accuracy= 0.000\n",
      "Step 624, Minibatch Loss= 79.8811, Training Accuracy= 0.000\n",
      "Step 625, Minibatch Loss= 80.3873, Training Accuracy= 0.000\n",
      "Step 626, Minibatch Loss= 76.5604, Training Accuracy= 0.000\n",
      "Step 627, Minibatch Loss= 78.8792, Training Accuracy= 0.000\n",
      "Step 628, Minibatch Loss= 80.9817, Training Accuracy= 0.000\n",
      "Step 629, Minibatch Loss= 66.5125, Training Accuracy= 0.000\n",
      "Step 630, Minibatch Loss= 83.0260, Training Accuracy= 0.000\n",
      "Step 631, Minibatch Loss= 75.6567, Training Accuracy= 0.000\n",
      "Step 632, Minibatch Loss= 72.5815, Training Accuracy= 0.000\n",
      "Step 633, Minibatch Loss= 79.4020, Training Accuracy= 0.000\n",
      "Step 634, Minibatch Loss= 85.6347, Training Accuracy= 0.000\n",
      "Step 635, Minibatch Loss= 74.3617, Training Accuracy= 0.000\n",
      "Step 636, Minibatch Loss= 68.6099, Training Accuracy= 0.000\n",
      "Step 637, Minibatch Loss= 73.7628, Training Accuracy= 0.000\n",
      "Step 638, Minibatch Loss= 64.4265, Training Accuracy= 0.000\n",
      "Step 639, Minibatch Loss= 60.4454, Training Accuracy= 0.000\n",
      "Step 640, Minibatch Loss= 64.9935, Training Accuracy= 0.000\n",
      "Step 641, Minibatch Loss= 76.1096, Training Accuracy= 0.000\n",
      "Step 642, Minibatch Loss= 72.0838, Training Accuracy= 0.000\n",
      "Step 643, Minibatch Loss= 65.2971, Training Accuracy= 0.000\n",
      "Step 644, Minibatch Loss= 69.3847, Training Accuracy= 0.000\n",
      "Step 645, Minibatch Loss= 73.4141, Training Accuracy= 0.000\n",
      "Step 646, Minibatch Loss= 84.9792, Training Accuracy= 0.000\n",
      "Step 647, Minibatch Loss= 76.5423, Training Accuracy= 0.000\n",
      "Step 648, Minibatch Loss= 67.9733, Training Accuracy= 0.000\n",
      "Step 649, Minibatch Loss= 78.5841, Training Accuracy= 0.000\n",
      "Step 650, Minibatch Loss= 68.1171, Training Accuracy= 0.000\n",
      "Step 651, Minibatch Loss= 76.0278, Training Accuracy= 0.000\n",
      "Step 652, Minibatch Loss= 75.9987, Training Accuracy= 0.000\n",
      "Step 653, Minibatch Loss= 72.6948, Training Accuracy= 0.000\n",
      "Step 654, Minibatch Loss= 71.7110, Training Accuracy= 0.000\n",
      "Step 655, Minibatch Loss= 71.8094, Training Accuracy= 0.000\n",
      "Step 656, Minibatch Loss= 68.2412, Training Accuracy= 0.000\n",
      "Step 657, Minibatch Loss= 76.6875, Training Accuracy= 0.000\n",
      "Step 658, Minibatch Loss= 69.6911, Training Accuracy= 0.000\n",
      "Step 659, Minibatch Loss= 74.2564, Training Accuracy= 0.000\n",
      "Step 660, Minibatch Loss= 70.5897, Training Accuracy= 0.000\n",
      "Step 661, Minibatch Loss= 77.5647, Training Accuracy= 0.000\n",
      "Step 662, Minibatch Loss= 87.7999, Training Accuracy= 0.000\n",
      "Step 663, Minibatch Loss= 74.3569, Training Accuracy= 0.000\n",
      "Step 664, Minibatch Loss= 65.1707, Training Accuracy= 0.000\n",
      "Step 665, Minibatch Loss= 79.4804, Training Accuracy= 0.000\n",
      "Step 666, Minibatch Loss= 82.0823, Training Accuracy= 0.000\n",
      "Step 667, Minibatch Loss= 74.6758, Training Accuracy= 0.000\n",
      "Step 668, Minibatch Loss= 82.5698, Training Accuracy= 0.000\n",
      "Step 669, Minibatch Loss= 60.1279, Training Accuracy= 0.000\n",
      "Step 670, Minibatch Loss= 77.1756, Training Accuracy= 0.000\n",
      "Step 671, Minibatch Loss= 74.3734, Training Accuracy= 0.000\n",
      "Step 672, Minibatch Loss= 73.3298, Training Accuracy= 0.000\n",
      "Step 673, Minibatch Loss= 70.1794, Training Accuracy= 0.000\n",
      "Step 674, Minibatch Loss= 74.5546, Training Accuracy= 0.000\n",
      "Step 675, Minibatch Loss= 75.3869, Training Accuracy= 0.000\n",
      "Step 676, Minibatch Loss= 77.3082, Training Accuracy= 0.000\n",
      "Step 677, Minibatch Loss= 66.0982, Training Accuracy= 0.000\n",
      "Step 678, Minibatch Loss= 63.7543, Training Accuracy= 0.000\n",
      "Step 679, Minibatch Loss= 71.0256, Training Accuracy= 0.000\n",
      "Step 680, Minibatch Loss= 85.9147, Training Accuracy= 0.000\n",
      "Step 681, Minibatch Loss= 80.1785, Training Accuracy= 0.000\n",
      "Step 682, Minibatch Loss= 78.2277, Training Accuracy= 0.000\n",
      "Step 683, Minibatch Loss= 60.5069, Training Accuracy= 0.000\n",
      "Step 684, Minibatch Loss= 74.9405, Training Accuracy= 0.000\n",
      "Step 685, Minibatch Loss= 66.5746, Training Accuracy= 0.000\n",
      "Step 686, Minibatch Loss= 82.4559, Training Accuracy= 0.000\n",
      "Step 687, Minibatch Loss= 75.5692, Training Accuracy= 0.000\n",
      "Step 688, Minibatch Loss= 74.1950, Training Accuracy= 0.000\n",
      "Step 689, Minibatch Loss= 71.5972, Training Accuracy= 0.000\n",
      "Step 690, Minibatch Loss= 67.2995, Training Accuracy= 0.000\n",
      "Step 691, Minibatch Loss= 77.2982, Training Accuracy= 0.000\n",
      "Step 692, Minibatch Loss= 76.2359, Training Accuracy= 0.000\n",
      "Step 693, Minibatch Loss= 75.9537, Training Accuracy= 0.000\n",
      "Step 694, Minibatch Loss= 87.6687, Training Accuracy= 0.000\n",
      "Step 695, Minibatch Loss= 84.9386, Training Accuracy= 0.000\n",
      "Step 696, Minibatch Loss= 66.8205, Training Accuracy= 0.000\n",
      "Step 697, Minibatch Loss= 68.1531, Training Accuracy= 0.000\n",
      "Step 698, Minibatch Loss= 59.8529, Training Accuracy= 0.000\n",
      "Step 699, Minibatch Loss= 69.0537, Training Accuracy= 0.000\n",
      "Step 700, Minibatch Loss= 73.3105, Training Accuracy= 0.000\n",
      "Step 701, Minibatch Loss= 79.9603, Training Accuracy= 0.000\n",
      "Step 702, Minibatch Loss= 93.8266, Training Accuracy= 0.000\n",
      "Step 703, Minibatch Loss= 82.1730, Training Accuracy= 0.000\n",
      "Step 704, Minibatch Loss= 68.6242, Training Accuracy= 0.000\n",
      "Step 705, Minibatch Loss= 60.4621, Training Accuracy= 0.000\n",
      "Step 706, Minibatch Loss= 64.3242, Training Accuracy= 0.000\n",
      "Step 707, Minibatch Loss= 60.5905, Training Accuracy= 0.000\n",
      "Step 708, Minibatch Loss= 72.1307, Training Accuracy= 0.000\n",
      "Step 709, Minibatch Loss= 72.5000, Training Accuracy= 0.000\n",
      "Step 710, Minibatch Loss= 65.5235, Training Accuracy= 0.000\n",
      "Step 711, Minibatch Loss= 58.7375, Training Accuracy= 0.000\n",
      "Step 712, Minibatch Loss= 66.6631, Training Accuracy= 0.000\n",
      "Step 713, Minibatch Loss= 67.9522, Training Accuracy= 0.000\n",
      "Step 714, Minibatch Loss= 67.8298, Training Accuracy= 0.000\n",
      "Step 715, Minibatch Loss= 79.3888, Training Accuracy= 0.000\n",
      "Step 716, Minibatch Loss= 72.7932, Training Accuracy= 0.000\n",
      "Step 717, Minibatch Loss= 88.9924, Training Accuracy= 0.000\n",
      "Step 718, Minibatch Loss= 69.3682, Training Accuracy= 0.000\n",
      "Step 719, Minibatch Loss= 81.0569, Training Accuracy= 0.000\n",
      "Step 720, Minibatch Loss= 68.6395, Training Accuracy= 0.000\n",
      "Step 721, Minibatch Loss= 64.6257, Training Accuracy= 0.000\n",
      "Step 722, Minibatch Loss= 67.1445, Training Accuracy= 0.000\n",
      "Step 723, Minibatch Loss= 63.8676, Training Accuracy= 0.000\n",
      "Step 724, Minibatch Loss= 91.7166, Training Accuracy= 0.000\n",
      "Step 725, Minibatch Loss= 68.4570, Training Accuracy= 0.000\n",
      "Step 726, Minibatch Loss= 66.2291, Training Accuracy= 0.000\n",
      "Step 727, Minibatch Loss= 67.3552, Training Accuracy= 0.000\n",
      "Step 728, Minibatch Loss= 65.4436, Training Accuracy= 0.000\n",
      "Step 729, Minibatch Loss= 83.5859, Training Accuracy= 0.000\n",
      "Step 730, Minibatch Loss= 66.5279, Training Accuracy= 0.000\n",
      "Step 731, Minibatch Loss= 65.1122, Training Accuracy= 0.000\n",
      "Step 732, Minibatch Loss= 61.1103, Training Accuracy= 0.000\n",
      "Step 733, Minibatch Loss= 67.5165, Training Accuracy= 0.000\n",
      "Step 734, Minibatch Loss= 61.1339, Training Accuracy= 0.000\n",
      "Step 735, Minibatch Loss= 64.6475, Training Accuracy= 0.000\n",
      "Step 736, Minibatch Loss= 80.5401, Training Accuracy= 0.000\n",
      "Step 737, Minibatch Loss= 56.2818, Training Accuracy= 0.000\n",
      "Step 738, Minibatch Loss= 61.1477, Training Accuracy= 0.000\n",
      "Step 739, Minibatch Loss= 67.5322, Training Accuracy= 0.000\n",
      "Step 740, Minibatch Loss= 66.6841, Training Accuracy= 0.000\n",
      "Step 741, Minibatch Loss= 62.0433, Training Accuracy= 0.000\n",
      "Step 742, Minibatch Loss= 63.8960, Training Accuracy= 0.000\n",
      "Step 743, Minibatch Loss= 61.7044, Training Accuracy= 0.000\n",
      "Step 744, Minibatch Loss= 59.1210, Training Accuracy= 0.000\n",
      "Step 745, Minibatch Loss= 78.3283, Training Accuracy= 0.000\n",
      "Step 746, Minibatch Loss= 72.0432, Training Accuracy= 0.000\n",
      "Step 747, Minibatch Loss= 68.7672, Training Accuracy= 0.000\n",
      "Step 748, Minibatch Loss= 66.3251, Training Accuracy= 0.000\n",
      "Step 749, Minibatch Loss= 57.5708, Training Accuracy= 0.000\n",
      "Step 750, Minibatch Loss= 63.1173, Training Accuracy= 0.000\n",
      "Step 751, Minibatch Loss= 70.4313, Training Accuracy= 0.000\n",
      "Step 752, Minibatch Loss= 71.2227, Training Accuracy= 0.000\n",
      "Step 753, Minibatch Loss= 68.9508, Training Accuracy= 0.000\n",
      "Step 754, Minibatch Loss= 66.8013, Training Accuracy= 0.000\n",
      "Step 755, Minibatch Loss= 65.0592, Training Accuracy= 0.000\n",
      "Step 756, Minibatch Loss= 62.6052, Training Accuracy= 0.000\n",
      "Step 757, Minibatch Loss= 58.7257, Training Accuracy= 0.000\n",
      "Step 758, Minibatch Loss= 64.5180, Training Accuracy= 0.000\n",
      "Step 759, Minibatch Loss= 64.4672, Training Accuracy= 0.000\n",
      "Step 760, Minibatch Loss= 62.1712, Training Accuracy= 0.000\n",
      "Step 761, Minibatch Loss= 64.7753, Training Accuracy= 0.000\n",
      "Step 762, Minibatch Loss= 62.3855, Training Accuracy= 0.000\n",
      "Step 763, Minibatch Loss= 64.0208, Training Accuracy= 0.000\n",
      "Step 764, Minibatch Loss= 59.8783, Training Accuracy= 0.000\n",
      "Step 765, Minibatch Loss= 62.0329, Training Accuracy= 0.000\n",
      "Step 766, Minibatch Loss= 54.2606, Training Accuracy= 0.000\n",
      "Step 767, Minibatch Loss= 62.1930, Training Accuracy= 0.000\n",
      "Step 768, Minibatch Loss= 58.4100, Training Accuracy= 0.000\n",
      "Step 769, Minibatch Loss= 61.1582, Training Accuracy= 0.000\n",
      "Step 770, Minibatch Loss= 73.2024, Training Accuracy= 0.000\n",
      "Step 771, Minibatch Loss= 79.7212, Training Accuracy= 0.000\n",
      "Step 772, Minibatch Loss= 60.3343, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 773, Minibatch Loss= 61.4995, Training Accuracy= 0.000\n",
      "Step 774, Minibatch Loss= 65.2316, Training Accuracy= 0.000\n",
      "Step 775, Minibatch Loss= 60.7034, Training Accuracy= 0.000\n",
      "Step 776, Minibatch Loss= 54.6277, Training Accuracy= 0.000\n",
      "Step 777, Minibatch Loss= 71.3939, Training Accuracy= 0.000\n",
      "Step 778, Minibatch Loss= 50.7970, Training Accuracy= 0.000\n",
      "Step 779, Minibatch Loss= 58.0550, Training Accuracy= 0.000\n",
      "Step 780, Minibatch Loss= 54.9852, Training Accuracy= 0.000\n",
      "Step 781, Minibatch Loss= 46.4511, Training Accuracy= 0.000\n",
      "Step 782, Minibatch Loss= 59.0370, Training Accuracy= 0.000\n",
      "Step 783, Minibatch Loss= 63.9442, Training Accuracy= 0.000\n",
      "Step 784, Minibatch Loss= 61.4318, Training Accuracy= 0.000\n",
      "Step 785, Minibatch Loss= 51.2800, Training Accuracy= 0.000\n",
      "Step 786, Minibatch Loss= 51.4256, Training Accuracy= 0.000\n",
      "Step 787, Minibatch Loss= 53.1387, Training Accuracy= 0.000\n",
      "Step 788, Minibatch Loss= 65.8491, Training Accuracy= 0.000\n",
      "Step 789, Minibatch Loss= 62.6036, Training Accuracy= 0.000\n",
      "Step 790, Minibatch Loss= 56.0390, Training Accuracy= 0.000\n",
      "Step 791, Minibatch Loss= 55.6647, Training Accuracy= 0.000\n",
      "Step 792, Minibatch Loss= 56.0131, Training Accuracy= 0.000\n",
      "Step 793, Minibatch Loss= 56.5879, Training Accuracy= 0.000\n",
      "Step 794, Minibatch Loss= 61.1612, Training Accuracy= 0.000\n",
      "Step 795, Minibatch Loss= 58.3742, Training Accuracy= 0.000\n",
      "Step 796, Minibatch Loss= 61.9167, Training Accuracy= 0.000\n",
      "Step 797, Minibatch Loss= 58.0772, Training Accuracy= 0.000\n",
      "Step 798, Minibatch Loss= 69.1443, Training Accuracy= 0.000\n",
      "Step 799, Minibatch Loss= 61.9760, Training Accuracy= 0.000\n",
      "Step 800, Minibatch Loss= 54.6887, Training Accuracy= 0.000\n",
      "Step 801, Minibatch Loss= 61.3003, Training Accuracy= 0.000\n",
      "Step 802, Minibatch Loss= 60.7089, Training Accuracy= 0.000\n",
      "Step 803, Minibatch Loss= 66.9755, Training Accuracy= 0.000\n",
      "Step 804, Minibatch Loss= 56.5934, Training Accuracy= 0.000\n",
      "Step 805, Minibatch Loss= 59.6423, Training Accuracy= 0.000\n",
      "Step 806, Minibatch Loss= 52.0826, Training Accuracy= 0.000\n",
      "Step 807, Minibatch Loss= 56.9754, Training Accuracy= 0.000\n",
      "Step 808, Minibatch Loss= 49.6832, Training Accuracy= 0.000\n",
      "Step 809, Minibatch Loss= 49.6036, Training Accuracy= 0.000\n",
      "Step 810, Minibatch Loss= 57.8378, Training Accuracy= 0.000\n",
      "Step 811, Minibatch Loss= 60.9402, Training Accuracy= 0.000\n",
      "Step 812, Minibatch Loss= 57.2075, Training Accuracy= 0.000\n",
      "Step 813, Minibatch Loss= 51.9489, Training Accuracy= 0.000\n",
      "Step 814, Minibatch Loss= 55.4091, Training Accuracy= 0.000\n",
      "Step 815, Minibatch Loss= 58.2762, Training Accuracy= 0.000\n",
      "Step 816, Minibatch Loss= 58.0407, Training Accuracy= 0.000\n",
      "Step 817, Minibatch Loss= 53.5991, Training Accuracy= 0.000\n",
      "Step 818, Minibatch Loss= 64.8654, Training Accuracy= 0.000\n",
      "Step 819, Minibatch Loss= 54.8306, Training Accuracy= 0.000\n",
      "Step 820, Minibatch Loss= 59.5256, Training Accuracy= 0.000\n",
      "Step 821, Minibatch Loss= 59.8720, Training Accuracy= 0.000\n",
      "Step 822, Minibatch Loss= 78.5568, Training Accuracy= 0.000\n",
      "Step 823, Minibatch Loss= 77.7243, Training Accuracy= 0.000\n",
      "Step 824, Minibatch Loss= 81.3698, Training Accuracy= 0.000\n",
      "Step 825, Minibatch Loss= 63.0307, Training Accuracy= 0.000\n",
      "Step 826, Minibatch Loss= 53.6486, Training Accuracy= 0.000\n",
      "Step 827, Minibatch Loss= 45.7670, Training Accuracy= 0.000\n",
      "Step 828, Minibatch Loss= 56.9314, Training Accuracy= 0.000\n",
      "Step 829, Minibatch Loss= 66.6912, Training Accuracy= 0.000\n",
      "Step 830, Minibatch Loss= 64.7440, Training Accuracy= 0.000\n",
      "Step 831, Minibatch Loss= 75.4495, Training Accuracy= 0.000\n",
      "Step 832, Minibatch Loss= 98.7427, Training Accuracy= 0.000\n",
      "Step 833, Minibatch Loss= 95.6991, Training Accuracy= 0.000\n",
      "Step 834, Minibatch Loss= 115.7144, Training Accuracy= 0.000\n",
      "Step 835, Minibatch Loss= 88.7905, Training Accuracy= 0.000\n",
      "Step 836, Minibatch Loss= 82.6084, Training Accuracy= 0.000\n",
      "Step 837, Minibatch Loss= 56.4316, Training Accuracy= 0.000\n",
      "Step 838, Minibatch Loss= 68.6944, Training Accuracy= 0.000\n",
      "Step 839, Minibatch Loss= 70.7623, Training Accuracy= 0.000\n",
      "Step 840, Minibatch Loss= 84.6329, Training Accuracy= 0.000\n",
      "Step 841, Minibatch Loss= 88.7939, Training Accuracy= 0.000\n",
      "Step 842, Minibatch Loss= 110.0561, Training Accuracy= 0.000\n",
      "Step 843, Minibatch Loss= 80.5091, Training Accuracy= 0.000\n",
      "Step 844, Minibatch Loss= 70.0904, Training Accuracy= 0.000\n",
      "Step 845, Minibatch Loss= 60.8307, Training Accuracy= 0.000\n",
      "Step 846, Minibatch Loss= 65.3422, Training Accuracy= 0.000\n",
      "Step 847, Minibatch Loss= 74.9880, Training Accuracy= 0.000\n",
      "Step 848, Minibatch Loss= 79.1182, Training Accuracy= 0.000\n",
      "Step 849, Minibatch Loss= 77.8220, Training Accuracy= 0.000\n",
      "Step 850, Minibatch Loss= 62.1236, Training Accuracy= 0.000\n",
      "Step 851, Minibatch Loss= 53.9208, Training Accuracy= 0.000\n",
      "Step 852, Minibatch Loss= 61.9526, Training Accuracy= 0.000\n",
      "Step 853, Minibatch Loss= 78.7538, Training Accuracy= 0.000\n",
      "Step 854, Minibatch Loss= 75.6810, Training Accuracy= 0.000\n",
      "Step 855, Minibatch Loss= 71.8373, Training Accuracy= 0.000\n",
      "Step 856, Minibatch Loss= 53.0415, Training Accuracy= 0.000\n",
      "Step 857, Minibatch Loss= 49.2486, Training Accuracy= 0.000\n",
      "Step 858, Minibatch Loss= 81.9959, Training Accuracy= 0.000\n",
      "Step 859, Minibatch Loss= 136.5821, Training Accuracy= 0.000\n",
      "Step 860, Minibatch Loss= 91.3662, Training Accuracy= 0.000\n",
      "Step 861, Minibatch Loss= 68.4319, Training Accuracy= 0.000\n",
      "Step 862, Minibatch Loss= 44.7466, Training Accuracy= 0.000\n",
      "Step 863, Minibatch Loss= 69.9876, Training Accuracy= 0.000\n",
      "Step 864, Minibatch Loss= 81.9505, Training Accuracy= 0.000\n",
      "Step 865, Minibatch Loss= 78.0893, Training Accuracy= 0.000\n",
      "Step 866, Minibatch Loss= 82.7113, Training Accuracy= 0.000\n",
      "Step 867, Minibatch Loss= 60.6755, Training Accuracy= 0.000\n",
      "Step 868, Minibatch Loss= 56.8394, Training Accuracy= 0.000\n",
      "Step 869, Minibatch Loss= 57.7217, Training Accuracy= 0.000\n",
      "Step 870, Minibatch Loss= 81.8563, Training Accuracy= 0.000\n",
      "Step 871, Minibatch Loss= 62.1396, Training Accuracy= 0.000\n",
      "Step 872, Minibatch Loss= 52.0382, Training Accuracy= 0.000\n",
      "Step 873, Minibatch Loss= 54.4678, Training Accuracy= 0.000\n",
      "Step 874, Minibatch Loss= 67.8063, Training Accuracy= 0.000\n",
      "Step 875, Minibatch Loss= 62.0296, Training Accuracy= 0.000\n",
      "Step 876, Minibatch Loss= 52.3044, Training Accuracy= 0.000\n",
      "Step 877, Minibatch Loss= 45.7352, Training Accuracy= 0.000\n",
      "Step 878, Minibatch Loss= 54.4567, Training Accuracy= 0.000\n",
      "Step 879, Minibatch Loss= 50.8606, Training Accuracy= 0.000\n",
      "Step 880, Minibatch Loss= 48.4319, Training Accuracy= 0.000\n",
      "Step 881, Minibatch Loss= 46.8139, Training Accuracy= 0.000\n",
      "Step 882, Minibatch Loss= 59.4273, Training Accuracy= 0.000\n",
      "Step 883, Minibatch Loss= 76.1350, Training Accuracy= 0.000\n",
      "Step 884, Minibatch Loss= 85.8830, Training Accuracy= 0.000\n",
      "Step 885, Minibatch Loss= 77.9940, Training Accuracy= 0.000\n",
      "Step 886, Minibatch Loss= 63.0294, Training Accuracy= 0.000\n",
      "Step 887, Minibatch Loss= 56.0952, Training Accuracy= 0.000\n",
      "Step 888, Minibatch Loss= 50.6803, Training Accuracy= 0.000\n",
      "Step 889, Minibatch Loss= 58.1285, Training Accuracy= 0.000\n",
      "Step 890, Minibatch Loss= 50.3959, Training Accuracy= 0.000\n",
      "Step 891, Minibatch Loss= 52.8249, Training Accuracy= 0.000\n",
      "Step 892, Minibatch Loss= 71.5958, Training Accuracy= 0.000\n",
      "Step 893, Minibatch Loss= 74.6382, Training Accuracy= 0.000\n",
      "Step 894, Minibatch Loss= 74.7884, Training Accuracy= 0.000\n",
      "Step 895, Minibatch Loss= 92.4620, Training Accuracy= 0.000\n",
      "Step 896, Minibatch Loss= 102.8483, Training Accuracy= 0.000\n",
      "Step 897, Minibatch Loss= 111.5966, Training Accuracy= 0.000\n",
      "Step 898, Minibatch Loss= 102.3708, Training Accuracy= 0.000\n",
      "Step 899, Minibatch Loss= 73.3304, Training Accuracy= 0.000\n",
      "Step 900, Minibatch Loss= 71.2593, Training Accuracy= 0.000\n",
      "Step 901, Minibatch Loss= 71.0154, Training Accuracy= 0.000\n",
      "Step 902, Minibatch Loss= 52.8893, Training Accuracy= 0.000\n",
      "Step 903, Minibatch Loss= 43.2225, Training Accuracy= 0.000\n",
      "Step 904, Minibatch Loss= 48.2044, Training Accuracy= 0.000\n",
      "Step 905, Minibatch Loss= 47.0249, Training Accuracy= 0.000\n",
      "Step 906, Minibatch Loss= 58.8244, Training Accuracy= 0.000\n",
      "Step 907, Minibatch Loss= 60.3992, Training Accuracy= 0.000\n",
      "Step 908, Minibatch Loss= 42.8739, Training Accuracy= 0.000\n",
      "Step 909, Minibatch Loss= 44.5095, Training Accuracy= 0.000\n",
      "Step 910, Minibatch Loss= 52.4233, Training Accuracy= 0.000\n",
      "Step 911, Minibatch Loss= 52.5541, Training Accuracy= 0.000\n",
      "Step 912, Minibatch Loss= 52.5580, Training Accuracy= 0.000\n",
      "Step 913, Minibatch Loss= 50.2693, Training Accuracy= 0.000\n",
      "Step 914, Minibatch Loss= 46.3092, Training Accuracy= 0.000\n",
      "Step 915, Minibatch Loss= 43.9965, Training Accuracy= 0.000\n",
      "Step 916, Minibatch Loss= 50.8820, Training Accuracy= 0.000\n",
      "Step 917, Minibatch Loss= 45.7355, Training Accuracy= 0.000\n",
      "Step 918, Minibatch Loss= 43.5405, Training Accuracy= 0.000\n",
      "Step 919, Minibatch Loss= 53.5749, Training Accuracy= 0.000\n",
      "Step 920, Minibatch Loss= 40.7670, Training Accuracy= 0.000\n",
      "Step 921, Minibatch Loss= 60.1541, Training Accuracy= 0.000\n",
      "Step 922, Minibatch Loss= 44.0550, Training Accuracy= 0.000\n",
      "Step 923, Minibatch Loss= 66.1686, Training Accuracy= 0.000\n",
      "Step 924, Minibatch Loss= 46.1384, Training Accuracy= 0.000\n",
      "Step 925, Minibatch Loss= 51.4545, Training Accuracy= 0.000\n",
      "Step 926, Minibatch Loss= 46.6083, Training Accuracy= 0.000\n",
      "Step 927, Minibatch Loss= 53.2058, Training Accuracy= 0.000\n",
      "Step 928, Minibatch Loss= 57.9773, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 929, Minibatch Loss= 55.6336, Training Accuracy= 0.000\n",
      "Step 930, Minibatch Loss= 50.5066, Training Accuracy= 0.000\n",
      "Step 931, Minibatch Loss= 52.8960, Training Accuracy= 0.000\n",
      "Step 932, Minibatch Loss= 51.1858, Training Accuracy= 0.000\n",
      "Step 933, Minibatch Loss= 59.7612, Training Accuracy= 0.000\n",
      "Step 934, Minibatch Loss= 43.8390, Training Accuracy= 0.000\n",
      "Step 935, Minibatch Loss= 52.8823, Training Accuracy= 0.000\n",
      "Step 936, Minibatch Loss= 58.9829, Training Accuracy= 0.000\n",
      "Step 937, Minibatch Loss= 47.8777, Training Accuracy= 0.000\n",
      "Step 938, Minibatch Loss= 49.9984, Training Accuracy= 0.000\n",
      "Step 939, Minibatch Loss= 40.2255, Training Accuracy= 0.000\n",
      "Step 940, Minibatch Loss= 48.3747, Training Accuracy= 0.000\n",
      "Step 941, Minibatch Loss= 43.3058, Training Accuracy= 0.000\n",
      "Step 942, Minibatch Loss= 52.9349, Training Accuracy= 0.000\n",
      "Step 943, Minibatch Loss= 47.7291, Training Accuracy= 0.000\n",
      "Step 944, Minibatch Loss= 51.2612, Training Accuracy= 0.000\n",
      "Step 945, Minibatch Loss= 50.8411, Training Accuracy= 0.000\n",
      "Step 946, Minibatch Loss= 60.3179, Training Accuracy= 0.000\n",
      "Step 947, Minibatch Loss= 44.0973, Training Accuracy= 0.000\n",
      "Step 948, Minibatch Loss= 52.7652, Training Accuracy= 0.000\n",
      "Step 949, Minibatch Loss= 51.1908, Training Accuracy= 0.000\n",
      "Step 950, Minibatch Loss= 55.7954, Training Accuracy= 0.000\n",
      "Step 951, Minibatch Loss= 47.2813, Training Accuracy= 0.000\n",
      "Step 952, Minibatch Loss= 53.5218, Training Accuracy= 0.000\n",
      "Step 953, Minibatch Loss= 50.2727, Training Accuracy= 0.000\n",
      "Step 954, Minibatch Loss= 41.7484, Training Accuracy= 0.000\n",
      "Step 955, Minibatch Loss= 38.5840, Training Accuracy= 0.000\n",
      "Step 956, Minibatch Loss= 47.7943, Training Accuracy= 0.000\n",
      "Step 957, Minibatch Loss= 56.6147, Training Accuracy= 0.000\n",
      "Step 958, Minibatch Loss= 53.4813, Training Accuracy= 0.000\n",
      "Step 959, Minibatch Loss= 56.5373, Training Accuracy= 0.000\n",
      "Step 960, Minibatch Loss= 55.2048, Training Accuracy= 0.000\n",
      "Step 961, Minibatch Loss= 57.3228, Training Accuracy= 0.000\n",
      "Step 962, Minibatch Loss= 51.3001, Training Accuracy= 0.000\n",
      "Step 963, Minibatch Loss= 58.2196, Training Accuracy= 0.000\n",
      "Step 964, Minibatch Loss= 59.0839, Training Accuracy= 0.000\n",
      "Step 965, Minibatch Loss= 50.2238, Training Accuracy= 0.000\n",
      "Step 966, Minibatch Loss= 56.1768, Training Accuracy= 0.000\n",
      "Step 967, Minibatch Loss= 55.1674, Training Accuracy= 0.000\n",
      "Step 968, Minibatch Loss= 70.2953, Training Accuracy= 0.000\n",
      "Step 969, Minibatch Loss= 64.4080, Training Accuracy= 0.000\n",
      "Step 970, Minibatch Loss= 72.4777, Training Accuracy= 0.000\n",
      "Step 971, Minibatch Loss= 85.1301, Training Accuracy= 0.000\n",
      "Step 972, Minibatch Loss= 90.5816, Training Accuracy= 0.000\n",
      "Step 973, Minibatch Loss= 92.5254, Training Accuracy= 0.000\n",
      "Step 974, Minibatch Loss= 90.5565, Training Accuracy= 0.000\n",
      "Step 975, Minibatch Loss= 95.9805, Training Accuracy= 0.000\n",
      "Step 976, Minibatch Loss= 91.0821, Training Accuracy= 0.000\n",
      "Step 977, Minibatch Loss= 71.5283, Training Accuracy= 0.000\n",
      "Step 978, Minibatch Loss= 51.7588, Training Accuracy= 0.000\n",
      "Step 979, Minibatch Loss= 43.9333, Training Accuracy= 0.000\n",
      "Step 980, Minibatch Loss= 73.1496, Training Accuracy= 0.000\n",
      "Step 981, Minibatch Loss= 92.6117, Training Accuracy= 0.000\n",
      "Step 982, Minibatch Loss= 92.5184, Training Accuracy= 0.000\n",
      "Step 983, Minibatch Loss= 129.9496, Training Accuracy= 0.000\n",
      "Step 984, Minibatch Loss= 89.1881, Training Accuracy= 0.000\n",
      "Step 985, Minibatch Loss= 50.7401, Training Accuracy= 0.000\n",
      "Step 986, Minibatch Loss= 50.4902, Training Accuracy= 0.000\n",
      "Step 987, Minibatch Loss= 90.8734, Training Accuracy= 0.000\n",
      "Step 988, Minibatch Loss= 142.7399, Training Accuracy= 0.000\n",
      "Step 989, Minibatch Loss= 130.0402, Training Accuracy= 0.000\n",
      "Step 990, Minibatch Loss= 95.0096, Training Accuracy= 0.000\n",
      "Step 991, Minibatch Loss= 56.6211, Training Accuracy= 0.000\n",
      "Step 992, Minibatch Loss= 69.2607, Training Accuracy= 0.000\n",
      "Step 993, Minibatch Loss= 99.1066, Training Accuracy= 0.000\n",
      "Step 994, Minibatch Loss= 70.7299, Training Accuracy= 0.000\n",
      "Step 995, Minibatch Loss= 47.5644, Training Accuracy= 0.000\n",
      "Step 996, Minibatch Loss= 77.6429, Training Accuracy= 0.000\n",
      "Step 997, Minibatch Loss= 102.7663, Training Accuracy= 0.000\n",
      "Step 998, Minibatch Loss= 71.3561, Training Accuracy= 0.000\n",
      "Step 999, Minibatch Loss= 47.3771, Training Accuracy= 0.000\n",
      "Step 1000, Minibatch Loss= 81.3575, Training Accuracy= 0.000\n",
      "Step 1001, Minibatch Loss= 70.7612, Training Accuracy= 0.000\n",
      "Step 1002, Minibatch Loss= 52.2931, Training Accuracy= 0.000\n",
      "Step 1003, Minibatch Loss= 65.2657, Training Accuracy= 0.000\n",
      "Step 1004, Minibatch Loss= 82.0789, Training Accuracy= 0.000\n",
      "Step 1005, Minibatch Loss= 58.3624, Training Accuracy= 0.000\n",
      "Step 1006, Minibatch Loss= 48.3301, Training Accuracy= 0.000\n",
      "Step 1007, Minibatch Loss= 73.1288, Training Accuracy= 0.000\n",
      "Step 1008, Minibatch Loss= 63.1584, Training Accuracy= 0.000\n",
      "Step 1009, Minibatch Loss= 53.4930, Training Accuracy= 0.000\n",
      "Step 1010, Minibatch Loss= 55.5778, Training Accuracy= 0.000\n",
      "Step 1011, Minibatch Loss= 53.8930, Training Accuracy= 0.000\n",
      "Step 1012, Minibatch Loss= 52.1710, Training Accuracy= 0.000\n",
      "Step 1013, Minibatch Loss= 52.6438, Training Accuracy= 0.000\n",
      "Step 1014, Minibatch Loss= 73.7358, Training Accuracy= 0.000\n",
      "Step 1015, Minibatch Loss= 63.3854, Training Accuracy= 0.000\n",
      "Step 1016, Minibatch Loss= 57.1739, Training Accuracy= 0.000\n",
      "Step 1017, Minibatch Loss= 59.1396, Training Accuracy= 0.000\n",
      "Step 1018, Minibatch Loss= 44.4347, Training Accuracy= 0.000\n",
      "Step 1019, Minibatch Loss= 47.2066, Training Accuracy= 0.000\n",
      "Step 1020, Minibatch Loss= 62.1333, Training Accuracy= 0.000\n",
      "Step 1021, Minibatch Loss= 52.5148, Training Accuracy= 0.000\n",
      "Step 1022, Minibatch Loss= 46.6546, Training Accuracy= 0.000\n",
      "Step 1023, Minibatch Loss= 56.4823, Training Accuracy= 0.000\n",
      "Step 1024, Minibatch Loss= 56.4702, Training Accuracy= 0.000\n",
      "Step 1025, Minibatch Loss= 52.6225, Training Accuracy= 0.000\n",
      "Step 1026, Minibatch Loss= 73.6294, Training Accuracy= 0.000\n",
      "Step 1027, Minibatch Loss= 70.2593, Training Accuracy= 0.000\n",
      "Step 1028, Minibatch Loss= 81.3348, Training Accuracy= 0.000\n",
      "Step 1029, Minibatch Loss= 95.8067, Training Accuracy= 0.000\n",
      "Step 1030, Minibatch Loss= 135.6313, Training Accuracy= 0.000\n",
      "Step 1031, Minibatch Loss= 131.7949, Training Accuracy= 0.000\n",
      "Step 1032, Minibatch Loss= 90.8075, Training Accuracy= 0.000\n",
      "Step 1033, Minibatch Loss= 72.6031, Training Accuracy= 0.000\n",
      "Step 1034, Minibatch Loss= 62.8685, Training Accuracy= 0.000\n",
      "Step 1035, Minibatch Loss= 55.9514, Training Accuracy= 0.000\n",
      "Step 1036, Minibatch Loss= 51.1995, Training Accuracy= 0.000\n",
      "Step 1037, Minibatch Loss= 38.4761, Training Accuracy= 0.000\n",
      "Step 1038, Minibatch Loss= 43.0432, Training Accuracy= 0.000\n",
      "Step 1039, Minibatch Loss= 53.3899, Training Accuracy= 0.000\n",
      "Step 1040, Minibatch Loss= 67.7953, Training Accuracy= 0.000\n",
      "Step 1041, Minibatch Loss= 75.5026, Training Accuracy= 0.000\n",
      "Step 1042, Minibatch Loss= 51.3925, Training Accuracy= 0.000\n",
      "Step 1043, Minibatch Loss= 36.7311, Training Accuracy= 0.000\n",
      "Step 1044, Minibatch Loss= 44.9788, Training Accuracy= 0.000\n",
      "Step 1045, Minibatch Loss= 49.1047, Training Accuracy= 0.000\n",
      "Step 1046, Minibatch Loss= 41.3929, Training Accuracy= 0.000\n",
      "Step 1047, Minibatch Loss= 42.7108, Training Accuracy= 0.000\n",
      "Step 1048, Minibatch Loss= 49.0485, Training Accuracy= 0.000\n",
      "Step 1049, Minibatch Loss= 45.8811, Training Accuracy= 0.000\n",
      "Step 1050, Minibatch Loss= 40.0862, Training Accuracy= 0.000\n",
      "Step 1051, Minibatch Loss= 36.5955, Training Accuracy= 0.000\n",
      "Step 1052, Minibatch Loss= 39.9295, Training Accuracy= 0.000\n",
      "Step 1053, Minibatch Loss= 39.6721, Training Accuracy= 0.000\n",
      "Step 1054, Minibatch Loss= 39.0965, Training Accuracy= 0.000\n",
      "Step 1055, Minibatch Loss= 48.2903, Training Accuracy= 0.000\n",
      "Step 1056, Minibatch Loss= 45.7032, Training Accuracy= 0.000\n",
      "Step 1057, Minibatch Loss= 37.7084, Training Accuracy= 0.000\n",
      "Step 1058, Minibatch Loss= 39.1463, Training Accuracy= 0.000\n",
      "Step 1059, Minibatch Loss= 43.3464, Training Accuracy= 0.000\n",
      "Step 1060, Minibatch Loss= 48.8240, Training Accuracy= 0.000\n",
      "Step 1061, Minibatch Loss= 42.7368, Training Accuracy= 0.000\n",
      "Step 1062, Minibatch Loss= 38.3135, Training Accuracy= 0.000\n",
      "Step 1063, Minibatch Loss= 42.1780, Training Accuracy= 0.000\n",
      "Step 1064, Minibatch Loss= 38.9862, Training Accuracy= 0.000\n",
      "Step 1065, Minibatch Loss= 43.5916, Training Accuracy= 0.000\n",
      "Step 1066, Minibatch Loss= 42.5252, Training Accuracy= 0.000\n",
      "Step 1067, Minibatch Loss= 41.6484, Training Accuracy= 0.000\n",
      "Step 1068, Minibatch Loss= 50.2512, Training Accuracy= 0.000\n",
      "Step 1069, Minibatch Loss= 48.5367, Training Accuracy= 0.000\n",
      "Step 1070, Minibatch Loss= 56.0709, Training Accuracy= 0.000\n",
      "Step 1071, Minibatch Loss= 60.5844, Training Accuracy= 0.000\n",
      "Step 1072, Minibatch Loss= 59.6917, Training Accuracy= 0.000\n",
      "Step 1073, Minibatch Loss= 56.1245, Training Accuracy= 0.000\n",
      "Step 1074, Minibatch Loss= 42.0904, Training Accuracy= 0.000\n",
      "Step 1075, Minibatch Loss= 38.5752, Training Accuracy= 0.000\n",
      "Step 1076, Minibatch Loss= 42.7593, Training Accuracy= 0.000\n",
      "Step 1077, Minibatch Loss= 58.3947, Training Accuracy= 0.000\n",
      "Step 1078, Minibatch Loss= 73.3895, Training Accuracy= 0.000\n",
      "Step 1079, Minibatch Loss= 76.0033, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1080, Minibatch Loss= 66.9394, Training Accuracy= 0.000\n",
      "Step 1081, Minibatch Loss= 52.1259, Training Accuracy= 0.000\n",
      "Step 1082, Minibatch Loss= 47.7009, Training Accuracy= 0.000\n",
      "Step 1083, Minibatch Loss= 37.9064, Training Accuracy= 0.000\n",
      "Step 1084, Minibatch Loss= 39.1143, Training Accuracy= 0.000\n",
      "Step 1085, Minibatch Loss= 38.9695, Training Accuracy= 0.000\n",
      "Step 1086, Minibatch Loss= 54.3705, Training Accuracy= 0.000\n",
      "Step 1087, Minibatch Loss= 55.2514, Training Accuracy= 0.000\n",
      "Step 1088, Minibatch Loss= 61.9274, Training Accuracy= 0.000\n",
      "Step 1089, Minibatch Loss= 62.2152, Training Accuracy= 0.000\n",
      "Step 1090, Minibatch Loss= 40.1978, Training Accuracy= 0.000\n",
      "Step 1091, Minibatch Loss= 36.0982, Training Accuracy= 0.000\n",
      "Step 1092, Minibatch Loss= 36.5413, Training Accuracy= 0.000\n",
      "Step 1093, Minibatch Loss= 53.7896, Training Accuracy= 0.000\n",
      "Step 1094, Minibatch Loss= 65.4634, Training Accuracy= 0.000\n",
      "Step 1095, Minibatch Loss= 55.6063, Training Accuracy= 0.000\n",
      "Step 1096, Minibatch Loss= 47.1744, Training Accuracy= 0.000\n",
      "Step 1097, Minibatch Loss= 40.6957, Training Accuracy= 0.000\n",
      "Step 1098, Minibatch Loss= 35.1546, Training Accuracy= 0.000\n",
      "Step 1099, Minibatch Loss= 36.6167, Training Accuracy= 0.000\n",
      "Step 1100, Minibatch Loss= 38.9085, Training Accuracy= 0.000\n",
      "Step 1101, Minibatch Loss= 38.6214, Training Accuracy= 0.000\n",
      "Step 1102, Minibatch Loss= 41.4430, Training Accuracy= 0.000\n",
      "Step 1103, Minibatch Loss= 58.8085, Training Accuracy= 0.000\n",
      "Step 1104, Minibatch Loss= 43.0097, Training Accuracy= 0.000\n",
      "Step 1105, Minibatch Loss= 41.3362, Training Accuracy= 0.000\n",
      "Step 1106, Minibatch Loss= 38.6149, Training Accuracy= 0.000\n",
      "Step 1107, Minibatch Loss= 43.1832, Training Accuracy= 0.000\n",
      "Step 1108, Minibatch Loss= 39.1420, Training Accuracy= 0.000\n",
      "Step 1109, Minibatch Loss= 41.6543, Training Accuracy= 0.000\n",
      "Step 1110, Minibatch Loss= 37.4420, Training Accuracy= 0.000\n",
      "Step 1111, Minibatch Loss= 36.1674, Training Accuracy= 0.000\n",
      "Step 1112, Minibatch Loss= 37.5606, Training Accuracy= 0.000\n",
      "Step 1113, Minibatch Loss= 34.2786, Training Accuracy= 0.000\n",
      "Step 1114, Minibatch Loss= 38.8019, Training Accuracy= 0.000\n",
      "Step 1115, Minibatch Loss= 39.8788, Training Accuracy= 0.000\n",
      "Step 1116, Minibatch Loss= 36.2568, Training Accuracy= 0.000\n",
      "Step 1117, Minibatch Loss= 36.3196, Training Accuracy= 0.000\n",
      "Step 1118, Minibatch Loss= 35.0517, Training Accuracy= 0.000\n",
      "Step 1119, Minibatch Loss= 40.3078, Training Accuracy= 0.000\n",
      "Step 1120, Minibatch Loss= 32.0712, Training Accuracy= 0.000\n",
      "Step 1121, Minibatch Loss= 44.4502, Training Accuracy= 0.000\n",
      "Step 1122, Minibatch Loss= 44.5283, Training Accuracy= 0.000\n",
      "Step 1123, Minibatch Loss= 38.6397, Training Accuracy= 0.000\n",
      "Step 1124, Minibatch Loss= 32.1940, Training Accuracy= 0.000\n",
      "Step 1125, Minibatch Loss= 32.4171, Training Accuracy= 0.000\n",
      "Step 1126, Minibatch Loss= 35.1110, Training Accuracy= 0.000\n",
      "Step 1127, Minibatch Loss= 39.9601, Training Accuracy= 0.000\n",
      "Step 1128, Minibatch Loss= 34.7523, Training Accuracy= 0.000\n",
      "Step 1129, Minibatch Loss= 36.8824, Training Accuracy= 0.000\n",
      "Step 1130, Minibatch Loss= 42.1746, Training Accuracy= 0.000\n",
      "Step 1131, Minibatch Loss= 35.6245, Training Accuracy= 0.000\n",
      "Step 1132, Minibatch Loss= 38.1865, Training Accuracy= 0.000\n",
      "Step 1133, Minibatch Loss= 35.5122, Training Accuracy= 0.000\n",
      "Step 1134, Minibatch Loss= 39.9451, Training Accuracy= 0.000\n",
      "Step 1135, Minibatch Loss= 44.6569, Training Accuracy= 0.000\n",
      "Step 1136, Minibatch Loss= 46.8203, Training Accuracy= 0.000\n",
      "Step 1137, Minibatch Loss= 34.7604, Training Accuracy= 0.000\n",
      "Step 1138, Minibatch Loss= 32.6534, Training Accuracy= 0.000\n",
      "Step 1139, Minibatch Loss= 43.5229, Training Accuracy= 0.000\n",
      "Step 1140, Minibatch Loss= 46.0653, Training Accuracy= 0.000\n",
      "Step 1141, Minibatch Loss= 53.0008, Training Accuracy= 0.000\n",
      "Step 1142, Minibatch Loss= 57.4417, Training Accuracy= 0.000\n",
      "Step 1143, Minibatch Loss= 85.0692, Training Accuracy= 0.000\n",
      "Step 1144, Minibatch Loss= 98.1066, Training Accuracy= 0.000\n",
      "Step 1145, Minibatch Loss= 136.2556, Training Accuracy= 0.000\n",
      "Step 1146, Minibatch Loss= 103.5993, Training Accuracy= 0.000\n",
      "Step 1147, Minibatch Loss= 146.0094, Training Accuracy= 0.000\n",
      "Step 1148, Minibatch Loss= 154.4496, Training Accuracy= 0.000\n",
      "Step 1149, Minibatch Loss= 157.1014, Training Accuracy= 0.000\n",
      "Step 1150, Minibatch Loss= 80.2675, Training Accuracy= 0.000\n",
      "Step 1151, Minibatch Loss= 41.9419, Training Accuracy= 0.000\n",
      "Step 1152, Minibatch Loss= 40.4541, Training Accuracy= 0.000\n",
      "Step 1153, Minibatch Loss= 58.2956, Training Accuracy= 0.000\n",
      "Step 1154, Minibatch Loss= 59.1209, Training Accuracy= 0.000\n",
      "Step 1155, Minibatch Loss= 39.7155, Training Accuracy= 0.000\n",
      "Step 1156, Minibatch Loss= 34.9980, Training Accuracy= 0.000\n",
      "Step 1157, Minibatch Loss= 44.2526, Training Accuracy= 0.000\n",
      "Step 1158, Minibatch Loss= 53.7529, Training Accuracy= 0.000\n",
      "Step 1159, Minibatch Loss= 42.2551, Training Accuracy= 0.000\n",
      "Step 1160, Minibatch Loss= 39.4465, Training Accuracy= 0.000\n",
      "Step 1161, Minibatch Loss= 41.1050, Training Accuracy= 0.000\n",
      "Step 1162, Minibatch Loss= 50.1038, Training Accuracy= 0.000\n",
      "Step 1163, Minibatch Loss= 38.2903, Training Accuracy= 0.000\n",
      "Step 1164, Minibatch Loss= 36.2728, Training Accuracy= 0.000\n",
      "Step 1165, Minibatch Loss= 37.4937, Training Accuracy= 0.000\n",
      "Step 1166, Minibatch Loss= 36.2359, Training Accuracy= 0.000\n",
      "Step 1167, Minibatch Loss= 34.8577, Training Accuracy= 0.000\n",
      "Step 1168, Minibatch Loss= 35.4261, Training Accuracy= 0.000\n",
      "Step 1169, Minibatch Loss= 35.7001, Training Accuracy= 0.000\n",
      "Step 1170, Minibatch Loss= 40.9541, Training Accuracy= 0.000\n",
      "Step 1171, Minibatch Loss= 41.7656, Training Accuracy= 0.000\n",
      "Step 1172, Minibatch Loss= 42.0714, Training Accuracy= 0.000\n",
      "Step 1173, Minibatch Loss= 50.5170, Training Accuracy= 0.000\n",
      "Step 1174, Minibatch Loss= 50.7869, Training Accuracy= 0.000\n",
      "Step 1175, Minibatch Loss= 42.9666, Training Accuracy= 0.000\n",
      "Step 1176, Minibatch Loss= 40.2658, Training Accuracy= 0.000\n",
      "Step 1177, Minibatch Loss= 40.3516, Training Accuracy= 0.000\n",
      "Step 1178, Minibatch Loss= 43.3229, Training Accuracy= 0.000\n",
      "Step 1179, Minibatch Loss= 36.8197, Training Accuracy= 0.000\n",
      "Step 1180, Minibatch Loss= 34.5482, Training Accuracy= 0.000\n",
      "Step 1181, Minibatch Loss= 35.4766, Training Accuracy= 0.000\n",
      "Step 1182, Minibatch Loss= 35.9648, Training Accuracy= 0.000\n",
      "Step 1183, Minibatch Loss= 40.1419, Training Accuracy= 0.000\n",
      "Step 1184, Minibatch Loss= 39.0149, Training Accuracy= 0.000\n",
      "Step 1185, Minibatch Loss= 34.7111, Training Accuracy= 0.000\n",
      "Step 1186, Minibatch Loss= 34.0463, Training Accuracy= 0.000\n",
      "Step 1187, Minibatch Loss= 33.5208, Training Accuracy= 0.000\n",
      "Step 1188, Minibatch Loss= 28.4450, Training Accuracy= 0.000\n",
      "Step 1189, Minibatch Loss= 29.0360, Training Accuracy= 0.000\n",
      "Step 1190, Minibatch Loss= 39.2126, Training Accuracy= 0.000\n",
      "Step 1191, Minibatch Loss= 37.8159, Training Accuracy= 0.000\n",
      "Step 1192, Minibatch Loss= 36.7061, Training Accuracy= 0.000\n",
      "Step 1193, Minibatch Loss= 36.8570, Training Accuracy= 0.000\n",
      "Step 1194, Minibatch Loss= 30.7402, Training Accuracy= 0.000\n",
      "Step 1195, Minibatch Loss= 30.6008, Training Accuracy= 0.000\n",
      "Step 1196, Minibatch Loss= 33.9833, Training Accuracy= 0.000\n",
      "Step 1197, Minibatch Loss= 39.7749, Training Accuracy= 0.000\n",
      "Step 1198, Minibatch Loss= 39.2558, Training Accuracy= 0.000\n",
      "Step 1199, Minibatch Loss= 37.2219, Training Accuracy= 0.000\n",
      "Step 1200, Minibatch Loss= 41.3850, Training Accuracy= 0.000\n",
      "Step 1201, Minibatch Loss= 44.0220, Training Accuracy= 0.000\n",
      "Step 1202, Minibatch Loss= 45.5776, Training Accuracy= 0.000\n",
      "Step 1203, Minibatch Loss= 46.3331, Training Accuracy= 0.000\n",
      "Step 1204, Minibatch Loss= 62.8315, Training Accuracy= 0.000\n",
      "Step 1205, Minibatch Loss= 65.7273, Training Accuracy= 0.000\n",
      "Step 1206, Minibatch Loss= 53.4979, Training Accuracy= 0.000\n",
      "Step 1207, Minibatch Loss= 64.0416, Training Accuracy= 0.000\n",
      "Step 1208, Minibatch Loss= 58.7647, Training Accuracy= 0.000\n",
      "Step 1209, Minibatch Loss= 63.1503, Training Accuracy= 0.000\n",
      "Step 1210, Minibatch Loss= 44.6789, Training Accuracy= 0.000\n",
      "Step 1211, Minibatch Loss= 45.6501, Training Accuracy= 0.000\n",
      "Step 1212, Minibatch Loss= 33.5309, Training Accuracy= 0.000\n",
      "Step 1213, Minibatch Loss= 43.6256, Training Accuracy= 0.000\n",
      "Step 1214, Minibatch Loss= 37.5652, Training Accuracy= 0.000\n",
      "Step 1215, Minibatch Loss= 44.8164, Training Accuracy= 0.000\n",
      "Step 1216, Minibatch Loss= 36.7868, Training Accuracy= 0.000\n",
      "Step 1217, Minibatch Loss= 32.5977, Training Accuracy= 0.000\n",
      "Step 1218, Minibatch Loss= 34.3928, Training Accuracy= 0.000\n",
      "Step 1219, Minibatch Loss= 37.5498, Training Accuracy= 0.000\n",
      "Step 1220, Minibatch Loss= 40.5472, Training Accuracy= 0.000\n",
      "Step 1221, Minibatch Loss= 34.6913, Training Accuracy= 0.000\n",
      "Step 1222, Minibatch Loss= 29.4600, Training Accuracy= 0.000\n",
      "Step 1223, Minibatch Loss= 42.2967, Training Accuracy= 0.000\n",
      "Step 1224, Minibatch Loss= 42.9081, Training Accuracy= 0.000\n",
      "Step 1225, Minibatch Loss= 51.3144, Training Accuracy= 0.000\n",
      "Step 1226, Minibatch Loss= 49.3387, Training Accuracy= 0.000\n",
      "Step 1227, Minibatch Loss= 36.5975, Training Accuracy= 0.000\n",
      "Step 1228, Minibatch Loss= 29.4104, Training Accuracy= 0.000\n",
      "Step 1229, Minibatch Loss= 34.0418, Training Accuracy= 0.000\n",
      "Step 1230, Minibatch Loss= 32.8387, Training Accuracy= 0.000\n",
      "Step 1231, Minibatch Loss= 33.9569, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1232, Minibatch Loss= 44.7274, Training Accuracy= 0.000\n",
      "Step 1233, Minibatch Loss= 68.8507, Training Accuracy= 0.000\n",
      "Step 1234, Minibatch Loss= 81.1390, Training Accuracy= 0.000\n",
      "Step 1235, Minibatch Loss= 76.1014, Training Accuracy= 0.000\n",
      "Step 1236, Minibatch Loss= 55.8044, Training Accuracy= 0.000\n",
      "Step 1237, Minibatch Loss= 35.0928, Training Accuracy= 0.000\n",
      "Step 1238, Minibatch Loss= 35.1341, Training Accuracy= 0.000\n",
      "Step 1239, Minibatch Loss= 52.5130, Training Accuracy= 0.000\n",
      "Step 1240, Minibatch Loss= 53.3176, Training Accuracy= 0.000\n",
      "Step 1241, Minibatch Loss= 43.6134, Training Accuracy= 0.000\n",
      "Step 1242, Minibatch Loss= 32.9763, Training Accuracy= 0.000\n",
      "Step 1243, Minibatch Loss= 29.5840, Training Accuracy= 0.000\n",
      "Step 1244, Minibatch Loss= 33.6999, Training Accuracy= 0.000\n",
      "Step 1245, Minibatch Loss= 41.9730, Training Accuracy= 0.000\n",
      "Step 1246, Minibatch Loss= 46.3674, Training Accuracy= 0.000\n",
      "Step 1247, Minibatch Loss= 43.8422, Training Accuracy= 0.000\n",
      "Step 1248, Minibatch Loss= 33.4578, Training Accuracy= 0.000\n",
      "Step 1249, Minibatch Loss= 31.9080, Training Accuracy= 0.000\n",
      "Step 1250, Minibatch Loss= 43.6230, Training Accuracy= 0.000\n",
      "Step 1251, Minibatch Loss= 44.0131, Training Accuracy= 0.000\n",
      "Step 1252, Minibatch Loss= 41.5041, Training Accuracy= 0.000\n",
      "Step 1253, Minibatch Loss= 42.8564, Training Accuracy= 0.000\n",
      "Step 1254, Minibatch Loss= 29.9454, Training Accuracy= 0.000\n",
      "Step 1255, Minibatch Loss= 33.4671, Training Accuracy= 0.000\n",
      "Step 1256, Minibatch Loss= 55.7706, Training Accuracy= 0.000\n",
      "Step 1257, Minibatch Loss= 61.7532, Training Accuracy= 0.000\n",
      "Step 1258, Minibatch Loss= 69.8012, Training Accuracy= 0.000\n",
      "Step 1259, Minibatch Loss= 70.1527, Training Accuracy= 0.000\n",
      "Step 1260, Minibatch Loss= 63.7321, Training Accuracy= 0.000\n",
      "Step 1261, Minibatch Loss= 81.2643, Training Accuracy= 0.000\n",
      "Step 1262, Minibatch Loss= 71.2811, Training Accuracy= 0.000\n",
      "Step 1263, Minibatch Loss= 51.3615, Training Accuracy= 0.000\n",
      "Step 1264, Minibatch Loss= 48.6179, Training Accuracy= 0.000\n",
      "Step 1265, Minibatch Loss= 55.8875, Training Accuracy= 0.000\n",
      "Step 1266, Minibatch Loss= 51.6672, Training Accuracy= 0.000\n",
      "Step 1267, Minibatch Loss= 52.0019, Training Accuracy= 0.000\n",
      "Step 1268, Minibatch Loss= 47.4530, Training Accuracy= 0.000\n",
      "Step 1269, Minibatch Loss= 60.8225, Training Accuracy= 0.000\n",
      "Step 1270, Minibatch Loss= 86.7041, Training Accuracy= 0.000\n",
      "Step 1271, Minibatch Loss= 124.8441, Training Accuracy= 0.000\n",
      "Step 1272, Minibatch Loss= 110.3190, Training Accuracy= 0.000\n",
      "Step 1273, Minibatch Loss= 166.8891, Training Accuracy= 0.000\n",
      "Step 1274, Minibatch Loss= 187.6102, Training Accuracy= 0.000\n",
      "Step 1275, Minibatch Loss= 146.0510, Training Accuracy= 0.000\n",
      "Step 1276, Minibatch Loss= 122.4914, Training Accuracy= 0.000\n",
      "Step 1277, Minibatch Loss= 150.2329, Training Accuracy= 0.000\n",
      "Step 1278, Minibatch Loss= 197.1982, Training Accuracy= 0.000\n",
      "Step 1279, Minibatch Loss= 302.7843, Training Accuracy= 0.000\n",
      "Step 1280, Minibatch Loss= 310.6695, Training Accuracy= 0.000\n",
      "Step 1281, Minibatch Loss= 441.8853, Training Accuracy= 0.000\n",
      "Step 1282, Minibatch Loss= 364.4286, Training Accuracy= 0.000\n",
      "Step 1283, Minibatch Loss= 306.8990, Training Accuracy= 0.000\n",
      "Step 1284, Minibatch Loss= 277.5711, Training Accuracy= 0.000\n",
      "Step 1285, Minibatch Loss= 199.8000, Training Accuracy= 0.000\n",
      "Step 1286, Minibatch Loss= 172.3450, Training Accuracy= 0.000\n",
      "Step 1287, Minibatch Loss= 91.5905, Training Accuracy= 0.000\n",
      "Step 1288, Minibatch Loss= 125.6877, Training Accuracy= 0.000\n",
      "Step 1289, Minibatch Loss= 185.2552, Training Accuracy= 0.000\n",
      "Step 1290, Minibatch Loss= 150.2373, Training Accuracy= 0.000\n",
      "Step 1291, Minibatch Loss= 103.3050, Training Accuracy= 0.000\n",
      "Step 1292, Minibatch Loss= 124.4274, Training Accuracy= 0.000\n",
      "Step 1293, Minibatch Loss= 78.6068, Training Accuracy= 0.000\n",
      "Step 1294, Minibatch Loss= 59.3550, Training Accuracy= 0.000\n",
      "Step 1295, Minibatch Loss= 81.9807, Training Accuracy= 0.000\n",
      "Step 1296, Minibatch Loss= 87.0408, Training Accuracy= 0.000\n",
      "Step 1297, Minibatch Loss= 56.6213, Training Accuracy= 0.000\n",
      "Step 1298, Minibatch Loss= 62.8890, Training Accuracy= 0.000\n",
      "Step 1299, Minibatch Loss= 97.3014, Training Accuracy= 0.000\n",
      "Step 1300, Minibatch Loss= 63.6315, Training Accuracy= 0.000\n",
      "Step 1301, Minibatch Loss= 37.4286, Training Accuracy= 0.000\n",
      "Step 1302, Minibatch Loss= 80.8817, Training Accuracy= 0.000\n",
      "Step 1303, Minibatch Loss= 57.0506, Training Accuracy= 0.000\n",
      "Step 1304, Minibatch Loss= 42.3632, Training Accuracy= 0.000\n",
      "Step 1305, Minibatch Loss= 56.3587, Training Accuracy= 0.000\n",
      "Step 1306, Minibatch Loss= 43.2269, Training Accuracy= 0.000\n",
      "Step 1307, Minibatch Loss= 40.8217, Training Accuracy= 0.000\n",
      "Step 1308, Minibatch Loss= 38.4575, Training Accuracy= 0.000\n",
      "Step 1309, Minibatch Loss= 40.3380, Training Accuracy= 0.000\n",
      "Step 1310, Minibatch Loss= 43.5054, Training Accuracy= 0.000\n",
      "Step 1311, Minibatch Loss= 41.6531, Training Accuracy= 0.000\n",
      "Step 1312, Minibatch Loss= 39.7426, Training Accuracy= 0.000\n",
      "Step 1313, Minibatch Loss= 37.7905, Training Accuracy= 0.000\n",
      "Step 1314, Minibatch Loss= 36.9853, Training Accuracy= 0.000\n",
      "Step 1315, Minibatch Loss= 31.6892, Training Accuracy= 0.000\n",
      "Step 1316, Minibatch Loss= 37.1276, Training Accuracy= 0.000\n",
      "Step 1317, Minibatch Loss= 26.9357, Training Accuracy= 0.000\n",
      "Step 1318, Minibatch Loss= 36.3148, Training Accuracy= 0.000\n",
      "Step 1319, Minibatch Loss= 32.3410, Training Accuracy= 0.000\n",
      "Step 1320, Minibatch Loss= 32.6647, Training Accuracy= 0.000\n",
      "Step 1321, Minibatch Loss= 37.6340, Training Accuracy= 0.000\n",
      "Step 1322, Minibatch Loss= 41.1359, Training Accuracy= 0.000\n",
      "Step 1323, Minibatch Loss= 36.6954, Training Accuracy= 0.000\n",
      "Step 1324, Minibatch Loss= 31.5953, Training Accuracy= 0.000\n",
      "Step 1325, Minibatch Loss= 30.2401, Training Accuracy= 0.000\n",
      "Step 1326, Minibatch Loss= 32.6072, Training Accuracy= 0.000\n",
      "Step 1327, Minibatch Loss= 37.0512, Training Accuracy= 0.000\n",
      "Step 1328, Minibatch Loss= 38.9313, Training Accuracy= 0.000\n",
      "Step 1329, Minibatch Loss= 31.2084, Training Accuracy= 0.000\n",
      "Step 1330, Minibatch Loss= 40.5138, Training Accuracy= 0.000\n",
      "Step 1331, Minibatch Loss= 41.5413, Training Accuracy= 0.000\n",
      "Step 1332, Minibatch Loss= 30.7814, Training Accuracy= 0.000\n",
      "Step 1333, Minibatch Loss= 30.0792, Training Accuracy= 0.000\n",
      "Step 1334, Minibatch Loss= 24.7572, Training Accuracy= 0.000\n",
      "Step 1335, Minibatch Loss= 24.0684, Training Accuracy= 0.000\n",
      "Step 1336, Minibatch Loss= 34.1930, Training Accuracy= 0.000\n",
      "Step 1337, Minibatch Loss= 26.5997, Training Accuracy= 0.000\n",
      "Step 1338, Minibatch Loss= 32.4213, Training Accuracy= 0.000\n",
      "Step 1339, Minibatch Loss= 32.8058, Training Accuracy= 0.000\n",
      "Step 1340, Minibatch Loss= 35.8154, Training Accuracy= 0.000\n",
      "Step 1341, Minibatch Loss= 30.8011, Training Accuracy= 0.000\n",
      "Step 1342, Minibatch Loss= 23.9269, Training Accuracy= 0.000\n",
      "Step 1343, Minibatch Loss= 28.7965, Training Accuracy= 0.000\n",
      "Step 1344, Minibatch Loss= 24.8215, Training Accuracy= 0.000\n",
      "Step 1345, Minibatch Loss= 27.4118, Training Accuracy= 0.000\n",
      "Step 1346, Minibatch Loss= 29.3901, Training Accuracy= 0.000\n",
      "Step 1347, Minibatch Loss= 30.3151, Training Accuracy= 0.000\n",
      "Step 1348, Minibatch Loss= 28.8438, Training Accuracy= 0.000\n",
      "Step 1349, Minibatch Loss= 30.3942, Training Accuracy= 0.000\n",
      "Step 1350, Minibatch Loss= 32.7398, Training Accuracy= 0.000\n",
      "Step 1351, Minibatch Loss= 32.8885, Training Accuracy= 0.000\n",
      "Step 1352, Minibatch Loss= 35.7271, Training Accuracy= 0.000\n",
      "Step 1353, Minibatch Loss= 31.1132, Training Accuracy= 0.000\n",
      "Step 1354, Minibatch Loss= 32.8539, Training Accuracy= 0.000\n",
      "Step 1355, Minibatch Loss= 30.4517, Training Accuracy= 0.000\n",
      "Step 1356, Minibatch Loss= 31.4292, Training Accuracy= 0.000\n",
      "Step 1357, Minibatch Loss= 26.6817, Training Accuracy= 0.000\n",
      "Step 1358, Minibatch Loss= 24.9362, Training Accuracy= 0.000\n",
      "Step 1359, Minibatch Loss= 25.2779, Training Accuracy= 0.000\n",
      "Step 1360, Minibatch Loss= 26.6686, Training Accuracy= 0.000\n",
      "Step 1361, Minibatch Loss= 24.3191, Training Accuracy= 0.000\n",
      "Step 1362, Minibatch Loss= 24.4237, Training Accuracy= 0.000\n",
      "Step 1363, Minibatch Loss= 23.0505, Training Accuracy= 0.000\n",
      "Step 1364, Minibatch Loss= 27.2608, Training Accuracy= 0.000\n",
      "Step 1365, Minibatch Loss= 20.9446, Training Accuracy= 0.000\n",
      "Step 1366, Minibatch Loss= 23.3038, Training Accuracy= 0.000\n",
      "Step 1367, Minibatch Loss= 23.7290, Training Accuracy= 0.000\n",
      "Step 1368, Minibatch Loss= 23.6850, Training Accuracy= 0.000\n",
      "Step 1369, Minibatch Loss= 24.1546, Training Accuracy= 0.000\n",
      "Step 1370, Minibatch Loss= 28.4189, Training Accuracy= 0.000\n",
      "Step 1371, Minibatch Loss= 29.0186, Training Accuracy= 0.000\n",
      "Step 1372, Minibatch Loss= 25.5928, Training Accuracy= 0.000\n",
      "Step 1373, Minibatch Loss= 22.8689, Training Accuracy= 0.000\n",
      "Step 1374, Minibatch Loss= 25.9546, Training Accuracy= 0.000\n",
      "Step 1375, Minibatch Loss= 30.3456, Training Accuracy= 0.000\n",
      "Step 1376, Minibatch Loss= 24.8010, Training Accuracy= 0.000\n",
      "Step 1377, Minibatch Loss= 23.8072, Training Accuracy= 0.000\n",
      "Step 1378, Minibatch Loss= 24.6944, Training Accuracy= 0.000\n",
      "Step 1379, Minibatch Loss= 27.0286, Training Accuracy= 0.000\n",
      "Step 1380, Minibatch Loss= 25.4970, Training Accuracy= 0.000\n",
      "Step 1381, Minibatch Loss= 27.5335, Training Accuracy= 0.000\n",
      "Step 1382, Minibatch Loss= 32.3141, Training Accuracy= 0.000\n",
      "Step 1383, Minibatch Loss= 32.1015, Training Accuracy= 0.000\n",
      "Step 1384, Minibatch Loss= 26.9236, Training Accuracy= 0.000\n",
      "Step 1385, Minibatch Loss= 29.4230, Training Accuracy= 0.000\n",
      "Step 1386, Minibatch Loss= 32.4234, Training Accuracy= 0.000\n",
      "Step 1387, Minibatch Loss= 38.9563, Training Accuracy= 0.000\n",
      "Step 1388, Minibatch Loss= 49.9130, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1389, Minibatch Loss= 61.7874, Training Accuracy= 0.000\n",
      "Step 1390, Minibatch Loss= 61.5359, Training Accuracy= 0.000\n",
      "Step 1391, Minibatch Loss= 65.9137, Training Accuracy= 0.000\n",
      "Step 1392, Minibatch Loss= 43.7913, Training Accuracy= 0.000\n",
      "Step 1393, Minibatch Loss= 36.8422, Training Accuracy= 0.000\n",
      "Step 1394, Minibatch Loss= 47.0663, Training Accuracy= 0.000\n",
      "Step 1395, Minibatch Loss= 57.4431, Training Accuracy= 0.000\n",
      "Step 1396, Minibatch Loss= 46.9106, Training Accuracy= 0.000\n",
      "Step 1397, Minibatch Loss= 50.8390, Training Accuracy= 0.000\n",
      "Step 1398, Minibatch Loss= 45.2099, Training Accuracy= 0.000\n",
      "Step 1399, Minibatch Loss= 38.6851, Training Accuracy= 0.000\n",
      "Step 1400, Minibatch Loss= 42.7210, Training Accuracy= 0.000\n",
      "Step 1401, Minibatch Loss= 51.7446, Training Accuracy= 0.000\n",
      "Step 1402, Minibatch Loss= 49.3945, Training Accuracy= 0.000\n",
      "Step 1403, Minibatch Loss= 39.8129, Training Accuracy= 0.000\n",
      "Step 1404, Minibatch Loss= 38.3947, Training Accuracy= 0.000\n",
      "Step 1405, Minibatch Loss= 36.2192, Training Accuracy= 0.000\n",
      "Step 1406, Minibatch Loss= 41.8070, Training Accuracy= 0.000\n",
      "Step 1407, Minibatch Loss= 49.5453, Training Accuracy= 0.000\n",
      "Step 1408, Minibatch Loss= 43.1686, Training Accuracy= 0.000\n",
      "Step 1409, Minibatch Loss= 37.3295, Training Accuracy= 0.000\n",
      "Step 1410, Minibatch Loss= 39.6251, Training Accuracy= 0.000\n",
      "Step 1411, Minibatch Loss= 28.9111, Training Accuracy= 0.000\n",
      "Step 1412, Minibatch Loss= 25.6919, Training Accuracy= 0.000\n",
      "Step 1413, Minibatch Loss= 28.3320, Training Accuracy= 0.000\n",
      "Step 1414, Minibatch Loss= 32.6040, Training Accuracy= 0.000\n",
      "Step 1415, Minibatch Loss= 45.0574, Training Accuracy= 0.000\n",
      "Step 1416, Minibatch Loss= 56.2862, Training Accuracy= 0.000\n",
      "Step 1417, Minibatch Loss= 74.8800, Training Accuracy= 0.000\n",
      "Step 1418, Minibatch Loss= 69.7861, Training Accuracy= 0.000\n",
      "Step 1419, Minibatch Loss= 61.9583, Training Accuracy= 0.000\n",
      "Step 1420, Minibatch Loss= 33.8309, Training Accuracy= 0.000\n",
      "Step 1421, Minibatch Loss= 34.1507, Training Accuracy= 0.000\n",
      "Step 1422, Minibatch Loss= 39.7990, Training Accuracy= 0.000\n",
      "Step 1423, Minibatch Loss= 61.3142, Training Accuracy= 0.000\n",
      "Step 1424, Minibatch Loss= 76.6324, Training Accuracy= 0.000\n",
      "Step 1425, Minibatch Loss= 64.6119, Training Accuracy= 0.000\n",
      "Step 1426, Minibatch Loss= 37.1004, Training Accuracy= 0.000\n",
      "Step 1427, Minibatch Loss= 29.0248, Training Accuracy= 0.000\n",
      "Step 1428, Minibatch Loss= 42.9995, Training Accuracy= 0.000\n",
      "Step 1429, Minibatch Loss= 45.3373, Training Accuracy= 0.000\n",
      "Step 1430, Minibatch Loss= 36.0316, Training Accuracy= 0.000\n",
      "Step 1431, Minibatch Loss= 28.6900, Training Accuracy= 0.000\n",
      "Step 1432, Minibatch Loss= 35.0381, Training Accuracy= 0.000\n",
      "Step 1433, Minibatch Loss= 36.3724, Training Accuracy= 0.000\n",
      "Step 1434, Minibatch Loss= 36.6071, Training Accuracy= 0.000\n",
      "Step 1435, Minibatch Loss= 32.0326, Training Accuracy= 0.000\n",
      "Step 1436, Minibatch Loss= 26.3172, Training Accuracy= 0.000\n",
      "Step 1437, Minibatch Loss= 35.9310, Training Accuracy= 0.000\n",
      "Step 1438, Minibatch Loss= 41.2644, Training Accuracy= 0.000\n",
      "Step 1439, Minibatch Loss= 32.8657, Training Accuracy= 0.000\n",
      "Step 1440, Minibatch Loss= 31.0199, Training Accuracy= 0.000\n",
      "Step 1441, Minibatch Loss= 30.9719, Training Accuracy= 0.000\n",
      "Step 1442, Minibatch Loss= 40.8867, Training Accuracy= 0.000\n",
      "Step 1443, Minibatch Loss= 39.0331, Training Accuracy= 0.000\n",
      "Step 1444, Minibatch Loss= 36.0753, Training Accuracy= 0.000\n",
      "Step 1445, Minibatch Loss= 43.8388, Training Accuracy= 0.000\n",
      "Step 1446, Minibatch Loss= 46.8735, Training Accuracy= 0.000\n",
      "Step 1447, Minibatch Loss= 50.8860, Training Accuracy= 0.000\n",
      "Step 1448, Minibatch Loss= 55.2905, Training Accuracy= 0.000\n",
      "Step 1449, Minibatch Loss= 54.6175, Training Accuracy= 0.000\n",
      "Step 1450, Minibatch Loss= 76.6291, Training Accuracy= 0.000\n",
      "Step 1451, Minibatch Loss= 116.6677, Training Accuracy= 0.000\n",
      "Step 1452, Minibatch Loss= 161.9160, Training Accuracy= 0.000\n",
      "Step 1453, Minibatch Loss= 131.6308, Training Accuracy= 0.000\n",
      "Step 1454, Minibatch Loss= 70.0155, Training Accuracy= 0.000\n",
      "Step 1455, Minibatch Loss= 41.3920, Training Accuracy= 0.000\n",
      "Step 1456, Minibatch Loss= 41.6500, Training Accuracy= 0.000\n",
      "Step 1457, Minibatch Loss= 70.3281, Training Accuracy= 0.000\n",
      "Step 1458, Minibatch Loss= 72.5028, Training Accuracy= 0.000\n",
      "Step 1459, Minibatch Loss= 67.5241, Training Accuracy= 0.000\n",
      "Step 1460, Minibatch Loss= 32.4404, Training Accuracy= 0.000\n",
      "Step 1461, Minibatch Loss= 33.1046, Training Accuracy= 0.000\n",
      "Step 1462, Minibatch Loss= 50.3907, Training Accuracy= 0.000\n",
      "Step 1463, Minibatch Loss= 78.0136, Training Accuracy= 0.000\n",
      "Step 1464, Minibatch Loss= 64.3054, Training Accuracy= 0.000\n",
      "Step 1465, Minibatch Loss= 34.3977, Training Accuracy= 0.000\n",
      "Step 1466, Minibatch Loss= 44.6650, Training Accuracy= 0.000\n",
      "Step 1467, Minibatch Loss= 46.5811, Training Accuracy= 0.000\n",
      "Step 1468, Minibatch Loss= 30.6811, Training Accuracy= 0.000\n",
      "Step 1469, Minibatch Loss= 25.2284, Training Accuracy= 0.000\n",
      "Step 1470, Minibatch Loss= 45.1401, Training Accuracy= 0.000\n",
      "Step 1471, Minibatch Loss= 50.1565, Training Accuracy= 0.000\n",
      "Step 1472, Minibatch Loss= 35.8754, Training Accuracy= 0.000\n",
      "Step 1473, Minibatch Loss= 33.4577, Training Accuracy= 0.000\n",
      "Step 1474, Minibatch Loss= 45.7705, Training Accuracy= 0.000\n",
      "Step 1475, Minibatch Loss= 39.6260, Training Accuracy= 0.000\n",
      "Step 1476, Minibatch Loss= 36.6130, Training Accuracy= 0.000\n",
      "Step 1477, Minibatch Loss= 46.7142, Training Accuracy= 0.000\n",
      "Step 1478, Minibatch Loss= 49.0523, Training Accuracy= 0.000\n",
      "Step 1479, Minibatch Loss= 36.0835, Training Accuracy= 0.000\n",
      "Step 1480, Minibatch Loss= 44.4157, Training Accuracy= 0.000\n",
      "Step 1481, Minibatch Loss= 48.3812, Training Accuracy= 0.000\n",
      "Step 1482, Minibatch Loss= 39.6600, Training Accuracy= 0.000\n",
      "Step 1483, Minibatch Loss= 41.1143, Training Accuracy= 0.000\n",
      "Step 1484, Minibatch Loss= 39.3401, Training Accuracy= 0.000\n",
      "Step 1485, Minibatch Loss= 35.1056, Training Accuracy= 0.000\n",
      "Step 1486, Minibatch Loss= 45.7409, Training Accuracy= 0.000\n",
      "Step 1487, Minibatch Loss= 44.1116, Training Accuracy= 0.000\n",
      "Step 1488, Minibatch Loss= 41.2938, Training Accuracy= 0.000\n",
      "Step 1489, Minibatch Loss= 45.3333, Training Accuracy= 0.000\n",
      "Step 1490, Minibatch Loss= 42.3090, Training Accuracy= 0.000\n",
      "Step 1491, Minibatch Loss= 42.5917, Training Accuracy= 0.000\n",
      "Step 1492, Minibatch Loss= 41.0936, Training Accuracy= 0.000\n",
      "Step 1493, Minibatch Loss= 33.4838, Training Accuracy= 0.000\n",
      "Step 1494, Minibatch Loss= 26.3781, Training Accuracy= 0.000\n",
      "Step 1495, Minibatch Loss= 26.8375, Training Accuracy= 0.000\n",
      "Step 1496, Minibatch Loss= 27.1068, Training Accuracy= 0.000\n",
      "Step 1497, Minibatch Loss= 33.1901, Training Accuracy= 0.000\n",
      "Step 1498, Minibatch Loss= 35.2836, Training Accuracy= 0.000\n",
      "Step 1499, Minibatch Loss= 36.1388, Training Accuracy= 0.000\n",
      "Step 1500, Minibatch Loss= 22.6174, Training Accuracy= 0.000\n",
      "Step 1501, Minibatch Loss= 25.3655, Training Accuracy= 0.000\n",
      "Step 1502, Minibatch Loss= 28.5886, Training Accuracy= 0.000\n",
      "Step 1503, Minibatch Loss= 34.0759, Training Accuracy= 0.000\n",
      "Step 1504, Minibatch Loss= 32.7271, Training Accuracy= 0.000\n",
      "Step 1505, Minibatch Loss= 30.0835, Training Accuracy= 0.000\n",
      "Step 1506, Minibatch Loss= 28.9457, Training Accuracy= 0.000\n",
      "Step 1507, Minibatch Loss= 31.8708, Training Accuracy= 0.000\n",
      "Step 1508, Minibatch Loss= 31.6191, Training Accuracy= 0.000\n",
      "Step 1509, Minibatch Loss= 26.6599, Training Accuracy= 0.000\n",
      "Step 1510, Minibatch Loss= 25.1134, Training Accuracy= 0.000\n",
      "Step 1511, Minibatch Loss= 21.2996, Training Accuracy= 0.000\n",
      "Step 1512, Minibatch Loss= 22.5916, Training Accuracy= 0.000\n",
      "Step 1513, Minibatch Loss= 26.9730, Training Accuracy= 0.000\n",
      "Step 1514, Minibatch Loss= 23.7120, Training Accuracy= 0.000\n",
      "Step 1515, Minibatch Loss= 26.5070, Training Accuracy= 0.000\n",
      "Step 1516, Minibatch Loss= 29.2542, Training Accuracy= 0.000\n",
      "Step 1517, Minibatch Loss= 26.6469, Training Accuracy= 0.000\n",
      "Step 1518, Minibatch Loss= 28.3139, Training Accuracy= 0.000\n",
      "Step 1519, Minibatch Loss= 28.4852, Training Accuracy= 0.000\n",
      "Step 1520, Minibatch Loss= 32.3886, Training Accuracy= 0.000\n",
      "Step 1521, Minibatch Loss= 31.9380, Training Accuracy= 0.000\n",
      "Step 1522, Minibatch Loss= 38.8827, Training Accuracy= 0.000\n",
      "Step 1523, Minibatch Loss= 63.9728, Training Accuracy= 0.000\n",
      "Step 1524, Minibatch Loss= 97.3925, Training Accuracy= 0.000\n",
      "Step 1525, Minibatch Loss= 79.1614, Training Accuracy= 0.000\n",
      "Step 1526, Minibatch Loss= 51.2550, Training Accuracy= 0.000\n",
      "Step 1527, Minibatch Loss= 41.6078, Training Accuracy= 0.000\n",
      "Step 1528, Minibatch Loss= 43.7299, Training Accuracy= 0.000\n",
      "Step 1529, Minibatch Loss= 59.7991, Training Accuracy= 0.000\n",
      "Step 1530, Minibatch Loss= 73.5817, Training Accuracy= 0.000\n",
      "Step 1531, Minibatch Loss= 79.3133, Training Accuracy= 0.000\n",
      "Step 1532, Minibatch Loss= 97.5117, Training Accuracy= 0.000\n",
      "Step 1533, Minibatch Loss= 85.9950, Training Accuracy= 0.000\n",
      "Step 1534, Minibatch Loss= 62.3823, Training Accuracy= 0.000\n",
      "Step 1535, Minibatch Loss= 56.3068, Training Accuracy= 0.000\n",
      "Step 1536, Minibatch Loss= 61.3591, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1537, Minibatch Loss= 86.9989, Training Accuracy= 0.000\n",
      "Step 1538, Minibatch Loss= 97.2259, Training Accuracy= 0.000\n",
      "Step 1539, Minibatch Loss= 83.1092, Training Accuracy= 0.000\n",
      "Step 1540, Minibatch Loss= 114.8794, Training Accuracy= 0.000\n",
      "Step 1541, Minibatch Loss= 153.7883, Training Accuracy= 0.000\n",
      "Step 1542, Minibatch Loss= 165.8423, Training Accuracy= 0.000\n",
      "Step 1543, Minibatch Loss= 215.4802, Training Accuracy= 0.000\n",
      "Step 1544, Minibatch Loss= 271.2538, Training Accuracy= 0.000\n",
      "Step 1545, Minibatch Loss= 235.2928, Training Accuracy= 0.000\n",
      "Step 1546, Minibatch Loss= 263.8300, Training Accuracy= 0.000\n",
      "Step 1547, Minibatch Loss= 252.5543, Training Accuracy= 0.000\n",
      "Step 1548, Minibatch Loss= 158.0510, Training Accuracy= 0.000\n",
      "Step 1549, Minibatch Loss= 102.2465, Training Accuracy= 0.000\n",
      "Step 1550, Minibatch Loss= 95.9408, Training Accuracy= 0.000\n",
      "Step 1551, Minibatch Loss= 107.6487, Training Accuracy= 0.000\n",
      "Step 1552, Minibatch Loss= 87.7587, Training Accuracy= 0.000\n",
      "Step 1553, Minibatch Loss= 45.9922, Training Accuracy= 0.000\n",
      "Step 1554, Minibatch Loss= 53.5630, Training Accuracy= 0.000\n",
      "Step 1555, Minibatch Loss= 68.7279, Training Accuracy= 0.000\n",
      "Step 1556, Minibatch Loss= 44.6457, Training Accuracy= 0.000\n",
      "Step 1557, Minibatch Loss= 46.7884, Training Accuracy= 0.000\n",
      "Step 1558, Minibatch Loss= 51.8403, Training Accuracy= 0.000\n",
      "Step 1559, Minibatch Loss= 32.0174, Training Accuracy= 0.000\n",
      "Step 1560, Minibatch Loss= 47.4816, Training Accuracy= 0.000\n",
      "Step 1561, Minibatch Loss= 48.9443, Training Accuracy= 0.000\n",
      "Step 1562, Minibatch Loss= 31.1013, Training Accuracy= 0.000\n",
      "Step 1563, Minibatch Loss= 42.4122, Training Accuracy= 0.000\n",
      "Step 1564, Minibatch Loss= 35.0149, Training Accuracy= 0.000\n",
      "Step 1565, Minibatch Loss= 39.8636, Training Accuracy= 0.000\n",
      "Step 1566, Minibatch Loss= 39.2925, Training Accuracy= 0.000\n",
      "Step 1567, Minibatch Loss= 24.5857, Training Accuracy= 0.000\n",
      "Step 1568, Minibatch Loss= 30.7265, Training Accuracy= 0.000\n",
      "Step 1569, Minibatch Loss= 30.4493, Training Accuracy= 0.000\n",
      "Step 1570, Minibatch Loss= 26.1593, Training Accuracy= 0.000\n",
      "Step 1571, Minibatch Loss= 29.9228, Training Accuracy= 0.000\n",
      "Step 1572, Minibatch Loss= 20.7898, Training Accuracy= 0.000\n",
      "Step 1573, Minibatch Loss= 29.6985, Training Accuracy= 0.000\n",
      "Step 1574, Minibatch Loss= 25.4450, Training Accuracy= 0.000\n",
      "Step 1575, Minibatch Loss= 25.8592, Training Accuracy= 0.000\n",
      "Step 1576, Minibatch Loss= 26.3644, Training Accuracy= 0.000\n",
      "Step 1577, Minibatch Loss= 22.6891, Training Accuracy= 0.000\n",
      "Step 1578, Minibatch Loss= 23.1384, Training Accuracy= 0.000\n",
      "Step 1579, Minibatch Loss= 27.6500, Training Accuracy= 0.000\n",
      "Step 1580, Minibatch Loss= 25.7696, Training Accuracy= 0.000\n",
      "Step 1581, Minibatch Loss= 23.7488, Training Accuracy= 0.000\n",
      "Step 1582, Minibatch Loss= 24.5658, Training Accuracy= 0.000\n",
      "Step 1583, Minibatch Loss= 23.6564, Training Accuracy= 0.000\n",
      "Step 1584, Minibatch Loss= 21.2446, Training Accuracy= 0.000\n",
      "Step 1585, Minibatch Loss= 23.2982, Training Accuracy= 0.000\n",
      "Step 1586, Minibatch Loss= 25.0910, Training Accuracy= 0.000\n",
      "Step 1587, Minibatch Loss= 22.7559, Training Accuracy= 0.000\n",
      "Step 1588, Minibatch Loss= 25.1837, Training Accuracy= 0.000\n",
      "Step 1589, Minibatch Loss= 23.1003, Training Accuracy= 0.000\n",
      "Step 1590, Minibatch Loss= 26.6079, Training Accuracy= 0.000\n",
      "Step 1591, Minibatch Loss= 31.4127, Training Accuracy= 0.000\n",
      "Step 1592, Minibatch Loss= 28.8773, Training Accuracy= 0.000\n",
      "Step 1593, Minibatch Loss= 37.8438, Training Accuracy= 0.000\n",
      "Step 1594, Minibatch Loss= 36.3602, Training Accuracy= 0.000\n",
      "Step 1595, Minibatch Loss= 39.6337, Training Accuracy= 0.000\n",
      "Step 1596, Minibatch Loss= 46.0510, Training Accuracy= 0.000\n",
      "Step 1597, Minibatch Loss= 56.1981, Training Accuracy= 0.000\n",
      "Step 1598, Minibatch Loss= 78.1314, Training Accuracy= 0.000\n",
      "Step 1599, Minibatch Loss= 105.5023, Training Accuracy= 0.000\n",
      "Step 1600, Minibatch Loss= 184.6160, Training Accuracy= 0.000\n",
      "Step 1601, Minibatch Loss= 383.5447, Training Accuracy= 0.000\n",
      "Step 1602, Minibatch Loss= 719.7889, Training Accuracy= 0.000\n",
      "Step 1603, Minibatch Loss= 770.4019, Training Accuracy= 0.000\n",
      "Step 1604, Minibatch Loss= 402.7001, Training Accuracy= 0.000\n",
      "Step 1605, Minibatch Loss= 170.2381, Training Accuracy= 0.000\n",
      "Step 1606, Minibatch Loss= 476.1662, Training Accuracy= 0.000\n",
      "Step 1607, Minibatch Loss= 240.0353, Training Accuracy= 0.000\n",
      "Step 1608, Minibatch Loss= 175.6535, Training Accuracy= 0.000\n",
      "Step 1609, Minibatch Loss= 217.4721, Training Accuracy= 0.000\n",
      "Step 1610, Minibatch Loss= 157.5509, Training Accuracy= 0.000\n",
      "Step 1611, Minibatch Loss= 246.5272, Training Accuracy= 0.000\n",
      "Step 1612, Minibatch Loss= 140.4701, Training Accuracy= 0.000\n",
      "Step 1613, Minibatch Loss= 115.0226, Training Accuracy= 0.000\n",
      "Step 1614, Minibatch Loss= 149.1372, Training Accuracy= 0.000\n",
      "Step 1615, Minibatch Loss= 110.8592, Training Accuracy= 0.000\n",
      "Step 1616, Minibatch Loss= 133.8743, Training Accuracy= 0.000\n",
      "Step 1617, Minibatch Loss= 65.9333, Training Accuracy= 0.000\n",
      "Step 1618, Minibatch Loss= 81.9275, Training Accuracy= 0.000\n",
      "Step 1619, Minibatch Loss= 80.3277, Training Accuracy= 0.000\n",
      "Step 1620, Minibatch Loss= 57.3396, Training Accuracy= 0.000\n",
      "Step 1621, Minibatch Loss= 77.8761, Training Accuracy= 0.000\n",
      "Step 1622, Minibatch Loss= 77.4921, Training Accuracy= 0.000\n",
      "Step 1623, Minibatch Loss= 72.9430, Training Accuracy= 0.000\n",
      "Step 1624, Minibatch Loss= 61.3494, Training Accuracy= 0.000\n",
      "Step 1625, Minibatch Loss= 51.3699, Training Accuracy= 0.000\n",
      "Step 1626, Minibatch Loss= 46.7605, Training Accuracy= 0.000\n",
      "Step 1627, Minibatch Loss= 41.3591, Training Accuracy= 0.000\n",
      "Step 1628, Minibatch Loss= 40.3786, Training Accuracy= 0.000\n",
      "Step 1629, Minibatch Loss= 46.1907, Training Accuracy= 0.000\n",
      "Step 1630, Minibatch Loss= 45.9700, Training Accuracy= 0.000\n",
      "Step 1631, Minibatch Loss= 29.8252, Training Accuracy= 0.000\n",
      "Step 1632, Minibatch Loss= 31.7418, Training Accuracy= 0.000\n",
      "Step 1633, Minibatch Loss= 32.6845, Training Accuracy= 0.000\n",
      "Step 1634, Minibatch Loss= 36.6042, Training Accuracy= 0.000\n",
      "Step 1635, Minibatch Loss= 39.5762, Training Accuracy= 0.000\n",
      "Step 1636, Minibatch Loss= 29.4608, Training Accuracy= 0.000\n",
      "Step 1637, Minibatch Loss= 32.7625, Training Accuracy= 0.000\n",
      "Step 1638, Minibatch Loss= 27.7474, Training Accuracy= 0.000\n",
      "Step 1639, Minibatch Loss= 30.5872, Training Accuracy= 0.000\n",
      "Step 1640, Minibatch Loss= 22.3067, Training Accuracy= 0.000\n",
      "Step 1641, Minibatch Loss= 22.5429, Training Accuracy= 0.000\n",
      "Step 1642, Minibatch Loss= 26.5113, Training Accuracy= 0.000\n",
      "Step 1643, Minibatch Loss= 22.2383, Training Accuracy= 0.000\n",
      "Step 1644, Minibatch Loss= 22.3985, Training Accuracy= 0.000\n",
      "Step 1645, Minibatch Loss= 23.1516, Training Accuracy= 0.000\n",
      "Step 1646, Minibatch Loss= 21.7355, Training Accuracy= 0.000\n",
      "Step 1647, Minibatch Loss= 23.7272, Training Accuracy= 0.000\n",
      "Step 1648, Minibatch Loss= 22.2924, Training Accuracy= 0.000\n",
      "Step 1649, Minibatch Loss= 20.6675, Training Accuracy= 0.000\n",
      "Step 1650, Minibatch Loss= 21.9476, Training Accuracy= 0.000\n",
      "Step 1651, Minibatch Loss= 21.1609, Training Accuracy= 0.000\n",
      "Step 1652, Minibatch Loss= 22.7230, Training Accuracy= 0.000\n",
      "Step 1653, Minibatch Loss= 21.5742, Training Accuracy= 0.000\n",
      "Step 1654, Minibatch Loss= 21.3975, Training Accuracy= 0.000\n",
      "Step 1655, Minibatch Loss= 22.9273, Training Accuracy= 0.000\n",
      "Step 1656, Minibatch Loss= 22.0498, Training Accuracy= 0.000\n",
      "Step 1657, Minibatch Loss= 27.0595, Training Accuracy= 0.000\n",
      "Step 1658, Minibatch Loss= 29.2215, Training Accuracy= 0.000\n",
      "Step 1659, Minibatch Loss= 39.5783, Training Accuracy= 0.000\n",
      "Step 1660, Minibatch Loss= 50.8463, Training Accuracy= 0.000\n",
      "Step 1661, Minibatch Loss= 42.8534, Training Accuracy= 0.000\n",
      "Step 1662, Minibatch Loss= 44.5978, Training Accuracy= 0.000\n",
      "Step 1663, Minibatch Loss= 45.2019, Training Accuracy= 0.000\n",
      "Step 1664, Minibatch Loss= 48.0289, Training Accuracy= 0.000\n",
      "Step 1665, Minibatch Loss= 47.2338, Training Accuracy= 0.000\n",
      "Step 1666, Minibatch Loss= 55.9731, Training Accuracy= 0.000\n",
      "Step 1667, Minibatch Loss= 73.6095, Training Accuracy= 0.000\n",
      "Step 1668, Minibatch Loss= 91.4779, Training Accuracy= 0.000\n",
      "Step 1669, Minibatch Loss= 65.0316, Training Accuracy= 0.000\n",
      "Step 1670, Minibatch Loss= 41.6002, Training Accuracy= 0.000\n",
      "Step 1671, Minibatch Loss= 22.0630, Training Accuracy= 0.000\n",
      "Step 1672, Minibatch Loss= 24.0466, Training Accuracy= 0.000\n",
      "Step 1673, Minibatch Loss= 29.4573, Training Accuracy= 0.000\n",
      "Step 1674, Minibatch Loss= 32.3181, Training Accuracy= 0.000\n",
      "Step 1675, Minibatch Loss= 24.3783, Training Accuracy= 0.000\n",
      "Step 1676, Minibatch Loss= 22.3428, Training Accuracy= 0.000\n",
      "Step 1677, Minibatch Loss= 23.0224, Training Accuracy= 0.000\n",
      "Step 1678, Minibatch Loss= 26.6734, Training Accuracy= 0.000\n",
      "Step 1679, Minibatch Loss= 27.1726, Training Accuracy= 0.000\n",
      "Step 1680, Minibatch Loss= 24.9422, Training Accuracy= 0.000\n",
      "Step 1681, Minibatch Loss= 21.8217, Training Accuracy= 0.000\n",
      "Step 1682, Minibatch Loss= 21.0079, Training Accuracy= 0.000\n",
      "Step 1683, Minibatch Loss= 24.5927, Training Accuracy= 0.000\n",
      "Step 1684, Minibatch Loss= 18.3574, Training Accuracy= 0.000\n",
      "Step 1685, Minibatch Loss= 18.4781, Training Accuracy= 0.000\n",
      "Step 1686, Minibatch Loss= 21.3494, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1687, Minibatch Loss= 21.8155, Training Accuracy= 0.000\n",
      "Step 1688, Minibatch Loss= 18.4837, Training Accuracy= 0.000\n",
      "Step 1689, Minibatch Loss= 17.9889, Training Accuracy= 0.000\n",
      "Step 1690, Minibatch Loss= 24.7338, Training Accuracy= 0.000\n",
      "Step 1691, Minibatch Loss= 20.0936, Training Accuracy= 0.000\n",
      "Step 1692, Minibatch Loss= 20.3214, Training Accuracy= 0.000\n",
      "Step 1693, Minibatch Loss= 17.9634, Training Accuracy= 0.000\n",
      "Step 1694, Minibatch Loss= 16.9164, Training Accuracy= 0.000\n",
      "Step 1695, Minibatch Loss= 22.0318, Training Accuracy= 0.000\n",
      "Step 1696, Minibatch Loss= 18.8464, Training Accuracy= 0.000\n",
      "Step 1697, Minibatch Loss= 19.9502, Training Accuracy= 0.000\n",
      "Step 1698, Minibatch Loss= 19.1123, Training Accuracy= 0.000\n",
      "Step 1699, Minibatch Loss= 18.0309, Training Accuracy= 0.000\n",
      "Step 1700, Minibatch Loss= 23.1489, Training Accuracy= 0.000\n",
      "Step 1701, Minibatch Loss= 20.3627, Training Accuracy= 0.000\n",
      "Step 1702, Minibatch Loss= 16.6876, Training Accuracy= 0.000\n",
      "Step 1703, Minibatch Loss= 18.6975, Training Accuracy= 0.000\n",
      "Step 1704, Minibatch Loss= 22.0148, Training Accuracy= 0.000\n",
      "Step 1705, Minibatch Loss= 21.1122, Training Accuracy= 0.000\n",
      "Step 1706, Minibatch Loss= 22.4705, Training Accuracy= 0.000\n",
      "Step 1707, Minibatch Loss= 21.3126, Training Accuracy= 0.000\n",
      "Step 1708, Minibatch Loss= 21.3263, Training Accuracy= 0.000\n",
      "Step 1709, Minibatch Loss= 24.0077, Training Accuracy= 0.000\n",
      "Step 1710, Minibatch Loss= 21.2864, Training Accuracy= 0.000\n",
      "Step 1711, Minibatch Loss= 20.7413, Training Accuracy= 0.000\n",
      "Step 1712, Minibatch Loss= 20.1025, Training Accuracy= 0.000\n",
      "Step 1713, Minibatch Loss= 18.9034, Training Accuracy= 0.000\n",
      "Step 1714, Minibatch Loss= 21.8435, Training Accuracy= 0.000\n",
      "Step 1715, Minibatch Loss= 18.0834, Training Accuracy= 0.000\n",
      "Step 1716, Minibatch Loss= 21.2669, Training Accuracy= 0.000\n",
      "Step 1717, Minibatch Loss= 21.9960, Training Accuracy= 0.000\n",
      "Step 1718, Minibatch Loss= 26.1319, Training Accuracy= 0.000\n",
      "Step 1719, Minibatch Loss= 24.3977, Training Accuracy= 0.000\n",
      "Step 1720, Minibatch Loss= 26.5113, Training Accuracy= 0.000\n",
      "Step 1721, Minibatch Loss= 21.8299, Training Accuracy= 0.000\n",
      "Step 1722, Minibatch Loss= 17.4964, Training Accuracy= 0.000\n",
      "Step 1723, Minibatch Loss= 20.0131, Training Accuracy= 0.000\n",
      "Step 1724, Minibatch Loss= 19.6634, Training Accuracy= 0.000\n",
      "Step 1725, Minibatch Loss= 20.8167, Training Accuracy= 0.000\n",
      "Step 1726, Minibatch Loss= 23.7733, Training Accuracy= 0.000\n",
      "Step 1727, Minibatch Loss= 27.7703, Training Accuracy= 0.000\n",
      "Step 1728, Minibatch Loss= 33.3811, Training Accuracy= 0.000\n",
      "Step 1729, Minibatch Loss= 37.3249, Training Accuracy= 0.000\n",
      "Step 1730, Minibatch Loss= 38.4721, Training Accuracy= 0.000\n",
      "Step 1731, Minibatch Loss= 33.6982, Training Accuracy= 0.000\n",
      "Step 1732, Minibatch Loss= 22.4880, Training Accuracy= 0.000\n",
      "Step 1733, Minibatch Loss= 20.9344, Training Accuracy= 0.000\n",
      "Step 1734, Minibatch Loss= 26.2864, Training Accuracy= 0.000\n",
      "Step 1735, Minibatch Loss= 31.9308, Training Accuracy= 0.000\n",
      "Step 1736, Minibatch Loss= 33.8385, Training Accuracy= 0.000\n",
      "Step 1737, Minibatch Loss= 26.3630, Training Accuracy= 0.000\n",
      "Step 1738, Minibatch Loss= 25.5735, Training Accuracy= 0.000\n",
      "Step 1739, Minibatch Loss= 33.3590, Training Accuracy= 0.000\n",
      "Step 1740, Minibatch Loss= 41.8316, Training Accuracy= 0.000\n",
      "Step 1741, Minibatch Loss= 45.9139, Training Accuracy= 0.000\n",
      "Step 1742, Minibatch Loss= 50.8996, Training Accuracy= 0.000\n",
      "Step 1743, Minibatch Loss= 60.1831, Training Accuracy= 0.000\n",
      "Step 1744, Minibatch Loss= 72.2470, Training Accuracy= 0.000\n",
      "Step 1745, Minibatch Loss= 65.3505, Training Accuracy= 0.000\n",
      "Step 1746, Minibatch Loss= 84.5163, Training Accuracy= 0.000\n",
      "Step 1747, Minibatch Loss= 114.2428, Training Accuracy= 0.000\n",
      "Step 1748, Minibatch Loss= 197.4995, Training Accuracy= 0.000\n",
      "Step 1749, Minibatch Loss= 282.9289, Training Accuracy= 0.000\n",
      "Step 1750, Minibatch Loss= 256.3378, Training Accuracy= 0.000\n",
      "Step 1751, Minibatch Loss= 188.9958, Training Accuracy= 0.000\n",
      "Step 1752, Minibatch Loss= 68.0743, Training Accuracy= 0.000\n",
      "Step 1753, Minibatch Loss= 114.5932, Training Accuracy= 0.000\n",
      "Step 1754, Minibatch Loss= 172.0439, Training Accuracy= 0.000\n",
      "Step 1755, Minibatch Loss= 94.3015, Training Accuracy= 0.000\n",
      "Step 1756, Minibatch Loss= 58.3517, Training Accuracy= 0.000\n",
      "Step 1757, Minibatch Loss= 121.1316, Training Accuracy= 0.000\n",
      "Step 1758, Minibatch Loss= 68.7826, Training Accuracy= 0.000\n",
      "Step 1759, Minibatch Loss= 50.7703, Training Accuracy= 0.000\n",
      "Step 1760, Minibatch Loss= 107.2931, Training Accuracy= 0.000\n",
      "Step 1761, Minibatch Loss= 57.0201, Training Accuracy= 0.000\n",
      "Step 1762, Minibatch Loss= 79.2806, Training Accuracy= 0.000\n",
      "Step 1763, Minibatch Loss= 82.8788, Training Accuracy= 0.000\n",
      "Step 1764, Minibatch Loss= 66.5576, Training Accuracy= 0.000\n",
      "Step 1765, Minibatch Loss= 114.3145, Training Accuracy= 0.000\n",
      "Step 1766, Minibatch Loss= 101.5617, Training Accuracy= 0.000\n",
      "Step 1767, Minibatch Loss= 110.5315, Training Accuracy= 0.000\n",
      "Step 1768, Minibatch Loss= 106.9246, Training Accuracy= 0.000\n",
      "Step 1769, Minibatch Loss= 143.7922, Training Accuracy= 0.000\n",
      "Step 1770, Minibatch Loss= 129.8413, Training Accuracy= 0.000\n",
      "Step 1771, Minibatch Loss= 71.4394, Training Accuracy= 0.000\n",
      "Step 1772, Minibatch Loss= 40.3941, Training Accuracy= 0.000\n",
      "Step 1773, Minibatch Loss= 43.9271, Training Accuracy= 0.000\n",
      "Step 1774, Minibatch Loss= 70.6662, Training Accuracy= 0.000\n",
      "Step 1775, Minibatch Loss= 82.6727, Training Accuracy= 0.000\n",
      "Step 1776, Minibatch Loss= 59.4603, Training Accuracy= 0.000\n",
      "Step 1777, Minibatch Loss= 37.5645, Training Accuracy= 0.000\n",
      "Step 1778, Minibatch Loss= 38.6726, Training Accuracy= 0.000\n",
      "Step 1779, Minibatch Loss= 55.1855, Training Accuracy= 0.000\n",
      "Step 1780, Minibatch Loss= 43.8197, Training Accuracy= 0.000\n",
      "Step 1781, Minibatch Loss= 26.2709, Training Accuracy= 0.000\n",
      "Step 1782, Minibatch Loss= 36.7768, Training Accuracy= 0.000\n",
      "Step 1783, Minibatch Loss= 45.2310, Training Accuracy= 0.000\n",
      "Step 1784, Minibatch Loss= 24.7576, Training Accuracy= 0.000\n",
      "Step 1785, Minibatch Loss= 27.4645, Training Accuracy= 0.000\n",
      "Step 1786, Minibatch Loss= 33.9938, Training Accuracy= 0.000\n",
      "Step 1787, Minibatch Loss= 25.5815, Training Accuracy= 0.000\n",
      "Step 1788, Minibatch Loss= 27.0037, Training Accuracy= 0.000\n",
      "Step 1789, Minibatch Loss= 35.6353, Training Accuracy= 0.000\n",
      "Step 1790, Minibatch Loss= 23.4820, Training Accuracy= 0.000\n",
      "Step 1791, Minibatch Loss= 21.1957, Training Accuracy= 0.000\n",
      "Step 1792, Minibatch Loss= 32.1536, Training Accuracy= 0.000\n",
      "Step 1793, Minibatch Loss= 27.9647, Training Accuracy= 0.000\n",
      "Step 1794, Minibatch Loss= 22.7994, Training Accuracy= 0.000\n",
      "Step 1795, Minibatch Loss= 27.9129, Training Accuracy= 0.000\n",
      "Step 1796, Minibatch Loss= 23.8702, Training Accuracy= 0.000\n",
      "Step 1797, Minibatch Loss= 22.9456, Training Accuracy= 0.000\n",
      "Step 1798, Minibatch Loss= 25.2276, Training Accuracy= 0.000\n",
      "Step 1799, Minibatch Loss= 23.9539, Training Accuracy= 0.000\n",
      "Step 1800, Minibatch Loss= 27.6065, Training Accuracy= 0.000\n",
      "Step 1801, Minibatch Loss= 29.1127, Training Accuracy= 0.000\n",
      "Step 1802, Minibatch Loss= 30.5931, Training Accuracy= 0.000\n",
      "Step 1803, Minibatch Loss= 22.4581, Training Accuracy= 0.000\n",
      "Step 1804, Minibatch Loss= 24.4741, Training Accuracy= 0.000\n",
      "Step 1805, Minibatch Loss= 17.2431, Training Accuracy= 0.000\n",
      "Step 1806, Minibatch Loss= 19.6697, Training Accuracy= 0.000\n",
      "Step 1807, Minibatch Loss= 19.6431, Training Accuracy= 0.000\n",
      "Step 1808, Minibatch Loss= 16.1731, Training Accuracy= 0.000\n",
      "Step 1809, Minibatch Loss= 17.4656, Training Accuracy= 0.000\n",
      "Step 1810, Minibatch Loss= 17.3523, Training Accuracy= 0.000\n",
      "Step 1811, Minibatch Loss= 17.7815, Training Accuracy= 0.000\n",
      "Step 1812, Minibatch Loss= 19.6442, Training Accuracy= 0.000\n",
      "Step 1813, Minibatch Loss= 17.0482, Training Accuracy= 0.000\n",
      "Step 1814, Minibatch Loss= 18.0843, Training Accuracy= 0.000\n",
      "Step 1815, Minibatch Loss= 17.9651, Training Accuracy= 0.000\n",
      "Step 1816, Minibatch Loss= 16.8533, Training Accuracy= 0.000\n",
      "Step 1817, Minibatch Loss= 17.9407, Training Accuracy= 0.000\n",
      "Step 1818, Minibatch Loss= 20.9288, Training Accuracy= 0.000\n",
      "Step 1819, Minibatch Loss= 20.2908, Training Accuracy= 0.000\n",
      "Step 1820, Minibatch Loss= 19.3916, Training Accuracy= 0.000\n",
      "Step 1821, Minibatch Loss= 16.8150, Training Accuracy= 0.000\n",
      "Step 1822, Minibatch Loss= 19.0253, Training Accuracy= 0.000\n",
      "Step 1823, Minibatch Loss= 20.3429, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1824, Minibatch Loss= 18.1131, Training Accuracy= 0.000\n",
      "Step 1825, Minibatch Loss= 17.8456, Training Accuracy= 0.000\n",
      "Step 1826, Minibatch Loss= 17.0271, Training Accuracy= 0.000\n",
      "Step 1827, Minibatch Loss= 18.2706, Training Accuracy= 0.000\n",
      "Step 1828, Minibatch Loss= 17.0031, Training Accuracy= 0.000\n",
      "Step 1829, Minibatch Loss= 16.7932, Training Accuracy= 0.000\n",
      "Step 1830, Minibatch Loss= 20.9926, Training Accuracy= 0.000\n",
      "Step 1831, Minibatch Loss= 23.8303, Training Accuracy= 0.000\n",
      "Step 1832, Minibatch Loss= 20.9127, Training Accuracy= 0.000\n",
      "Step 1833, Minibatch Loss= 22.3048, Training Accuracy= 0.000\n",
      "Step 1834, Minibatch Loss= 24.7342, Training Accuracy= 0.000\n",
      "Step 1835, Minibatch Loss= 33.6429, Training Accuracy= 0.000\n",
      "Step 1836, Minibatch Loss= 34.4429, Training Accuracy= 0.000\n",
      "Step 1837, Minibatch Loss= 36.5539, Training Accuracy= 0.000\n",
      "Step 1838, Minibatch Loss= 40.3147, Training Accuracy= 0.000\n",
      "Step 1839, Minibatch Loss= 43.4561, Training Accuracy= 0.000\n",
      "Step 1840, Minibatch Loss= 52.3331, Training Accuracy= 0.000\n",
      "Step 1841, Minibatch Loss= 61.2628, Training Accuracy= 0.000\n",
      "Step 1842, Minibatch Loss= 74.0498, Training Accuracy= 0.000\n",
      "Step 1843, Minibatch Loss= 94.9934, Training Accuracy= 0.000\n",
      "Step 1844, Minibatch Loss= 104.9113, Training Accuracy= 0.000\n",
      "Step 1845, Minibatch Loss= 120.4515, Training Accuracy= 0.000\n",
      "Step 1846, Minibatch Loss= 139.7499, Training Accuracy= 0.000\n",
      "Step 1847, Minibatch Loss= 124.2898, Training Accuracy= 0.000\n",
      "Step 1848, Minibatch Loss= 120.1540, Training Accuracy= 0.000\n",
      "Step 1849, Minibatch Loss= 90.3289, Training Accuracy= 0.000\n",
      "Step 1850, Minibatch Loss= 85.8591, Training Accuracy= 0.000\n",
      "Step 1851, Minibatch Loss= 128.1940, Training Accuracy= 0.000\n",
      "Step 1852, Minibatch Loss= 81.8562, Training Accuracy= 0.000\n",
      "Step 1853, Minibatch Loss= 35.1725, Training Accuracy= 0.000\n",
      "Step 1854, Minibatch Loss= 46.1025, Training Accuracy= 0.000\n",
      "Step 1855, Minibatch Loss= 91.9841, Training Accuracy= 0.000\n",
      "Step 1856, Minibatch Loss= 82.4739, Training Accuracy= 0.000\n",
      "Step 1857, Minibatch Loss= 51.1449, Training Accuracy= 0.000\n",
      "Step 1858, Minibatch Loss= 40.4181, Training Accuracy= 0.000\n",
      "Step 1859, Minibatch Loss= 61.5963, Training Accuracy= 0.000\n",
      "Step 1860, Minibatch Loss= 72.2785, Training Accuracy= 0.000\n",
      "Step 1861, Minibatch Loss= 62.9675, Training Accuracy= 0.000\n",
      "Step 1862, Minibatch Loss= 31.9898, Training Accuracy= 0.000\n",
      "Step 1863, Minibatch Loss= 29.5914, Training Accuracy= 0.000\n",
      "Step 1864, Minibatch Loss= 41.8175, Training Accuracy= 0.000\n",
      "Step 1865, Minibatch Loss= 32.5363, Training Accuracy= 0.000\n",
      "Step 1866, Minibatch Loss= 26.0919, Training Accuracy= 0.000\n",
      "Step 1867, Minibatch Loss= 30.1947, Training Accuracy= 0.000\n",
      "Step 1868, Minibatch Loss= 26.3191, Training Accuracy= 0.000\n",
      "Step 1869, Minibatch Loss= 24.7965, Training Accuracy= 0.000\n",
      "Step 1870, Minibatch Loss= 26.9540, Training Accuracy= 0.000\n",
      "Step 1871, Minibatch Loss= 33.5653, Training Accuracy= 0.000\n",
      "Step 1872, Minibatch Loss= 29.8227, Training Accuracy= 0.000\n",
      "Step 1873, Minibatch Loss= 34.5510, Training Accuracy= 0.000\n",
      "Step 1874, Minibatch Loss= 33.7695, Training Accuracy= 0.000\n",
      "Step 1875, Minibatch Loss= 25.9620, Training Accuracy= 0.000\n",
      "Step 1876, Minibatch Loss= 24.1886, Training Accuracy= 0.000\n",
      "Step 1877, Minibatch Loss= 25.0857, Training Accuracy= 0.000\n",
      "Step 1878, Minibatch Loss= 27.1652, Training Accuracy= 0.000\n",
      "Step 1879, Minibatch Loss= 46.3965, Training Accuracy= 0.000\n",
      "Step 1880, Minibatch Loss= 51.9774, Training Accuracy= 0.000\n",
      "Step 1881, Minibatch Loss= 66.3561, Training Accuracy= 0.000\n",
      "Step 1882, Minibatch Loss= 88.8487, Training Accuracy= 0.000\n",
      "Step 1883, Minibatch Loss= 79.8355, Training Accuracy= 0.000\n",
      "Step 1884, Minibatch Loss= 69.8605, Training Accuracy= 0.000\n",
      "Step 1885, Minibatch Loss= 54.4779, Training Accuracy= 0.000\n",
      "Step 1886, Minibatch Loss= 62.3428, Training Accuracy= 0.000\n",
      "Step 1887, Minibatch Loss= 61.7891, Training Accuracy= 0.000\n",
      "Step 1888, Minibatch Loss= 70.1527, Training Accuracy= 0.000\n",
      "Step 1889, Minibatch Loss= 69.8995, Training Accuracy= 0.000\n",
      "Step 1890, Minibatch Loss= 49.9843, Training Accuracy= 0.000\n",
      "Step 1891, Minibatch Loss= 39.7557, Training Accuracy= 0.000\n",
      "Step 1892, Minibatch Loss= 45.1683, Training Accuracy= 0.000\n",
      "Step 1893, Minibatch Loss= 64.4505, Training Accuracy= 0.000\n",
      "Step 1894, Minibatch Loss= 82.0023, Training Accuracy= 0.000\n",
      "Step 1895, Minibatch Loss= 82.6250, Training Accuracy= 0.000\n",
      "Step 1896, Minibatch Loss= 116.1813, Training Accuracy= 0.000\n",
      "Step 1897, Minibatch Loss= 137.1580, Training Accuracy= 0.000\n",
      "Step 1898, Minibatch Loss= 85.5240, Training Accuracy= 0.000\n",
      "Step 1899, Minibatch Loss= 45.6482, Training Accuracy= 0.000\n",
      "Step 1900, Minibatch Loss= 27.1053, Training Accuracy= 0.000\n",
      "Step 1901, Minibatch Loss= 38.8699, Training Accuracy= 0.000\n",
      "Step 1902, Minibatch Loss= 41.4205, Training Accuracy= 0.000\n",
      "Step 1903, Minibatch Loss= 31.6842, Training Accuracy= 0.000\n",
      "Step 1904, Minibatch Loss= 25.5164, Training Accuracy= 0.000\n",
      "Step 1905, Minibatch Loss= 31.0714, Training Accuracy= 0.000\n",
      "Step 1906, Minibatch Loss= 44.2329, Training Accuracy= 0.000\n",
      "Step 1907, Minibatch Loss= 43.5808, Training Accuracy= 0.000\n",
      "Step 1908, Minibatch Loss= 28.6498, Training Accuracy= 0.000\n",
      "Step 1909, Minibatch Loss= 21.9317, Training Accuracy= 0.000\n",
      "Step 1910, Minibatch Loss= 20.7799, Training Accuracy= 0.000\n",
      "Step 1911, Minibatch Loss= 23.9622, Training Accuracy= 0.000\n",
      "Step 1912, Minibatch Loss= 22.5415, Training Accuracy= 0.000\n",
      "Step 1913, Minibatch Loss= 22.0094, Training Accuracy= 0.000\n",
      "Step 1914, Minibatch Loss= 21.8793, Training Accuracy= 0.000\n",
      "Step 1915, Minibatch Loss= 19.6868, Training Accuracy= 0.000\n",
      "Step 1916, Minibatch Loss= 17.2843, Training Accuracy= 0.000\n",
      "Step 1917, Minibatch Loss= 20.4988, Training Accuracy= 0.000\n",
      "Step 1918, Minibatch Loss= 20.1027, Training Accuracy= 0.000\n",
      "Step 1919, Minibatch Loss= 19.2427, Training Accuracy= 0.000\n",
      "Step 1920, Minibatch Loss= 19.2950, Training Accuracy= 0.000\n",
      "Step 1921, Minibatch Loss= 18.4120, Training Accuracy= 0.000\n",
      "Step 1922, Minibatch Loss= 17.4418, Training Accuracy= 0.000\n",
      "Step 1923, Minibatch Loss= 15.5549, Training Accuracy= 0.000\n",
      "Step 1924, Minibatch Loss= 15.8856, Training Accuracy= 0.000\n",
      "Step 1925, Minibatch Loss= 15.2069, Training Accuracy= 0.000\n",
      "Step 1926, Minibatch Loss= 14.8547, Training Accuracy= 0.000\n",
      "Step 1927, Minibatch Loss= 16.8722, Training Accuracy= 0.000\n",
      "Step 1928, Minibatch Loss= 17.4019, Training Accuracy= 0.000\n",
      "Step 1929, Minibatch Loss= 14.0214, Training Accuracy= 0.000\n",
      "Step 1930, Minibatch Loss= 14.6716, Training Accuracy= 0.000\n",
      "Step 1931, Minibatch Loss= 17.2168, Training Accuracy= 0.000\n",
      "Step 1932, Minibatch Loss= 14.4276, Training Accuracy= 0.000\n",
      "Step 1933, Minibatch Loss= 15.6562, Training Accuracy= 0.000\n",
      "Step 1934, Minibatch Loss= 18.3321, Training Accuracy= 0.000\n",
      "Step 1935, Minibatch Loss= 17.1124, Training Accuracy= 0.000\n",
      "Step 1936, Minibatch Loss= 14.1869, Training Accuracy= 0.000\n",
      "Step 1937, Minibatch Loss= 15.5928, Training Accuracy= 0.000\n",
      "Step 1938, Minibatch Loss= 14.5545, Training Accuracy= 0.000\n",
      "Step 1939, Minibatch Loss= 20.7945, Training Accuracy= 0.000\n",
      "Step 1940, Minibatch Loss= 21.8030, Training Accuracy= 0.000\n",
      "Step 1941, Minibatch Loss= 22.3838, Training Accuracy= 0.000\n",
      "Step 1942, Minibatch Loss= 22.5835, Training Accuracy= 0.000\n",
      "Step 1943, Minibatch Loss= 15.7250, Training Accuracy= 0.000\n",
      "Step 1944, Minibatch Loss= 15.5981, Training Accuracy= 0.000\n",
      "Step 1945, Minibatch Loss= 20.4859, Training Accuracy= 0.000\n",
      "Step 1946, Minibatch Loss= 19.5018, Training Accuracy= 0.000\n",
      "Step 1947, Minibatch Loss= 18.9745, Training Accuracy= 0.000\n",
      "Step 1948, Minibatch Loss= 13.2653, Training Accuracy= 0.000\n",
      "Step 1949, Minibatch Loss= 17.5614, Training Accuracy= 0.000\n",
      "Step 1950, Minibatch Loss= 19.9490, Training Accuracy= 0.000\n",
      "Step 1951, Minibatch Loss= 17.6329, Training Accuracy= 0.000\n",
      "Step 1952, Minibatch Loss= 18.9361, Training Accuracy= 0.000\n",
      "Step 1953, Minibatch Loss= 17.5233, Training Accuracy= 0.000\n",
      "Step 1954, Minibatch Loss= 16.6249, Training Accuracy= 0.000\n",
      "Step 1955, Minibatch Loss= 20.1312, Training Accuracy= 0.000\n",
      "Step 1956, Minibatch Loss= 19.4219, Training Accuracy= 0.000\n",
      "Step 1957, Minibatch Loss= 17.3244, Training Accuracy= 0.000\n",
      "Step 1958, Minibatch Loss= 14.5943, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1959, Minibatch Loss= 18.2888, Training Accuracy= 0.000\n",
      "Step 1960, Minibatch Loss= 20.2085, Training Accuracy= 0.000\n",
      "Step 1961, Minibatch Loss= 21.2360, Training Accuracy= 0.000\n",
      "Step 1962, Minibatch Loss= 17.6174, Training Accuracy= 0.000\n",
      "Step 1963, Minibatch Loss= 19.7594, Training Accuracy= 0.000\n",
      "Step 1964, Minibatch Loss= 16.6191, Training Accuracy= 0.000\n",
      "Step 1965, Minibatch Loss= 17.8726, Training Accuracy= 0.000\n",
      "Step 1966, Minibatch Loss= 17.1088, Training Accuracy= 0.000\n",
      "Step 1967, Minibatch Loss= 17.1617, Training Accuracy= 0.000\n",
      "Step 1968, Minibatch Loss= 18.9742, Training Accuracy= 0.000\n",
      "Step 1969, Minibatch Loss= 23.7331, Training Accuracy= 0.000\n",
      "Step 1970, Minibatch Loss= 32.5047, Training Accuracy= 0.000\n",
      "Step 1971, Minibatch Loss= 38.4035, Training Accuracy= 0.000\n",
      "Step 1972, Minibatch Loss= 39.7188, Training Accuracy= 0.000\n",
      "Step 1973, Minibatch Loss= 51.1121, Training Accuracy= 0.000\n",
      "Step 1974, Minibatch Loss= 55.0048, Training Accuracy= 0.000\n",
      "Step 1975, Minibatch Loss= 47.3733, Training Accuracy= 0.000\n",
      "Step 1976, Minibatch Loss= 31.6091, Training Accuracy= 0.000\n",
      "Step 1977, Minibatch Loss= 23.3589, Training Accuracy= 0.000\n",
      "Step 1978, Minibatch Loss= 20.3901, Training Accuracy= 0.000\n",
      "Step 1979, Minibatch Loss= 28.3095, Training Accuracy= 0.000\n",
      "Step 1980, Minibatch Loss= 30.3485, Training Accuracy= 0.000\n",
      "Step 1981, Minibatch Loss= 37.6914, Training Accuracy= 0.000\n",
      "Step 1982, Minibatch Loss= 40.5125, Training Accuracy= 0.000\n",
      "Step 1983, Minibatch Loss= 37.3025, Training Accuracy= 0.000\n",
      "Step 1984, Minibatch Loss= 43.0942, Training Accuracy= 0.000\n",
      "Step 1985, Minibatch Loss= 63.3760, Training Accuracy= 0.000\n",
      "Step 1986, Minibatch Loss= 105.6447, Training Accuracy= 0.000\n",
      "Step 1987, Minibatch Loss= 127.2663, Training Accuracy= 0.000\n",
      "Step 1988, Minibatch Loss= 170.5558, Training Accuracy= 0.000\n",
      "Step 1989, Minibatch Loss= 237.2547, Training Accuracy= 0.000\n",
      "Step 1990, Minibatch Loss= 315.7802, Training Accuracy= 0.000\n",
      "Step 1991, Minibatch Loss= 141.9303, Training Accuracy= 0.000\n",
      "Step 1992, Minibatch Loss= 31.8079, Training Accuracy= 0.000\n",
      "Step 1993, Minibatch Loss= 140.5635, Training Accuracy= 0.000\n",
      "Step 1994, Minibatch Loss= 181.3367, Training Accuracy= 0.000\n",
      "Step 1995, Minibatch Loss= 41.1026, Training Accuracy= 0.000\n",
      "Step 1996, Minibatch Loss= 120.4235, Training Accuracy= 0.000\n",
      "Step 1997, Minibatch Loss= 99.4088, Training Accuracy= 0.000\n",
      "Step 1998, Minibatch Loss= 36.2199, Training Accuracy= 0.000\n",
      "Step 1999, Minibatch Loss= 76.4132, Training Accuracy= 0.000\n",
      "Step 2000, Minibatch Loss= 33.1482, Training Accuracy= 0.000\n",
      "Step 2001, Minibatch Loss= 62.0345, Training Accuracy= 0.000\n",
      "Step 2002, Minibatch Loss= 36.5999, Training Accuracy= 0.000\n",
      "Step 2003, Minibatch Loss= 44.0561, Training Accuracy= 0.000\n",
      "Step 2004, Minibatch Loss= 33.4939, Training Accuracy= 0.000\n",
      "Step 2005, Minibatch Loss= 36.4658, Training Accuracy= 0.000\n",
      "Step 2006, Minibatch Loss= 33.5111, Training Accuracy= 0.000\n",
      "Step 2007, Minibatch Loss= 36.1077, Training Accuracy= 0.000\n",
      "Step 2008, Minibatch Loss= 26.9420, Training Accuracy= 0.000\n",
      "Step 2009, Minibatch Loss= 36.7991, Training Accuracy= 0.000\n",
      "Step 2010, Minibatch Loss= 35.2044, Training Accuracy= 0.000\n",
      "Step 2011, Minibatch Loss= 39.9885, Training Accuracy= 0.000\n",
      "Step 2012, Minibatch Loss= 39.1075, Training Accuracy= 0.000\n",
      "Step 2013, Minibatch Loss= 60.7753, Training Accuracy= 0.000\n",
      "Step 2014, Minibatch Loss= 54.4872, Training Accuracy= 0.000\n",
      "Step 2015, Minibatch Loss= 38.9752, Training Accuracy= 0.000\n",
      "Step 2016, Minibatch Loss= 30.1107, Training Accuracy= 0.000\n",
      "Step 2017, Minibatch Loss= 25.0397, Training Accuracy= 0.000\n",
      "Step 2018, Minibatch Loss= 21.3421, Training Accuracy= 0.000\n",
      "Step 2019, Minibatch Loss= 26.4625, Training Accuracy= 0.000\n",
      "Step 2020, Minibatch Loss= 34.8963, Training Accuracy= 0.000\n",
      "Step 2021, Minibatch Loss= 30.4933, Training Accuracy= 0.000\n",
      "Step 2022, Minibatch Loss= 27.0808, Training Accuracy= 0.000\n",
      "Step 2023, Minibatch Loss= 24.2610, Training Accuracy= 0.000\n",
      "Step 2024, Minibatch Loss= 22.7103, Training Accuracy= 0.000\n",
      "Step 2025, Minibatch Loss= 20.3742, Training Accuracy= 0.000\n",
      "Step 2026, Minibatch Loss= 25.7105, Training Accuracy= 0.000\n",
      "Step 2027, Minibatch Loss= 34.3847, Training Accuracy= 0.000\n",
      "Step 2028, Minibatch Loss= 48.2403, Training Accuracy= 0.000\n",
      "Step 2029, Minibatch Loss= 60.0197, Training Accuracy= 0.000\n",
      "Step 2030, Minibatch Loss= 90.6370, Training Accuracy= 0.000\n",
      "Step 2031, Minibatch Loss= 116.0878, Training Accuracy= 0.000\n",
      "Step 2032, Minibatch Loss= 113.5954, Training Accuracy= 0.000\n",
      "Step 2033, Minibatch Loss= 156.6982, Training Accuracy= 0.000\n",
      "Step 2034, Minibatch Loss= 129.9762, Training Accuracy= 0.000\n",
      "Step 2035, Minibatch Loss= 83.8293, Training Accuracy= 0.000\n",
      "Step 2036, Minibatch Loss= 39.5289, Training Accuracy= 0.000\n",
      "Step 2037, Minibatch Loss= 66.4274, Training Accuracy= 0.000\n",
      "Step 2038, Minibatch Loss= 79.5182, Training Accuracy= 0.000\n",
      "Step 2039, Minibatch Loss= 44.7005, Training Accuracy= 0.000\n",
      "Step 2040, Minibatch Loss= 37.0295, Training Accuracy= 0.000\n",
      "Step 2041, Minibatch Loss= 56.2190, Training Accuracy= 0.000\n",
      "Step 2042, Minibatch Loss= 51.0287, Training Accuracy= 0.000\n",
      "Step 2043, Minibatch Loss= 24.1022, Training Accuracy= 0.000\n",
      "Step 2044, Minibatch Loss= 28.8665, Training Accuracy= 0.000\n",
      "Step 2045, Minibatch Loss= 42.5150, Training Accuracy= 0.000\n",
      "Step 2046, Minibatch Loss= 41.6982, Training Accuracy= 0.000\n",
      "Step 2047, Minibatch Loss= 40.2041, Training Accuracy= 0.000\n",
      "Step 2048, Minibatch Loss= 36.6207, Training Accuracy= 0.000\n",
      "Step 2049, Minibatch Loss= 21.4011, Training Accuracy= 0.000\n",
      "Step 2050, Minibatch Loss= 29.2230, Training Accuracy= 0.000\n",
      "Step 2051, Minibatch Loss= 36.4586, Training Accuracy= 0.000\n",
      "Step 2052, Minibatch Loss= 26.2259, Training Accuracy= 0.000\n",
      "Step 2053, Minibatch Loss= 27.5065, Training Accuracy= 0.000\n",
      "Step 2054, Minibatch Loss= 22.7056, Training Accuracy= 0.000\n",
      "Step 2055, Minibatch Loss= 25.6962, Training Accuracy= 0.000\n",
      "Step 2056, Minibatch Loss= 23.3579, Training Accuracy= 0.000\n",
      "Step 2057, Minibatch Loss= 19.0678, Training Accuracy= 0.000\n",
      "Step 2058, Minibatch Loss= 23.1492, Training Accuracy= 0.000\n",
      "Step 2059, Minibatch Loss= 25.4376, Training Accuracy= 0.000\n",
      "Step 2060, Minibatch Loss= 27.2300, Training Accuracy= 0.000\n",
      "Step 2061, Minibatch Loss= 23.9088, Training Accuracy= 0.000\n",
      "Step 2062, Minibatch Loss= 21.6052, Training Accuracy= 0.000\n",
      "Step 2063, Minibatch Loss= 26.1090, Training Accuracy= 0.000\n",
      "Step 2064, Minibatch Loss= 21.6876, Training Accuracy= 0.000\n",
      "Step 2065, Minibatch Loss= 26.4740, Training Accuracy= 0.000\n",
      "Step 2066, Minibatch Loss= 21.5030, Training Accuracy= 0.000\n",
      "Step 2067, Minibatch Loss= 22.3832, Training Accuracy= 0.000\n",
      "Step 2068, Minibatch Loss= 18.1252, Training Accuracy= 0.000\n",
      "Step 2069, Minibatch Loss= 17.9732, Training Accuracy= 0.000\n",
      "Step 2070, Minibatch Loss= 15.6136, Training Accuracy= 0.000\n",
      "Step 2071, Minibatch Loss= 15.0306, Training Accuracy= 0.000\n",
      "Step 2072, Minibatch Loss= 14.5921, Training Accuracy= 0.000\n",
      "Step 2073, Minibatch Loss= 14.2555, Training Accuracy= 0.000\n",
      "Step 2074, Minibatch Loss= 16.6250, Training Accuracy= 0.000\n",
      "Step 2075, Minibatch Loss= 15.3076, Training Accuracy= 0.000\n",
      "Step 2076, Minibatch Loss= 16.8232, Training Accuracy= 0.000\n",
      "Step 2077, Minibatch Loss= 15.4311, Training Accuracy= 0.000\n",
      "Step 2078, Minibatch Loss= 12.4332, Training Accuracy= 0.000\n",
      "Step 2079, Minibatch Loss= 13.5603, Training Accuracy= 0.000\n",
      "Step 2080, Minibatch Loss= 11.9688, Training Accuracy= 0.000\n",
      "Step 2081, Minibatch Loss= 13.8030, Training Accuracy= 0.000\n",
      "Step 2082, Minibatch Loss= 16.3625, Training Accuracy= 0.000\n",
      "Step 2083, Minibatch Loss= 18.3409, Training Accuracy= 0.000\n",
      "Step 2084, Minibatch Loss= 16.5172, Training Accuracy= 0.000\n",
      "Step 2085, Minibatch Loss= 16.0760, Training Accuracy= 0.000\n",
      "Step 2086, Minibatch Loss= 14.5252, Training Accuracy= 0.000\n",
      "Step 2087, Minibatch Loss= 12.4905, Training Accuracy= 0.000\n",
      "Step 2088, Minibatch Loss= 14.1852, Training Accuracy= 0.000\n",
      "Step 2089, Minibatch Loss= 18.2754, Training Accuracy= 0.000\n",
      "Step 2090, Minibatch Loss= 17.8040, Training Accuracy= 0.000\n",
      "Step 2091, Minibatch Loss= 15.0785, Training Accuracy= 0.000\n",
      "Step 2092, Minibatch Loss= 13.6830, Training Accuracy= 0.000\n",
      "Step 2093, Minibatch Loss= 12.8526, Training Accuracy= 0.000\n",
      "Step 2094, Minibatch Loss= 16.3603, Training Accuracy= 0.000\n",
      "Step 2095, Minibatch Loss= 14.4963, Training Accuracy= 0.000\n",
      "Step 2096, Minibatch Loss= 12.6944, Training Accuracy= 0.000\n",
      "Step 2097, Minibatch Loss= 14.8507, Training Accuracy= 0.000\n",
      "Step 2098, Minibatch Loss= 11.8892, Training Accuracy= 0.000\n",
      "Step 2099, Minibatch Loss= 14.2024, Training Accuracy= 0.000\n",
      "Step 2100, Minibatch Loss= 14.5020, Training Accuracy= 0.000\n",
      "Step 2101, Minibatch Loss= 15.5865, Training Accuracy= 0.000\n",
      "Step 2102, Minibatch Loss= 16.9251, Training Accuracy= 0.000\n",
      "Step 2103, Minibatch Loss= 12.5608, Training Accuracy= 0.000\n",
      "Step 2104, Minibatch Loss= 13.2010, Training Accuracy= 0.000\n",
      "Step 2105, Minibatch Loss= 13.8790, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2106, Minibatch Loss= 14.3213, Training Accuracy= 0.000\n",
      "Step 2107, Minibatch Loss= 18.9798, Training Accuracy= 0.000\n",
      "Step 2108, Minibatch Loss= 19.3068, Training Accuracy= 0.000\n",
      "Step 2109, Minibatch Loss= 18.7595, Training Accuracy= 0.000\n",
      "Step 2110, Minibatch Loss= 20.6002, Training Accuracy= 0.000\n",
      "Step 2111, Minibatch Loss= 21.5668, Training Accuracy= 0.000\n",
      "Step 2112, Minibatch Loss= 20.7869, Training Accuracy= 0.000\n",
      "Step 2113, Minibatch Loss= 21.4897, Training Accuracy= 0.000\n",
      "Step 2114, Minibatch Loss= 25.4683, Training Accuracy= 0.000\n",
      "Step 2115, Minibatch Loss= 30.3126, Training Accuracy= 0.000\n",
      "Step 2116, Minibatch Loss= 35.3835, Training Accuracy= 0.000\n",
      "Step 2117, Minibatch Loss= 37.4244, Training Accuracy= 0.000\n",
      "Step 2118, Minibatch Loss= 49.3372, Training Accuracy= 0.000\n",
      "Step 2119, Minibatch Loss= 54.8156, Training Accuracy= 0.000\n",
      "Step 2120, Minibatch Loss= 45.8620, Training Accuracy= 0.000\n",
      "Step 2121, Minibatch Loss= 47.3135, Training Accuracy= 0.000\n",
      "Step 2122, Minibatch Loss= 39.6626, Training Accuracy= 0.000\n",
      "Step 2123, Minibatch Loss= 37.2675, Training Accuracy= 0.000\n",
      "Step 2124, Minibatch Loss= 47.7313, Training Accuracy= 0.000\n",
      "Step 2125, Minibatch Loss= 47.9236, Training Accuracy= 0.000\n",
      "Step 2126, Minibatch Loss= 48.6620, Training Accuracy= 0.000\n",
      "Step 2127, Minibatch Loss= 48.1357, Training Accuracy= 0.000\n",
      "Step 2128, Minibatch Loss= 47.3764, Training Accuracy= 0.000\n",
      "Step 2129, Minibatch Loss= 36.8076, Training Accuracy= 0.000\n",
      "Step 2130, Minibatch Loss= 29.1075, Training Accuracy= 0.000\n",
      "Step 2131, Minibatch Loss= 24.2073, Training Accuracy= 0.000\n",
      "Step 2132, Minibatch Loss= 23.8043, Training Accuracy= 0.000\n",
      "Step 2133, Minibatch Loss= 30.3401, Training Accuracy= 0.000\n",
      "Step 2134, Minibatch Loss= 31.4260, Training Accuracy= 0.000\n",
      "Step 2135, Minibatch Loss= 27.9093, Training Accuracy= 0.000\n",
      "Step 2136, Minibatch Loss= 26.5160, Training Accuracy= 0.000\n",
      "Step 2137, Minibatch Loss= 26.1372, Training Accuracy= 0.000\n",
      "Step 2138, Minibatch Loss= 20.5846, Training Accuracy= 0.000\n",
      "Step 2139, Minibatch Loss= 17.8891, Training Accuracy= 0.000\n",
      "Step 2140, Minibatch Loss= 18.9673, Training Accuracy= 0.000\n",
      "Step 2141, Minibatch Loss= 26.9519, Training Accuracy= 0.000\n",
      "Step 2142, Minibatch Loss= 45.3880, Training Accuracy= 0.000\n",
      "Step 2143, Minibatch Loss= 58.0517, Training Accuracy= 0.000\n",
      "Step 2144, Minibatch Loss= 61.4813, Training Accuracy= 0.000\n",
      "Step 2145, Minibatch Loss= 54.0112, Training Accuracy= 0.000\n",
      "Step 2146, Minibatch Loss= 76.8629, Training Accuracy= 0.000\n",
      "Step 2147, Minibatch Loss= 152.7035, Training Accuracy= 0.000\n",
      "Step 2148, Minibatch Loss= 245.9786, Training Accuracy= 0.000\n",
      "Step 2149, Minibatch Loss= 288.2957, Training Accuracy= 0.000\n",
      "Step 2150, Minibatch Loss= 206.4699, Training Accuracy= 0.000\n",
      "Step 2151, Minibatch Loss= 138.7779, Training Accuracy= 0.000\n",
      "Step 2152, Minibatch Loss= 48.7420, Training Accuracy= 0.000\n",
      "Step 2153, Minibatch Loss= 85.6073, Training Accuracy= 0.000\n",
      "Step 2154, Minibatch Loss= 133.3685, Training Accuracy= 0.000\n",
      "Step 2155, Minibatch Loss= 57.9556, Training Accuracy= 0.000\n",
      "Step 2156, Minibatch Loss= 81.6244, Training Accuracy= 0.000\n",
      "Step 2157, Minibatch Loss= 71.2167, Training Accuracy= 0.000\n",
      "Step 2158, Minibatch Loss= 52.4693, Training Accuracy= 0.000\n",
      "Step 2159, Minibatch Loss= 68.3117, Training Accuracy= 0.000\n",
      "Step 2160, Minibatch Loss= 35.1167, Training Accuracy= 0.000\n",
      "Step 2161, Minibatch Loss= 60.8433, Training Accuracy= 0.000\n",
      "Step 2162, Minibatch Loss= 37.5706, Training Accuracy= 0.000\n",
      "Step 2163, Minibatch Loss= 53.2053, Training Accuracy= 0.000\n",
      "Step 2164, Minibatch Loss= 49.3552, Training Accuracy= 0.000\n",
      "Step 2165, Minibatch Loss= 83.2192, Training Accuracy= 0.000\n",
      "Step 2166, Minibatch Loss= 118.3481, Training Accuracy= 0.000\n",
      "Step 2167, Minibatch Loss= 139.9313, Training Accuracy= 0.000\n",
      "Step 2168, Minibatch Loss= 191.5008, Training Accuracy= 0.000\n",
      "Step 2169, Minibatch Loss= 144.8534, Training Accuracy= 0.000\n",
      "Step 2170, Minibatch Loss= 94.7128, Training Accuracy= 0.000\n",
      "Step 2171, Minibatch Loss= 54.3174, Training Accuracy= 0.000\n",
      "Step 2172, Minibatch Loss= 50.9137, Training Accuracy= 0.000\n",
      "Step 2173, Minibatch Loss= 83.2900, Training Accuracy= 0.000\n",
      "Step 2174, Minibatch Loss= 60.8693, Training Accuracy= 0.000\n",
      "Step 2175, Minibatch Loss= 43.9579, Training Accuracy= 0.000\n",
      "Step 2176, Minibatch Loss= 65.7468, Training Accuracy= 0.000\n",
      "Step 2177, Minibatch Loss= 36.9729, Training Accuracy= 0.000\n",
      "Step 2178, Minibatch Loss= 37.3979, Training Accuracy= 0.000\n",
      "Step 2179, Minibatch Loss= 47.6028, Training Accuracy= 0.000\n",
      "Step 2180, Minibatch Loss= 40.0930, Training Accuracy= 0.000\n",
      "Step 2181, Minibatch Loss= 55.2301, Training Accuracy= 0.000\n",
      "Step 2182, Minibatch Loss= 69.9770, Training Accuracy= 0.000\n",
      "Step 2183, Minibatch Loss= 56.7246, Training Accuracy= 0.000\n",
      "Step 2184, Minibatch Loss= 80.7667, Training Accuracy= 0.000\n",
      "Step 2185, Minibatch Loss= 77.7204, Training Accuracy= 0.000\n",
      "Step 2186, Minibatch Loss= 85.6247, Training Accuracy= 0.000\n",
      "Step 2187, Minibatch Loss= 57.9686, Training Accuracy= 0.000\n",
      "Step 2188, Minibatch Loss= 41.3490, Training Accuracy= 0.000\n",
      "Step 2189, Minibatch Loss= 34.6887, Training Accuracy= 0.000\n",
      "Step 2190, Minibatch Loss= 32.7699, Training Accuracy= 0.000\n",
      "Step 2191, Minibatch Loss= 32.8890, Training Accuracy= 0.000\n",
      "Step 2192, Minibatch Loss= 30.4276, Training Accuracy= 0.000\n",
      "Step 2193, Minibatch Loss= 28.9641, Training Accuracy= 0.000\n",
      "Step 2194, Minibatch Loss= 21.6277, Training Accuracy= 0.000\n",
      "Step 2195, Minibatch Loss= 26.9093, Training Accuracy= 0.000\n",
      "Step 2196, Minibatch Loss= 24.5433, Training Accuracy= 0.000\n",
      "Step 2197, Minibatch Loss= 20.2915, Training Accuracy= 0.000\n",
      "Step 2198, Minibatch Loss= 15.5464, Training Accuracy= 0.000\n",
      "Step 2199, Minibatch Loss= 18.0469, Training Accuracy= 0.000\n",
      "Step 2200, Minibatch Loss= 21.0449, Training Accuracy= 0.000\n",
      "Step 2201, Minibatch Loss= 23.0021, Training Accuracy= 0.000\n",
      "Step 2202, Minibatch Loss= 21.7579, Training Accuracy= 0.000\n",
      "Step 2203, Minibatch Loss= 20.9649, Training Accuracy= 0.000\n",
      "Step 2204, Minibatch Loss= 18.1452, Training Accuracy= 0.000\n",
      "Step 2205, Minibatch Loss= 18.7769, Training Accuracy= 0.000\n",
      "Step 2206, Minibatch Loss= 16.0442, Training Accuracy= 0.000\n",
      "Step 2207, Minibatch Loss= 12.3063, Training Accuracy= 0.000\n",
      "Step 2208, Minibatch Loss= 14.1120, Training Accuracy= 0.000\n",
      "Step 2209, Minibatch Loss= 17.4892, Training Accuracy= 0.000\n",
      "Step 2210, Minibatch Loss= 17.9026, Training Accuracy= 0.000\n",
      "Step 2211, Minibatch Loss= 15.9939, Training Accuracy= 0.000\n",
      "Step 2212, Minibatch Loss= 14.5065, Training Accuracy= 0.000\n",
      "Step 2213, Minibatch Loss= 13.7895, Training Accuracy= 0.000\n",
      "Step 2214, Minibatch Loss= 15.1485, Training Accuracy= 0.000\n",
      "Step 2215, Minibatch Loss= 17.7558, Training Accuracy= 0.000\n",
      "Step 2216, Minibatch Loss= 16.3852, Training Accuracy= 0.000\n",
      "Step 2217, Minibatch Loss= 15.4565, Training Accuracy= 0.000\n",
      "Step 2218, Minibatch Loss= 13.3234, Training Accuracy= 0.000\n",
      "Step 2219, Minibatch Loss= 14.0529, Training Accuracy= 0.000\n",
      "Step 2220, Minibatch Loss= 18.9665, Training Accuracy= 0.000\n",
      "Step 2221, Minibatch Loss= 17.9394, Training Accuracy= 0.000\n",
      "Step 2222, Minibatch Loss= 14.2536, Training Accuracy= 0.000\n",
      "Step 2223, Minibatch Loss= 11.8262, Training Accuracy= 0.000\n",
      "Step 2224, Minibatch Loss= 14.4580, Training Accuracy= 0.000\n",
      "Step 2225, Minibatch Loss= 14.7586, Training Accuracy= 0.000\n",
      "Step 2226, Minibatch Loss= 13.9052, Training Accuracy= 0.000\n",
      "Step 2227, Minibatch Loss= 14.2549, Training Accuracy= 0.000\n",
      "Step 2228, Minibatch Loss= 14.0746, Training Accuracy= 0.000\n",
      "Step 2229, Minibatch Loss= 13.1687, Training Accuracy= 0.000\n",
      "Step 2230, Minibatch Loss= 14.3173, Training Accuracy= 0.000\n",
      "Step 2231, Minibatch Loss= 12.8174, Training Accuracy= 0.000\n",
      "Step 2232, Minibatch Loss= 12.6480, Training Accuracy= 0.000\n",
      "Step 2233, Minibatch Loss= 13.1913, Training Accuracy= 0.000\n",
      "Step 2234, Minibatch Loss= 16.2345, Training Accuracy= 0.000\n",
      "Step 2235, Minibatch Loss= 16.1156, Training Accuracy= 0.000\n",
      "Step 2236, Minibatch Loss= 16.5564, Training Accuracy= 0.000\n",
      "Step 2237, Minibatch Loss= 15.7767, Training Accuracy= 0.000\n",
      "Step 2238, Minibatch Loss= 18.7969, Training Accuracy= 0.000\n",
      "Step 2239, Minibatch Loss= 18.6502, Training Accuracy= 0.000\n",
      "Step 2240, Minibatch Loss= 21.2896, Training Accuracy= 0.000\n",
      "Step 2241, Minibatch Loss= 19.7413, Training Accuracy= 0.000\n",
      "Step 2242, Minibatch Loss= 16.2884, Training Accuracy= 0.000\n",
      "Step 2243, Minibatch Loss= 13.3200, Training Accuracy= 0.000\n",
      "Step 2244, Minibatch Loss= 15.1769, Training Accuracy= 0.000\n",
      "Step 2245, Minibatch Loss= 12.1381, Training Accuracy= 0.000\n",
      "Step 2246, Minibatch Loss= 13.1473, Training Accuracy= 0.000\n",
      "Step 2247, Minibatch Loss= 16.3511, Training Accuracy= 0.000\n",
      "Step 2248, Minibatch Loss= 16.9182, Training Accuracy= 0.000\n",
      "Step 2249, Minibatch Loss= 16.6257, Training Accuracy= 0.000\n",
      "Step 2250, Minibatch Loss= 15.2211, Training Accuracy= 0.000\n",
      "Step 2251, Minibatch Loss= 17.3245, Training Accuracy= 0.000\n",
      "Step 2252, Minibatch Loss= 21.1367, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2253, Minibatch Loss= 20.8290, Training Accuracy= 0.000\n",
      "Step 2254, Minibatch Loss= 21.2239, Training Accuracy= 0.000\n",
      "Step 2255, Minibatch Loss= 22.1040, Training Accuracy= 0.000\n",
      "Step 2256, Minibatch Loss= 20.4190, Training Accuracy= 0.000\n",
      "Step 2257, Minibatch Loss= 15.9397, Training Accuracy= 0.000\n",
      "Step 2258, Minibatch Loss= 13.9029, Training Accuracy= 0.000\n",
      "Step 2259, Minibatch Loss= 16.6361, Training Accuracy= 0.000\n",
      "Step 2260, Minibatch Loss= 22.1076, Training Accuracy= 0.000\n",
      "Step 2261, Minibatch Loss= 26.7320, Training Accuracy= 0.000\n",
      "Step 2262, Minibatch Loss= 31.1383, Training Accuracy= 0.000\n",
      "Step 2263, Minibatch Loss= 30.3859, Training Accuracy= 0.000\n",
      "Step 2264, Minibatch Loss= 47.3211, Training Accuracy= 0.000\n",
      "Step 2265, Minibatch Loss= 78.3590, Training Accuracy= 0.000\n",
      "Step 2266, Minibatch Loss= 77.4422, Training Accuracy= 0.000\n",
      "Step 2267, Minibatch Loss= 101.2181, Training Accuracy= 0.000\n",
      "Step 2268, Minibatch Loss= 66.9499, Training Accuracy= 0.000\n",
      "Step 2269, Minibatch Loss= 30.9782, Training Accuracy= 0.000\n",
      "Step 2270, Minibatch Loss= 40.3622, Training Accuracy= 0.000\n",
      "Step 2271, Minibatch Loss= 56.7807, Training Accuracy= 0.000\n",
      "Step 2272, Minibatch Loss= 58.3426, Training Accuracy= 0.000\n",
      "Step 2273, Minibatch Loss= 49.4045, Training Accuracy= 0.000\n",
      "Step 2274, Minibatch Loss= 33.9764, Training Accuracy= 0.000\n",
      "Step 2275, Minibatch Loss= 39.2750, Training Accuracy= 0.000\n",
      "Step 2276, Minibatch Loss= 66.0694, Training Accuracy= 0.000\n",
      "Step 2277, Minibatch Loss= 77.1379, Training Accuracy= 0.000\n",
      "Step 2278, Minibatch Loss= 53.6362, Training Accuracy= 0.000\n",
      "Step 2279, Minibatch Loss= 67.6024, Training Accuracy= 0.000\n",
      "Step 2280, Minibatch Loss= 51.5064, Training Accuracy= 0.000\n",
      "Step 2281, Minibatch Loss= 28.0992, Training Accuracy= 0.000\n",
      "Step 2282, Minibatch Loss= 27.3362, Training Accuracy= 0.000\n",
      "Step 2283, Minibatch Loss= 23.3088, Training Accuracy= 0.000\n",
      "Step 2284, Minibatch Loss= 21.4302, Training Accuracy= 0.000\n",
      "Step 2285, Minibatch Loss= 26.8250, Training Accuracy= 0.000\n",
      "Step 2286, Minibatch Loss= 23.1901, Training Accuracy= 0.000\n",
      "Step 2287, Minibatch Loss= 18.7353, Training Accuracy= 0.000\n",
      "Step 2288, Minibatch Loss= 22.2350, Training Accuracy= 0.000\n",
      "Step 2289, Minibatch Loss= 25.8942, Training Accuracy= 0.000\n",
      "Step 2290, Minibatch Loss= 21.6743, Training Accuracy= 0.000\n",
      "Step 2291, Minibatch Loss= 18.9898, Training Accuracy= 0.000\n",
      "Step 2292, Minibatch Loss= 15.6654, Training Accuracy= 0.000\n",
      "Step 2293, Minibatch Loss= 14.7100, Training Accuracy= 0.000\n",
      "Step 2294, Minibatch Loss= 18.4310, Training Accuracy= 0.000\n",
      "Step 2295, Minibatch Loss= 17.1211, Training Accuracy= 0.000\n",
      "Step 2296, Minibatch Loss= 15.4498, Training Accuracy= 0.000\n",
      "Step 2297, Minibatch Loss= 18.0742, Training Accuracy= 0.000\n",
      "Step 2298, Minibatch Loss= 14.5465, Training Accuracy= 0.000\n",
      "Step 2299, Minibatch Loss= 14.4213, Training Accuracy= 0.000\n",
      "Step 2300, Minibatch Loss= 14.9627, Training Accuracy= 0.000\n",
      "Step 2301, Minibatch Loss= 13.4048, Training Accuracy= 0.000\n",
      "Step 2302, Minibatch Loss= 12.8791, Training Accuracy= 0.000\n",
      "Step 2303, Minibatch Loss= 13.8248, Training Accuracy= 0.000\n",
      "Step 2304, Minibatch Loss= 14.0831, Training Accuracy= 0.000\n",
      "Step 2305, Minibatch Loss= 11.8953, Training Accuracy= 0.000\n",
      "Step 2306, Minibatch Loss= 12.4978, Training Accuracy= 0.000\n",
      "Step 2307, Minibatch Loss= 14.5243, Training Accuracy= 0.000\n",
      "Step 2308, Minibatch Loss= 13.1376, Training Accuracy= 0.000\n",
      "Step 2309, Minibatch Loss= 12.6666, Training Accuracy= 0.000\n",
      "Step 2310, Minibatch Loss= 11.0333, Training Accuracy= 0.000\n",
      "Step 2311, Minibatch Loss= 11.7739, Training Accuracy= 0.000\n",
      "Step 2312, Minibatch Loss= 13.8602, Training Accuracy= 0.000\n",
      "Step 2313, Minibatch Loss= 16.0174, Training Accuracy= 0.000\n",
      "Step 2314, Minibatch Loss= 16.5849, Training Accuracy= 0.000\n",
      "Step 2315, Minibatch Loss= 16.8907, Training Accuracy= 0.000\n",
      "Step 2316, Minibatch Loss= 16.5450, Training Accuracy= 0.000\n",
      "Step 2317, Minibatch Loss= 13.5915, Training Accuracy= 0.000\n",
      "Step 2318, Minibatch Loss= 11.9917, Training Accuracy= 0.000\n",
      "Step 2319, Minibatch Loss= 13.3561, Training Accuracy= 0.000\n",
      "Step 2320, Minibatch Loss= 11.6409, Training Accuracy= 0.000\n",
      "Step 2321, Minibatch Loss= 12.5355, Training Accuracy= 0.000\n",
      "Step 2322, Minibatch Loss= 12.0523, Training Accuracy= 0.000\n",
      "Step 2323, Minibatch Loss= 12.2170, Training Accuracy= 0.000\n",
      "Step 2324, Minibatch Loss= 14.4336, Training Accuracy= 0.000\n",
      "Step 2325, Minibatch Loss= 16.4955, Training Accuracy= 0.000\n",
      "Step 2326, Minibatch Loss= 16.8233, Training Accuracy= 0.000\n",
      "Step 2327, Minibatch Loss= 15.7780, Training Accuracy= 0.000\n",
      "Step 2328, Minibatch Loss= 14.4192, Training Accuracy= 0.000\n",
      "Step 2329, Minibatch Loss= 14.0493, Training Accuracy= 0.000\n",
      "Step 2330, Minibatch Loss= 14.5166, Training Accuracy= 0.000\n",
      "Step 2331, Minibatch Loss= 15.3465, Training Accuracy= 0.000\n",
      "Step 2332, Minibatch Loss= 16.0149, Training Accuracy= 0.000\n",
      "Step 2333, Minibatch Loss= 14.4320, Training Accuracy= 0.000\n",
      "Step 2334, Minibatch Loss= 12.4864, Training Accuracy= 0.000\n",
      "Step 2335, Minibatch Loss= 14.0009, Training Accuracy= 0.000\n",
      "Step 2336, Minibatch Loss= 15.3347, Training Accuracy= 0.000\n",
      "Step 2337, Minibatch Loss= 13.0778, Training Accuracy= 0.000\n",
      "Step 2338, Minibatch Loss= 13.9677, Training Accuracy= 0.000\n",
      "Step 2339, Minibatch Loss= 15.1692, Training Accuracy= 0.000\n",
      "Step 2340, Minibatch Loss= 12.5863, Training Accuracy= 0.000\n",
      "Step 2341, Minibatch Loss= 11.2239, Training Accuracy= 0.000\n",
      "Step 2342, Minibatch Loss= 12.3593, Training Accuracy= 0.000\n",
      "Step 2343, Minibatch Loss= 12.1408, Training Accuracy= 0.000\n",
      "Step 2344, Minibatch Loss= 11.5503, Training Accuracy= 0.000\n",
      "Step 2345, Minibatch Loss= 10.8269, Training Accuracy= 0.000\n",
      "Step 2346, Minibatch Loss= 11.6405, Training Accuracy= 0.000\n",
      "Step 2347, Minibatch Loss= 10.7065, Training Accuracy= 0.000\n",
      "Step 2348, Minibatch Loss= 10.5102, Training Accuracy= 0.000\n",
      "Step 2349, Minibatch Loss= 10.6993, Training Accuracy= 0.000\n",
      "Step 2350, Minibatch Loss= 11.8278, Training Accuracy= 0.000\n",
      "Step 2351, Minibatch Loss= 12.5432, Training Accuracy= 0.000\n",
      "Step 2352, Minibatch Loss= 10.9497, Training Accuracy= 0.000\n",
      "Step 2353, Minibatch Loss= 12.9336, Training Accuracy= 0.000\n",
      "Step 2354, Minibatch Loss= 13.2657, Training Accuracy= 0.000\n",
      "Step 2355, Minibatch Loss= 9.9996, Training Accuracy= 0.000\n",
      "Step 2356, Minibatch Loss= 9.2978, Training Accuracy= 0.000\n",
      "Step 2357, Minibatch Loss= 10.8738, Training Accuracy= 0.000\n",
      "Step 2358, Minibatch Loss= 10.2511, Training Accuracy= 0.000\n",
      "Step 2359, Minibatch Loss= 9.5076, Training Accuracy= 0.000\n",
      "Step 2360, Minibatch Loss= 11.4067, Training Accuracy= 0.000\n",
      "Step 2361, Minibatch Loss= 15.9498, Training Accuracy= 0.000\n",
      "Step 2362, Minibatch Loss= 15.6893, Training Accuracy= 0.000\n",
      "Step 2363, Minibatch Loss= 13.6967, Training Accuracy= 0.000\n",
      "Step 2364, Minibatch Loss= 10.9525, Training Accuracy= 0.000\n",
      "Step 2365, Minibatch Loss= 10.0108, Training Accuracy= 0.000\n",
      "Step 2366, Minibatch Loss= 14.3387, Training Accuracy= 0.000\n",
      "Step 2367, Minibatch Loss= 18.8456, Training Accuracy= 0.000\n",
      "Step 2368, Minibatch Loss= 20.1474, Training Accuracy= 0.000\n",
      "Step 2369, Minibatch Loss= 22.9796, Training Accuracy= 0.000\n",
      "Step 2370, Minibatch Loss= 27.0817, Training Accuracy= 0.000\n",
      "Step 2371, Minibatch Loss= 26.8570, Training Accuracy= 0.000\n",
      "Step 2372, Minibatch Loss= 25.1906, Training Accuracy= 0.000\n",
      "Step 2373, Minibatch Loss= 17.9137, Training Accuracy= 0.000\n",
      "Step 2374, Minibatch Loss= 17.2647, Training Accuracy= 0.000\n",
      "Step 2375, Minibatch Loss= 18.6595, Training Accuracy= 0.000\n",
      "Step 2376, Minibatch Loss= 18.1455, Training Accuracy= 0.000\n",
      "Step 2377, Minibatch Loss= 14.1485, Training Accuracy= 0.000\n",
      "Step 2378, Minibatch Loss= 15.8587, Training Accuracy= 0.000\n",
      "Step 2379, Minibatch Loss= 16.3571, Training Accuracy= 0.000\n",
      "Step 2380, Minibatch Loss= 19.6824, Training Accuracy= 0.000\n",
      "Step 2381, Minibatch Loss= 23.6040, Training Accuracy= 0.000\n",
      "Step 2382, Minibatch Loss= 25.4725, Training Accuracy= 0.000\n",
      "Step 2383, Minibatch Loss= 33.4078, Training Accuracy= 0.000\n",
      "Step 2384, Minibatch Loss= 36.9066, Training Accuracy= 0.000\n",
      "Step 2385, Minibatch Loss= 53.3998, Training Accuracy= 0.000\n",
      "Step 2386, Minibatch Loss= 57.0697, Training Accuracy= 0.000\n",
      "Step 2387, Minibatch Loss= 46.3854, Training Accuracy= 0.000\n",
      "Step 2388, Minibatch Loss= 25.6763, Training Accuracy= 0.000\n",
      "Step 2389, Minibatch Loss= 19.4006, Training Accuracy= 0.000\n",
      "Step 2390, Minibatch Loss= 23.6103, Training Accuracy= 0.000\n",
      "Step 2391, Minibatch Loss= 27.0059, Training Accuracy= 0.000\n",
      "Step 2392, Minibatch Loss= 23.1943, Training Accuracy= 0.000\n",
      "Step 2393, Minibatch Loss= 16.0942, Training Accuracy= 0.000\n",
      "Step 2394, Minibatch Loss= 16.8073, Training Accuracy= 0.000\n",
      "Step 2395, Minibatch Loss= 16.9730, Training Accuracy= 0.000\n",
      "Step 2396, Minibatch Loss= 16.6793, Training Accuracy= 0.000\n",
      "Step 2397, Minibatch Loss= 15.7472, Training Accuracy= 0.000\n",
      "Step 2398, Minibatch Loss= 14.4775, Training Accuracy= 0.000\n",
      "Step 2399, Minibatch Loss= 17.3364, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2400, Minibatch Loss= 18.5223, Training Accuracy= 0.000\n",
      "Step 2401, Minibatch Loss= 17.1007, Training Accuracy= 0.000\n",
      "Step 2402, Minibatch Loss= 18.8923, Training Accuracy= 0.000\n",
      "Step 2403, Minibatch Loss= 25.3404, Training Accuracy= 0.000\n",
      "Step 2404, Minibatch Loss= 23.9113, Training Accuracy= 0.000\n",
      "Step 2405, Minibatch Loss= 23.5092, Training Accuracy= 0.000\n",
      "Step 2406, Minibatch Loss= 26.7104, Training Accuracy= 0.000\n",
      "Step 2407, Minibatch Loss= 23.5047, Training Accuracy= 0.000\n",
      "Step 2408, Minibatch Loss= 32.0369, Training Accuracy= 0.000\n",
      "Step 2409, Minibatch Loss= 28.5523, Training Accuracy= 0.000\n",
      "Step 2410, Minibatch Loss= 38.5725, Training Accuracy= 0.000\n",
      "Step 2411, Minibatch Loss= 45.2412, Training Accuracy= 0.000\n",
      "Step 2412, Minibatch Loss= 51.1999, Training Accuracy= 0.000\n",
      "Step 2413, Minibatch Loss= 57.8478, Training Accuracy= 0.000\n",
      "Step 2414, Minibatch Loss= 48.9937, Training Accuracy= 0.000\n",
      "Step 2415, Minibatch Loss= 44.9434, Training Accuracy= 0.000\n",
      "Step 2416, Minibatch Loss= 44.2294, Training Accuracy= 0.000\n",
      "Step 2417, Minibatch Loss= 65.1742, Training Accuracy= 0.000\n",
      "Step 2418, Minibatch Loss= 92.3313, Training Accuracy= 0.000\n",
      "Step 2419, Minibatch Loss= 111.0649, Training Accuracy= 0.000\n",
      "Step 2420, Minibatch Loss= 166.6499, Training Accuracy= 0.000\n",
      "Step 2421, Minibatch Loss= 322.9054, Training Accuracy= 0.000\n",
      "Step 2422, Minibatch Loss= 430.5839, Training Accuracy= 0.000\n",
      "Step 2423, Minibatch Loss= 149.9382, Training Accuracy= 0.000\n",
      "Step 2424, Minibatch Loss= 113.9003, Training Accuracy= 0.000\n",
      "Step 2425, Minibatch Loss= 245.9456, Training Accuracy= 0.000\n",
      "Step 2426, Minibatch Loss= 195.9812, Training Accuracy= 0.000\n",
      "Step 2427, Minibatch Loss= 142.3943, Training Accuracy= 0.000\n",
      "Step 2428, Minibatch Loss= 241.5722, Training Accuracy= 0.000\n",
      "Step 2429, Minibatch Loss= 178.5276, Training Accuracy= 0.000\n",
      "Step 2430, Minibatch Loss= 163.0210, Training Accuracy= 0.000\n",
      "Step 2431, Minibatch Loss= 230.8614, Training Accuracy= 0.000\n",
      "Step 2432, Minibatch Loss= 220.7636, Training Accuracy= 0.000\n",
      "Step 2433, Minibatch Loss= 264.7825, Training Accuracy= 0.000\n",
      "Step 2434, Minibatch Loss= 313.2240, Training Accuracy= 0.000\n",
      "Step 2435, Minibatch Loss= 470.5087, Training Accuracy= 0.000\n",
      "Step 2436, Minibatch Loss= 414.9381, Training Accuracy= 0.000\n",
      "Step 2437, Minibatch Loss= 519.2968, Training Accuracy= 0.000\n",
      "Step 2438, Minibatch Loss= 482.3676, Training Accuracy= 0.000\n",
      "Step 2439, Minibatch Loss= 415.0359, Training Accuracy= 0.000\n",
      "Step 2440, Minibatch Loss= 466.9663, Training Accuracy= 0.000\n",
      "Step 2441, Minibatch Loss= 476.0406, Training Accuracy= 0.000\n",
      "Step 2442, Minibatch Loss= 469.9008, Training Accuracy= 0.000\n",
      "Step 2443, Minibatch Loss= 567.5078, Training Accuracy= 0.000\n",
      "Step 2444, Minibatch Loss= 354.7382, Training Accuracy= 0.000\n",
      "Step 2445, Minibatch Loss= 419.4848, Training Accuracy= 0.000\n",
      "Step 2446, Minibatch Loss= 431.6025, Training Accuracy= 0.000\n",
      "Step 2447, Minibatch Loss= 358.0229, Training Accuracy= 0.000\n",
      "Step 2448, Minibatch Loss= 523.5459, Training Accuracy= 0.000\n",
      "Step 2449, Minibatch Loss= 617.7472, Training Accuracy= 0.000\n",
      "Step 2450, Minibatch Loss= 602.8972, Training Accuracy= 0.000\n",
      "Step 2451, Minibatch Loss= 514.0045, Training Accuracy= 0.000\n",
      "Step 2452, Minibatch Loss= 599.0958, Training Accuracy= 0.000\n",
      "Step 2453, Minibatch Loss= 213.2063, Training Accuracy= 0.000\n",
      "Step 2454, Minibatch Loss= 380.5178, Training Accuracy= 0.000\n",
      "Step 2455, Minibatch Loss= 274.1767, Training Accuracy= 0.000\n",
      "Step 2456, Minibatch Loss= 224.9969, Training Accuracy= 0.000\n",
      "Step 2457, Minibatch Loss= 202.7212, Training Accuracy= 0.000\n",
      "Step 2458, Minibatch Loss= 304.7668, Training Accuracy= 0.000\n",
      "Step 2459, Minibatch Loss= 218.7891, Training Accuracy= 0.000\n",
      "Step 2460, Minibatch Loss= 213.8124, Training Accuracy= 0.000\n",
      "Step 2461, Minibatch Loss= 206.5174, Training Accuracy= 0.000\n",
      "Step 2462, Minibatch Loss= 241.5676, Training Accuracy= 0.000\n",
      "Step 2463, Minibatch Loss= 253.4605, Training Accuracy= 0.000\n",
      "Step 2464, Minibatch Loss= 321.3729, Training Accuracy= 0.000\n",
      "Step 2465, Minibatch Loss= 298.6574, Training Accuracy= 0.000\n",
      "Step 2466, Minibatch Loss= 283.3083, Training Accuracy= 0.000\n",
      "Step 2467, Minibatch Loss= 180.8720, Training Accuracy= 0.000\n",
      "Step 2468, Minibatch Loss= 169.8609, Training Accuracy= 0.000\n",
      "Step 2469, Minibatch Loss= 251.6296, Training Accuracy= 0.000\n",
      "Step 2470, Minibatch Loss= 322.7768, Training Accuracy= 0.000\n",
      "Step 2471, Minibatch Loss= 218.0492, Training Accuracy= 0.000\n",
      "Step 2472, Minibatch Loss= 162.2712, Training Accuracy= 0.000\n",
      "Step 2473, Minibatch Loss= 121.4983, Training Accuracy= 0.000\n",
      "Step 2474, Minibatch Loss= 183.7989, Training Accuracy= 0.000\n",
      "Step 2475, Minibatch Loss= 138.5431, Training Accuracy= 0.000\n",
      "Step 2476, Minibatch Loss= 142.4676, Training Accuracy= 0.000\n",
      "Step 2477, Minibatch Loss= 111.4254, Training Accuracy= 0.000\n",
      "Step 2478, Minibatch Loss= 149.3127, Training Accuracy= 0.000\n",
      "Step 2479, Minibatch Loss= 128.0192, Training Accuracy= 0.000\n",
      "Step 2480, Minibatch Loss= 132.1018, Training Accuracy= 0.000\n",
      "Step 2481, Minibatch Loss= 162.5211, Training Accuracy= 0.000\n",
      "Step 2482, Minibatch Loss= 156.7337, Training Accuracy= 0.000\n",
      "Step 2483, Minibatch Loss= 141.3200, Training Accuracy= 0.000\n",
      "Step 2484, Minibatch Loss= 139.2253, Training Accuracy= 0.000\n",
      "Step 2485, Minibatch Loss= 104.8587, Training Accuracy= 0.000\n",
      "Step 2486, Minibatch Loss= 133.8092, Training Accuracy= 0.000\n",
      "Step 2487, Minibatch Loss= 111.5665, Training Accuracy= 0.000\n",
      "Step 2488, Minibatch Loss= 123.3822, Training Accuracy= 0.000\n",
      "Step 2489, Minibatch Loss= 161.6792, Training Accuracy= 0.000\n",
      "Step 2490, Minibatch Loss= 134.4094, Training Accuracy= 0.000\n",
      "Step 2491, Minibatch Loss= 96.5050, Training Accuracy= 0.000\n",
      "Step 2492, Minibatch Loss= 144.7420, Training Accuracy= 0.000\n",
      "Step 2493, Minibatch Loss= 186.9211, Training Accuracy= 0.000\n",
      "Step 2494, Minibatch Loss= 209.0156, Training Accuracy= 0.000\n",
      "Step 2495, Minibatch Loss= 120.4185, Training Accuracy= 0.000\n",
      "Step 2496, Minibatch Loss= 156.9777, Training Accuracy= 0.000\n",
      "Step 2497, Minibatch Loss= 180.0057, Training Accuracy= 0.000\n",
      "Step 2498, Minibatch Loss= 117.4675, Training Accuracy= 0.000\n",
      "Step 2499, Minibatch Loss= 77.5335, Training Accuracy= 0.000\n",
      "Step 2500, Minibatch Loss= 93.7560, Training Accuracy= 0.000\n",
      "Step 2501, Minibatch Loss= 88.4988, Training Accuracy= 0.000\n",
      "Step 2502, Minibatch Loss= 106.6731, Training Accuracy= 0.000\n",
      "Step 2503, Minibatch Loss= 94.7679, Training Accuracy= 0.000\n",
      "Step 2504, Minibatch Loss= 77.1083, Training Accuracy= 0.000\n",
      "Step 2505, Minibatch Loss= 70.6945, Training Accuracy= 0.000\n",
      "Step 2506, Minibatch Loss= 94.0634, Training Accuracy= 0.000\n",
      "Step 2507, Minibatch Loss= 88.6110, Training Accuracy= 0.000\n",
      "Step 2508, Minibatch Loss= 101.3371, Training Accuracy= 0.000\n",
      "Step 2509, Minibatch Loss= 77.9847, Training Accuracy= 0.000\n",
      "Step 2510, Minibatch Loss= 63.8040, Training Accuracy= 0.000\n",
      "Step 2511, Minibatch Loss= 73.3938, Training Accuracy= 0.000\n",
      "Step 2512, Minibatch Loss= 67.7189, Training Accuracy= 0.000\n",
      "Step 2513, Minibatch Loss= 39.1798, Training Accuracy= 0.000\n",
      "Step 2514, Minibatch Loss= 38.6987, Training Accuracy= 0.000\n",
      "Step 2515, Minibatch Loss= 36.3268, Training Accuracy= 0.000\n",
      "Step 2516, Minibatch Loss= 35.0383, Training Accuracy= 0.000\n",
      "Step 2517, Minibatch Loss= 38.0835, Training Accuracy= 0.000\n",
      "Step 2518, Minibatch Loss= 34.6644, Training Accuracy= 0.000\n",
      "Step 2519, Minibatch Loss= 30.8681, Training Accuracy= 0.000\n",
      "Step 2520, Minibatch Loss= 22.8478, Training Accuracy= 0.000\n",
      "Step 2521, Minibatch Loss= 19.7848, Training Accuracy= 0.000\n",
      "Step 2522, Minibatch Loss= 22.0814, Training Accuracy= 0.000\n",
      "Step 2523, Minibatch Loss= 25.3067, Training Accuracy= 0.000\n",
      "Step 2524, Minibatch Loss= 24.1819, Training Accuracy= 0.000\n",
      "Step 2525, Minibatch Loss= 17.8570, Training Accuracy= 0.000\n",
      "Step 2526, Minibatch Loss= 14.5280, Training Accuracy= 0.000\n",
      "Step 2527, Minibatch Loss= 18.6091, Training Accuracy= 0.000\n",
      "Step 2528, Minibatch Loss= 19.9330, Training Accuracy= 0.000\n",
      "Step 2529, Minibatch Loss= 16.0338, Training Accuracy= 0.000\n",
      "Step 2530, Minibatch Loss= 14.1182, Training Accuracy= 0.000\n",
      "Step 2531, Minibatch Loss= 13.7623, Training Accuracy= 0.000\n",
      "Step 2532, Minibatch Loss= 15.4164, Training Accuracy= 0.000\n",
      "Step 2533, Minibatch Loss= 15.2590, Training Accuracy= 0.000\n",
      "Step 2534, Minibatch Loss= 12.2126, Training Accuracy= 0.000\n",
      "Step 2535, Minibatch Loss= 12.7394, Training Accuracy= 0.000\n",
      "Step 2536, Minibatch Loss= 14.0235, Training Accuracy= 0.000\n",
      "Step 2537, Minibatch Loss= 13.2447, Training Accuracy= 0.000\n",
      "Step 2538, Minibatch Loss= 8.8679, Training Accuracy= 0.000\n",
      "Step 2539, Minibatch Loss= 11.4036, Training Accuracy= 0.000\n",
      "Step 2540, Minibatch Loss= 11.0762, Training Accuracy= 0.000\n",
      "Step 2541, Minibatch Loss= 9.8286, Training Accuracy= 0.000\n",
      "Step 2542, Minibatch Loss= 10.1871, Training Accuracy= 0.000\n",
      "Step 2543, Minibatch Loss= 12.5461, Training Accuracy= 0.000\n",
      "Step 2544, Minibatch Loss= 12.0861, Training Accuracy= 0.000\n",
      "Step 2545, Minibatch Loss= 11.7877, Training Accuracy= 0.000\n",
      "Step 2546, Minibatch Loss= 7.8251, Training Accuracy= 0.000\n",
      "Step 2547, Minibatch Loss= 9.7314, Training Accuracy= 0.000\n",
      "Step 2548, Minibatch Loss= 11.8277, Training Accuracy= 0.000\n",
      "Step 2549, Minibatch Loss= 11.4150, Training Accuracy= 0.000\n",
      "Step 2550, Minibatch Loss= 12.7737, Training Accuracy= 0.000\n",
      "Step 2551, Minibatch Loss= 13.2259, Training Accuracy= 0.000\n",
      "Step 2552, Minibatch Loss= 13.0480, Training Accuracy= 0.000\n",
      "Step 2553, Minibatch Loss= 10.9266, Training Accuracy= 0.000\n",
      "Step 2554, Minibatch Loss= 10.0549, Training Accuracy= 0.000\n",
      "Step 2555, Minibatch Loss= 11.6746, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2556, Minibatch Loss= 13.9793, Training Accuracy= 0.000\n",
      "Step 2557, Minibatch Loss= 20.2420, Training Accuracy= 0.000\n",
      "Step 2558, Minibatch Loss= 25.3344, Training Accuracy= 0.000\n",
      "Step 2559, Minibatch Loss= 28.1271, Training Accuracy= 0.000\n",
      "Step 2560, Minibatch Loss= 31.1927, Training Accuracy= 0.000\n",
      "Step 2561, Minibatch Loss= 38.5976, Training Accuracy= 0.000\n",
      "Step 2562, Minibatch Loss= 58.3671, Training Accuracy= 0.000\n",
      "Step 2563, Minibatch Loss= 81.9015, Training Accuracy= 0.000\n",
      "Step 2564, Minibatch Loss= 111.0300, Training Accuracy= 0.000\n",
      "Step 2565, Minibatch Loss= 109.7868, Training Accuracy= 0.000\n",
      "Step 2566, Minibatch Loss= 65.3842, Training Accuracy= 0.000\n",
      "Step 2567, Minibatch Loss= 27.2977, Training Accuracy= 0.000\n",
      "Step 2568, Minibatch Loss= 22.2375, Training Accuracy= 0.000\n",
      "Step 2569, Minibatch Loss= 33.9197, Training Accuracy= 0.000\n",
      "Step 2570, Minibatch Loss= 31.8480, Training Accuracy= 0.000\n",
      "Step 2571, Minibatch Loss= 13.8211, Training Accuracy= 0.000\n",
      "Step 2572, Minibatch Loss= 30.1109, Training Accuracy= 0.000\n",
      "Step 2573, Minibatch Loss= 35.6384, Training Accuracy= 0.000\n",
      "Step 2574, Minibatch Loss= 17.3714, Training Accuracy= 0.000\n",
      "Step 2575, Minibatch Loss= 16.8413, Training Accuracy= 0.000\n",
      "Step 2576, Minibatch Loss= 19.1960, Training Accuracy= 0.000\n",
      "Step 2577, Minibatch Loss= 15.5818, Training Accuracy= 0.000\n",
      "Step 2578, Minibatch Loss= 20.6530, Training Accuracy= 0.000\n",
      "Step 2579, Minibatch Loss= 15.3136, Training Accuracy= 0.000\n",
      "Step 2580, Minibatch Loss= 8.7857, Training Accuracy= 0.000\n",
      "Step 2581, Minibatch Loss= 14.3415, Training Accuracy= 0.000\n",
      "Step 2582, Minibatch Loss= 15.0988, Training Accuracy= 0.000\n",
      "Step 2583, Minibatch Loss= 13.6002, Training Accuracy= 0.000\n",
      "Step 2584, Minibatch Loss= 11.2443, Training Accuracy= 0.000\n",
      "Step 2585, Minibatch Loss= 10.0315, Training Accuracy= 0.000\n",
      "Step 2586, Minibatch Loss= 10.9197, Training Accuracy= 0.000\n",
      "Step 2587, Minibatch Loss= 12.0907, Training Accuracy= 0.000\n",
      "Step 2588, Minibatch Loss= 8.9262, Training Accuracy= 0.000\n",
      "Step 2589, Minibatch Loss= 10.6548, Training Accuracy= 0.000\n",
      "Step 2590, Minibatch Loss= 10.8295, Training Accuracy= 0.000\n",
      "Step 2591, Minibatch Loss= 11.6577, Training Accuracy= 0.000\n",
      "Step 2592, Minibatch Loss= 9.8163, Training Accuracy= 0.000\n",
      "Step 2593, Minibatch Loss= 8.5710, Training Accuracy= 0.000\n",
      "Step 2594, Minibatch Loss= 8.9172, Training Accuracy= 0.000\n",
      "Step 2595, Minibatch Loss= 8.8403, Training Accuracy= 0.000\n",
      "Step 2596, Minibatch Loss= 7.1721, Training Accuracy= 0.000\n",
      "Step 2597, Minibatch Loss= 8.6118, Training Accuracy= 0.000\n",
      "Step 2598, Minibatch Loss= 10.3878, Training Accuracy= 0.000\n",
      "Step 2599, Minibatch Loss= 10.7048, Training Accuracy= 0.000\n",
      "Step 2600, Minibatch Loss= 7.8167, Training Accuracy= 0.000\n",
      "Step 2601, Minibatch Loss= 7.4899, Training Accuracy= 0.000\n",
      "Step 2602, Minibatch Loss= 7.8495, Training Accuracy= 0.000\n",
      "Step 2603, Minibatch Loss= 7.5966, Training Accuracy= 0.000\n",
      "Step 2604, Minibatch Loss= 7.2687, Training Accuracy= 0.000\n",
      "Step 2605, Minibatch Loss= 7.5115, Training Accuracy= 0.000\n",
      "Step 2606, Minibatch Loss= 7.7551, Training Accuracy= 0.000\n",
      "Step 2607, Minibatch Loss= 9.7583, Training Accuracy= 0.000\n",
      "Step 2608, Minibatch Loss= 9.2451, Training Accuracy= 0.000\n",
      "Step 2609, Minibatch Loss= 8.6085, Training Accuracy= 0.000\n",
      "Step 2610, Minibatch Loss= 6.8909, Training Accuracy= 0.000\n",
      "Step 2611, Minibatch Loss= 6.4753, Training Accuracy= 0.000\n",
      "Step 2612, Minibatch Loss= 8.4930, Training Accuracy= 0.000\n",
      "Step 2613, Minibatch Loss= 8.5712, Training Accuracy= 0.000\n",
      "Step 2614, Minibatch Loss= 9.9384, Training Accuracy= 0.000\n",
      "Step 2615, Minibatch Loss= 10.2196, Training Accuracy= 0.000\n",
      "Step 2616, Minibatch Loss= 10.6041, Training Accuracy= 0.000\n",
      "Step 2617, Minibatch Loss= 8.7377, Training Accuracy= 0.000\n",
      "Step 2618, Minibatch Loss= 8.3675, Training Accuracy= 0.000\n",
      "Step 2619, Minibatch Loss= 6.9623, Training Accuracy= 0.000\n",
      "Step 2620, Minibatch Loss= 7.8842, Training Accuracy= 0.000\n",
      "Step 2621, Minibatch Loss= 8.0369, Training Accuracy= 0.000\n",
      "Step 2622, Minibatch Loss= 7.3938, Training Accuracy= 0.000\n",
      "Step 2623, Minibatch Loss= 7.8585, Training Accuracy= 0.000\n",
      "Step 2624, Minibatch Loss= 7.2007, Training Accuracy= 0.000\n",
      "Step 2625, Minibatch Loss= 7.0177, Training Accuracy= 0.000\n",
      "Step 2626, Minibatch Loss= 7.3108, Training Accuracy= 0.000\n",
      "Step 2627, Minibatch Loss= 6.1463, Training Accuracy= 0.000\n",
      "Step 2628, Minibatch Loss= 7.4021, Training Accuracy= 0.000\n",
      "Step 2629, Minibatch Loss= 8.6961, Training Accuracy= 0.000\n",
      "Step 2630, Minibatch Loss= 9.7948, Training Accuracy= 0.000\n",
      "Step 2631, Minibatch Loss= 8.3726, Training Accuracy= 0.000\n",
      "Step 2632, Minibatch Loss= 8.3131, Training Accuracy= 0.000\n",
      "Step 2633, Minibatch Loss= 7.5026, Training Accuracy= 0.000\n",
      "Step 2634, Minibatch Loss= 7.1895, Training Accuracy= 0.000\n",
      "Step 2635, Minibatch Loss= 6.8486, Training Accuracy= 0.000\n",
      "Step 2636, Minibatch Loss= 6.4481, Training Accuracy= 0.000\n",
      "Step 2637, Minibatch Loss= 7.1570, Training Accuracy= 0.000\n",
      "Step 2638, Minibatch Loss= 6.3319, Training Accuracy= 0.000\n",
      "Step 2639, Minibatch Loss= 5.9223, Training Accuracy= 0.000\n",
      "Step 2640, Minibatch Loss= 5.8743, Training Accuracy= 0.000\n",
      "Step 2641, Minibatch Loss= 7.0326, Training Accuracy= 0.000\n",
      "Step 2642, Minibatch Loss= 7.1299, Training Accuracy= 0.000\n",
      "Step 2643, Minibatch Loss= 5.6066, Training Accuracy= 0.000\n",
      "Step 2644, Minibatch Loss= 5.7236, Training Accuracy= 0.000\n",
      "Step 2645, Minibatch Loss= 6.5154, Training Accuracy= 0.000\n",
      "Step 2646, Minibatch Loss= 6.5099, Training Accuracy= 0.000\n",
      "Step 2647, Minibatch Loss= 6.2295, Training Accuracy= 0.000\n",
      "Step 2648, Minibatch Loss= 6.3447, Training Accuracy= 0.000\n",
      "Step 2649, Minibatch Loss= 6.8650, Training Accuracy= 0.000\n",
      "Step 2650, Minibatch Loss= 6.6506, Training Accuracy= 0.000\n",
      "Step 2651, Minibatch Loss= 7.3406, Training Accuracy= 0.000\n",
      "Step 2652, Minibatch Loss= 6.1675, Training Accuracy= 0.000\n",
      "Step 2653, Minibatch Loss= 6.0159, Training Accuracy= 0.000\n",
      "Step 2654, Minibatch Loss= 6.3645, Training Accuracy= 0.000\n",
      "Step 2655, Minibatch Loss= 6.4806, Training Accuracy= 0.000\n",
      "Step 2656, Minibatch Loss= 6.5374, Training Accuracy= 0.000\n",
      "Step 2657, Minibatch Loss= 7.0389, Training Accuracy= 0.000\n",
      "Step 2658, Minibatch Loss= 6.4709, Training Accuracy= 0.000\n",
      "Step 2659, Minibatch Loss= 5.7555, Training Accuracy= 0.000\n",
      "Step 2660, Minibatch Loss= 6.1962, Training Accuracy= 0.000\n",
      "Step 2661, Minibatch Loss= 6.6025, Training Accuracy= 0.000\n",
      "Step 2662, Minibatch Loss= 6.3288, Training Accuracy= 0.000\n",
      "Step 2663, Minibatch Loss= 5.9165, Training Accuracy= 0.000\n",
      "Step 2664, Minibatch Loss= 6.3081, Training Accuracy= 0.000\n",
      "Step 2665, Minibatch Loss= 5.8471, Training Accuracy= 0.000\n",
      "Step 2666, Minibatch Loss= 6.7306, Training Accuracy= 0.000\n",
      "Step 2667, Minibatch Loss= 8.4688, Training Accuracy= 0.000\n",
      "Step 2668, Minibatch Loss= 9.2250, Training Accuracy= 0.000\n",
      "Step 2669, Minibatch Loss= 12.9485, Training Accuracy= 0.000\n",
      "Step 2670, Minibatch Loss= 10.3295, Training Accuracy= 0.000\n",
      "Step 2671, Minibatch Loss= 8.0040, Training Accuracy= 0.000\n",
      "Step 2672, Minibatch Loss= 8.0448, Training Accuracy= 0.000\n",
      "Step 2673, Minibatch Loss= 7.8023, Training Accuracy= 0.000\n",
      "Step 2674, Minibatch Loss= 6.8564, Training Accuracy= 0.000\n",
      "Step 2675, Minibatch Loss= 9.5926, Training Accuracy= 0.000\n",
      "Step 2676, Minibatch Loss= 9.8787, Training Accuracy= 0.000\n",
      "Step 2677, Minibatch Loss= 11.5704, Training Accuracy= 0.000\n",
      "Step 2678, Minibatch Loss= 11.4394, Training Accuracy= 0.000\n",
      "Step 2679, Minibatch Loss= 14.3284, Training Accuracy= 0.000\n",
      "Step 2680, Minibatch Loss= 12.6790, Training Accuracy= 0.000\n",
      "Step 2681, Minibatch Loss= 9.3355, Training Accuracy= 0.000\n",
      "Step 2682, Minibatch Loss= 9.9006, Training Accuracy= 0.000\n",
      "Step 2683, Minibatch Loss= 7.6553, Training Accuracy= 0.000\n",
      "Step 2684, Minibatch Loss= 7.9353, Training Accuracy= 0.000\n",
      "Step 2685, Minibatch Loss= 7.9115, Training Accuracy= 0.000\n",
      "Step 2686, Minibatch Loss= 8.6045, Training Accuracy= 0.000\n",
      "Step 2687, Minibatch Loss= 9.3854, Training Accuracy= 0.000\n",
      "Step 2688, Minibatch Loss= 9.3116, Training Accuracy= 0.000\n",
      "Step 2689, Minibatch Loss= 13.2655, Training Accuracy= 0.000\n",
      "Step 2690, Minibatch Loss= 15.2698, Training Accuracy= 0.000\n",
      "Step 2691, Minibatch Loss= 15.8563, Training Accuracy= 0.000\n",
      "Step 2692, Minibatch Loss= 14.1482, Training Accuracy= 0.000\n",
      "Step 2693, Minibatch Loss= 12.0721, Training Accuracy= 0.000\n",
      "Step 2694, Minibatch Loss= 10.1431, Training Accuracy= 0.000\n",
      "Step 2695, Minibatch Loss= 9.2276, Training Accuracy= 0.000\n",
      "Step 2696, Minibatch Loss= 10.1961, Training Accuracy= 0.000\n",
      "Step 2697, Minibatch Loss= 10.5893, Training Accuracy= 0.000\n",
      "Step 2698, Minibatch Loss= 8.6767, Training Accuracy= 0.000\n",
      "Step 2699, Minibatch Loss= 7.6785, Training Accuracy= 0.000\n",
      "Step 2700, Minibatch Loss= 7.1462, Training Accuracy= 0.000\n",
      "Step 2701, Minibatch Loss= 9.5812, Training Accuracy= 0.000\n",
      "Step 2702, Minibatch Loss= 11.3178, Training Accuracy= 0.000\n",
      "Step 2703, Minibatch Loss= 9.5663, Training Accuracy= 0.000\n",
      "Step 2704, Minibatch Loss= 7.5708, Training Accuracy= 0.000\n",
      "Step 2705, Minibatch Loss= 7.4327, Training Accuracy= 0.000\n",
      "Step 2706, Minibatch Loss= 8.9057, Training Accuracy= 0.000\n",
      "Step 2707, Minibatch Loss= 10.5197, Training Accuracy= 0.000\n",
      "Step 2708, Minibatch Loss= 11.0522, Training Accuracy= 0.000\n",
      "Step 2709, Minibatch Loss= 9.9606, Training Accuracy= 0.000\n",
      "Step 2710, Minibatch Loss= 7.6924, Training Accuracy= 0.000\n",
      "Step 2711, Minibatch Loss= 7.3009, Training Accuracy= 0.000\n",
      "Step 2712, Minibatch Loss= 10.5662, Training Accuracy= 0.000\n",
      "Step 2713, Minibatch Loss= 10.9240, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2714, Minibatch Loss= 12.3793, Training Accuracy= 0.000\n",
      "Step 2715, Minibatch Loss= 11.6502, Training Accuracy= 0.000\n",
      "Step 2716, Minibatch Loss= 9.4240, Training Accuracy= 0.000\n",
      "Step 2717, Minibatch Loss= 8.4416, Training Accuracy= 0.000\n",
      "Step 2718, Minibatch Loss= 7.9710, Training Accuracy= 0.000\n",
      "Step 2719, Minibatch Loss= 7.9829, Training Accuracy= 0.000\n",
      "Step 2720, Minibatch Loss= 7.6617, Training Accuracy= 0.000\n",
      "Step 2721, Minibatch Loss= 9.1950, Training Accuracy= 0.000\n",
      "Step 2722, Minibatch Loss= 10.7388, Training Accuracy= 0.000\n",
      "Step 2723, Minibatch Loss= 8.6266, Training Accuracy= 0.000\n",
      "Step 2724, Minibatch Loss= 8.7008, Training Accuracy= 0.000\n",
      "Step 2725, Minibatch Loss= 7.5815, Training Accuracy= 0.000\n",
      "Step 2726, Minibatch Loss= 8.5945, Training Accuracy= 0.000\n",
      "Step 2727, Minibatch Loss= 7.5578, Training Accuracy= 0.000\n",
      "Step 2728, Minibatch Loss= 7.6302, Training Accuracy= 0.000\n",
      "Step 2729, Minibatch Loss= 8.5042, Training Accuracy= 0.000\n",
      "Step 2730, Minibatch Loss= 9.3972, Training Accuracy= 0.000\n",
      "Step 2731, Minibatch Loss= 7.8095, Training Accuracy= 0.000\n",
      "Step 2732, Minibatch Loss= 8.6616, Training Accuracy= 0.000\n",
      "Step 2733, Minibatch Loss= 7.4325, Training Accuracy= 0.000\n",
      "Step 2734, Minibatch Loss= 10.3413, Training Accuracy= 0.000\n",
      "Step 2735, Minibatch Loss= 10.1317, Training Accuracy= 0.000\n",
      "Step 2736, Minibatch Loss= 10.5696, Training Accuracy= 0.000\n",
      "Step 2737, Minibatch Loss= 10.8048, Training Accuracy= 0.000\n",
      "Step 2738, Minibatch Loss= 8.4620, Training Accuracy= 0.000\n",
      "Step 2739, Minibatch Loss= 7.8364, Training Accuracy= 0.000\n",
      "Step 2740, Minibatch Loss= 6.3493, Training Accuracy= 0.000\n",
      "Step 2741, Minibatch Loss= 6.3657, Training Accuracy= 0.000\n",
      "Step 2742, Minibatch Loss= 6.7148, Training Accuracy= 0.000\n",
      "Step 2743, Minibatch Loss= 6.2009, Training Accuracy= 0.000\n",
      "Step 2744, Minibatch Loss= 7.6354, Training Accuracy= 0.000\n",
      "Step 2745, Minibatch Loss= 8.6616, Training Accuracy= 0.000\n",
      "Step 2746, Minibatch Loss= 10.6445, Training Accuracy= 0.000\n",
      "Step 2747, Minibatch Loss= 9.7790, Training Accuracy= 0.000\n",
      "Step 2748, Minibatch Loss= 10.1591, Training Accuracy= 0.000\n",
      "Step 2749, Minibatch Loss= 9.7426, Training Accuracy= 0.000\n",
      "Step 2750, Minibatch Loss= 10.0977, Training Accuracy= 0.000\n",
      "Step 2751, Minibatch Loss= 8.7028, Training Accuracy= 0.000\n",
      "Step 2752, Minibatch Loss= 7.2152, Training Accuracy= 0.000\n",
      "Step 2753, Minibatch Loss= 7.0035, Training Accuracy= 0.000\n",
      "Step 2754, Minibatch Loss= 6.2925, Training Accuracy= 0.000\n",
      "Step 2755, Minibatch Loss= 6.5732, Training Accuracy= 0.000\n",
      "Step 2756, Minibatch Loss= 5.6587, Training Accuracy= 0.000\n",
      "Step 2757, Minibatch Loss= 6.7641, Training Accuracy= 0.000\n",
      "Step 2758, Minibatch Loss= 7.1199, Training Accuracy= 0.000\n",
      "Step 2759, Minibatch Loss= 7.7663, Training Accuracy= 0.000\n",
      "Step 2760, Minibatch Loss= 6.4660, Training Accuracy= 0.000\n",
      "Step 2761, Minibatch Loss= 7.2920, Training Accuracy= 0.000\n",
      "Step 2762, Minibatch Loss= 7.2791, Training Accuracy= 0.000\n",
      "Step 2763, Minibatch Loss= 8.9110, Training Accuracy= 0.000\n",
      "Step 2764, Minibatch Loss= 7.4173, Training Accuracy= 0.000\n",
      "Step 2765, Minibatch Loss= 7.3990, Training Accuracy= 0.000\n",
      "Step 2766, Minibatch Loss= 7.4568, Training Accuracy= 0.000\n",
      "Step 2767, Minibatch Loss= 7.6894, Training Accuracy= 0.000\n",
      "Step 2768, Minibatch Loss= 8.0562, Training Accuracy= 0.000\n",
      "Step 2769, Minibatch Loss= 7.9511, Training Accuracy= 0.000\n",
      "Step 2770, Minibatch Loss= 9.1767, Training Accuracy= 0.000\n",
      "Step 2771, Minibatch Loss= 10.8127, Training Accuracy= 0.000\n",
      "Step 2772, Minibatch Loss= 8.8340, Training Accuracy= 0.000\n",
      "Step 2773, Minibatch Loss= 8.8670, Training Accuracy= 0.000\n",
      "Step 2774, Minibatch Loss= 6.8063, Training Accuracy= 0.000\n",
      "Step 2775, Minibatch Loss= 6.5492, Training Accuracy= 0.000\n",
      "Step 2776, Minibatch Loss= 6.5676, Training Accuracy= 0.000\n",
      "Step 2777, Minibatch Loss= 6.9788, Training Accuracy= 0.000\n",
      "Step 2778, Minibatch Loss= 8.1238, Training Accuracy= 0.000\n",
      "Step 2779, Minibatch Loss= 8.2368, Training Accuracy= 0.000\n",
      "Step 2780, Minibatch Loss= 8.1621, Training Accuracy= 0.000\n",
      "Step 2781, Minibatch Loss= 8.3044, Training Accuracy= 0.000\n",
      "Step 2782, Minibatch Loss= 7.5183, Training Accuracy= 0.000\n",
      "Step 2783, Minibatch Loss= 5.8096, Training Accuracy= 0.000\n",
      "Step 2784, Minibatch Loss= 7.0249, Training Accuracy= 0.000\n",
      "Step 2785, Minibatch Loss= 9.3870, Training Accuracy= 0.000\n",
      "Step 2786, Minibatch Loss= 7.1777, Training Accuracy= 0.000\n",
      "Step 2787, Minibatch Loss= 6.8537, Training Accuracy= 0.000\n",
      "Step 2788, Minibatch Loss= 7.4443, Training Accuracy= 0.000\n",
      "Step 2789, Minibatch Loss= 6.5742, Training Accuracy= 0.000\n",
      "Step 2790, Minibatch Loss= 7.3412, Training Accuracy= 0.000\n",
      "Step 2791, Minibatch Loss= 7.2178, Training Accuracy= 0.000\n",
      "Step 2792, Minibatch Loss= 7.9299, Training Accuracy= 0.000\n",
      "Step 2793, Minibatch Loss= 10.1409, Training Accuracy= 0.000\n",
      "Step 2794, Minibatch Loss= 11.6958, Training Accuracy= 0.000\n",
      "Step 2795, Minibatch Loss= 12.1461, Training Accuracy= 0.000\n",
      "Step 2796, Minibatch Loss= 13.6194, Training Accuracy= 0.000\n",
      "Step 2797, Minibatch Loss= 13.7929, Training Accuracy= 0.000\n",
      "Step 2798, Minibatch Loss= 13.5921, Training Accuracy= 0.000\n",
      "Step 2799, Minibatch Loss= 12.4113, Training Accuracy= 0.000\n",
      "Step 2800, Minibatch Loss= 12.9256, Training Accuracy= 0.000\n",
      "Step 2801, Minibatch Loss= 11.7466, Training Accuracy= 0.000\n",
      "Step 2802, Minibatch Loss= 12.4240, Training Accuracy= 0.000\n",
      "Step 2803, Minibatch Loss= 8.9951, Training Accuracy= 0.000\n",
      "Step 2804, Minibatch Loss= 7.0255, Training Accuracy= 0.000\n",
      "Step 2805, Minibatch Loss= 7.3271, Training Accuracy= 0.000\n",
      "Step 2806, Minibatch Loss= 7.4297, Training Accuracy= 0.000\n",
      "Step 2807, Minibatch Loss= 8.2485, Training Accuracy= 0.000\n",
      "Step 2808, Minibatch Loss= 9.0762, Training Accuracy= 0.000\n",
      "Step 2809, Minibatch Loss= 8.1516, Training Accuracy= 0.000\n",
      "Step 2810, Minibatch Loss= 8.0545, Training Accuracy= 0.000\n",
      "Step 2811, Minibatch Loss= 8.6643, Training Accuracy= 0.000\n",
      "Step 2812, Minibatch Loss= 8.4154, Training Accuracy= 0.000\n",
      "Step 2813, Minibatch Loss= 9.6430, Training Accuracy= 0.000\n",
      "Step 2814, Minibatch Loss= 6.6191, Training Accuracy= 0.000\n",
      "Step 2815, Minibatch Loss= 7.2949, Training Accuracy= 0.000\n",
      "Step 2816, Minibatch Loss= 7.6518, Training Accuracy= 0.000\n",
      "Step 2817, Minibatch Loss= 6.9392, Training Accuracy= 0.000\n",
      "Step 2818, Minibatch Loss= 6.9769, Training Accuracy= 0.000\n",
      "Step 2819, Minibatch Loss= 6.6885, Training Accuracy= 0.000\n",
      "Step 2820, Minibatch Loss= 7.3423, Training Accuracy= 0.000\n",
      "Step 2821, Minibatch Loss= 8.0330, Training Accuracy= 0.000\n",
      "Step 2822, Minibatch Loss= 9.8537, Training Accuracy= 0.000\n",
      "Step 2823, Minibatch Loss= 7.2203, Training Accuracy= 0.000\n",
      "Step 2824, Minibatch Loss= 6.0208, Training Accuracy= 0.000\n",
      "Step 2825, Minibatch Loss= 7.2277, Training Accuracy= 0.000\n",
      "Step 2826, Minibatch Loss= 6.4514, Training Accuracy= 0.000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "now = datetime.now()\n",
    "log_dir = '%straining/output/%s' % (root, now.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "print(\"Start learning\")\n",
    "for step in range(1, num_steps + 1):\n",
    "    batch_x, batch_y = next_batch(batch_size, train_vector, train_label)\n",
    "#     print(batch_y)\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "    if step % display_step == 0 or step == 1:\n",
    "        # Calculate batch loss and accuracy\n",
    "        preds, summary, loss, acc = sess.run([logits, merged, loss_op, accuracy],\n",
    "                                                feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        writer.add_summary(summary, step)\n",
    "\n",
    "        print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.3f}\".format(acc))\n",
    "#         print(\"Predictions %s VS %s\" % (preds[0][0], batch_y[0][0]))\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "print(\"Testing Accuracy:\",\n",
    "      sess.run(accuracy, feed_dict={X: test_vector, Y: test_label}))\n",
    "writer.flush()\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdi = get_embs('http://data.doremus.org/artist/b82c0771-5280-39af-ad2e-8ace2f4ebda3')\n",
    "rossini = get_embs('http://data.doremus.org/artist/c5d5735c-1095-3ed4-a20f-1208ab9567f9')\n",
    "rossini_pp = get_embs('http://data.doremus.org/artist/32c2b0ff-35f1-3e65-b0ca-34aaf35f3d50')\n",
    "beethoven = get_embs('http://data.doremus.org/artist/6963af5e-b126-3d40-a84b-97e0b78f5452')\n",
    "mozart = get_embs('http://data.doremus.org/artist/4802a043-23bb-3b8d-a443-4a3bd22ccc63')\n",
    "ravel = get_embs('http://data.doremus.org/artist/1b1205f9-b99a-3bb8-ba77-256689af2e00')\n",
    "gershwin = get_embs('http://data.doremus.org/artist/5b2ec204-a456-3aa2-8ac7-25305464add8')\n",
    "coltrane = get_embs('http://data.doremus.org/artist/5425efed-002f-3638-a7b0-ad379a2bf63d')\n",
    "\n",
    "preds = sess.run(logits, feed_dict={X: rossini.reshape(1,342), Y: test_label[0].reshape(1,342)})\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
