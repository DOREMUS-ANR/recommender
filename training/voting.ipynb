{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load data in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://data.doremus.org/artist/d33ebb23-7b8d-3...</td>\n",
       "      <td>http://data.doremus.org/artist/6329cd86-d47a-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://data.doremus.org/artist/01915146-b964-3...</td>\n",
       "      <td>http://data.doremus.org/artist/6329cd86-d47a-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://data.doremus.org/artist/01915146-b964-3...</td>\n",
       "      <td>http://data.doremus.org/artist/d33ebb23-7b8d-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://data.doremus.org/artist/72b3b303-5c15-3...</td>\n",
       "      <td>http://data.doremus.org/artist/6329cd86-d47a-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://data.doremus.org/artist/72b3b303-5c15-3...</td>\n",
       "      <td>http://data.doremus.org/artist/d33ebb23-7b8d-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                seed  \\\n",
       "0  http://data.doremus.org/artist/d33ebb23-7b8d-3...   \n",
       "1  http://data.doremus.org/artist/01915146-b964-3...   \n",
       "2  http://data.doremus.org/artist/01915146-b964-3...   \n",
       "3  http://data.doremus.org/artist/72b3b303-5c15-3...   \n",
       "4  http://data.doremus.org/artist/72b3b303-5c15-3...   \n",
       "\n",
       "                                              target score  \n",
       "0  http://data.doremus.org/artist/6329cd86-d47a-3...     1  \n",
       "1  http://data.doremus.org/artist/6329cd86-d47a-3...     1  \n",
       "2  http://data.doremus.org/artist/d33ebb23-7b8d-3...     1  \n",
       "3  http://data.doremus.org/artist/6329cd86-d47a-3...     1  \n",
       "4  http://data.doremus.org/artist/d33ebb23-7b8d-3...     1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"../\"\n",
    "training_data_folder = '%straining_data/web-radio/output/rec' % root\n",
    "embDir = '%sembeddings' % root\n",
    "what = 'artist'\n",
    "\n",
    "uri_file = '%s/%s.emb.u' % (embDir, what)\n",
    "vector_file = '%s/%s.emb.v' % (embDir, what)\n",
    "# header_file = '%s/%s.emb.h' % (embDir, what)\n",
    "training_file = '%s/%s.dat' % (training_data_folder, what)\n",
    "\n",
    "vectors = np.array([line.strip().split(' ') for line in codecs.open(vector_file, 'r', 'utf-8')])\n",
    "# heads = np.array([line.strip() for line in codecs.open(header_file, 'r', 'utf-8')])\n",
    "uris = np.array([line.strip() for line in codecs.open(uri_file, 'r', 'utf-8')])\n",
    "\n",
    "train_array = np.array([line.strip().split(' ') for line in codecs.open(training_file, 'r', 'utf-8')])\n",
    "pd.DataFrame(train_array, columns=['seed', 'target', 'score']).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing: I want to substitute the seed and target with their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs(x):\n",
    "    # uri to embedding\n",
    "    v = vectors[np.argwhere(uris == x)]\n",
    "    if v.size == 0:\n",
    "        result = -2. * np.ones(vectors[0].size)\n",
    "    else:\n",
    "        result = v[0][0]\n",
    "    return result.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = np.array([get_embs(xi) for xi in train_array[:, 0]])\n",
    "col2 = np.array([get_embs(xi) for xi in train_array[:, 1]])\n",
    "col1 = np.concatenate((col1, [12., 45., 73.] * np.ones((train_array.shape[0], 3))), axis=1)\n",
    "col2 = np.concatenate((col2, [12., 45., 73.] * np.ones((train_array.shape[0], 3))), axis=1)\n",
    "col3 = np.array(train_array[:, 2]).astype('float32')\n",
    "col3 = col3.reshape((col3.size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    \"\"\"\n",
    "    Return a total of `num` random samples and labels. \n",
    "    \"\"\"\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = data[idx]\n",
    "    labels_shuffle = labels[idx]\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 140)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_vector = np.concatenate((col1, col2, col3), axis=1)\n",
    "b_size = 4\n",
    "x_size = col1[0].shape[0]\n",
    "\n",
    "training_vector = []\n",
    "for i in range(0,10000):\n",
    "    l, b = next_batch(4, np.concatenate((col1, col2), axis=1), col3)\n",
    "    training_vector.append(np.concatenate([b[:,:x_size], b[:,x_size:], l], axis=1).flatten())\n",
    "    \n",
    "training_vector = np.array(training_vector)\n",
    "training_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pasquale/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(training_vector, train_size=0.7)\n",
    "\n",
    "train_vector = train[:, : -b_size]\n",
    "train_label = train[:, -b_size:]\n",
    "# train_label = train_label.reshape((len(train_label), b_size))\n",
    "\n",
    "test_vector = test[:, :-b_size]\n",
    "test_label = test[:, -b_size:]\n",
    "# test_label = test_label.reshape((len(test_label), b_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(7000, 136)\n",
      "(7000, 4)\n",
      "Test\n",
      "(3000, 136)\n",
      "(3000, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "print(train_vector.shape)\n",
    "print(train_label.shape)\n",
    "print('Test')\n",
    "print(test_vector.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 1000\n",
    "batch_size = 64\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256  # 1st layer number of neurons\n",
    "n_hidden_2 = 256  # 2nd layer number of neurons\n",
    "num_input = train_vector[0].size\n",
    "num_output = col1[0].size\n",
    "num_output_wrap = train_label[0].size\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input], name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [None, num_output_wrap], name=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    with tf.name_scope('hidden_1') as scope:\n",
    "        # Hidden fully connected layer with 256 neurons\n",
    "        w1 = tf.Variable(tf.random_normal([num_input, n_hidden_1]), name='w')\n",
    "        b1 = tf.Variable(tf.random_normal([n_hidden_1]), name='b')\n",
    "        layer_1 = tf.add(tf.matmul(x, w1), b1, name='o')\n",
    "    with tf.name_scope('hidden_2') as scope:\n",
    "        # Hidden fully connected layer with 256 neurons\n",
    "        w2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='w')\n",
    "        b2 = tf.Variable(tf.random_normal([n_hidden_2]), name='b')\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, w2), b2, name='o')\n",
    "    with tf.name_scope('out_layer') as scope:\n",
    "        # Output fully connected layer with a neuron for each class\n",
    "        wo = tf.Variable(tf.random_normal([n_hidden_2, num_output]), name='w')\n",
    "        bo = tf.Variable(tf.random_normal([num_output]), name='b')\n",
    "        out_layer = tf.add(tf.matmul(layer_2, wo), bo, name=\"o\")\n",
    "        with tf.name_scope('u_norm') as scope:\n",
    "            row_sum = tf.reduce_sum(out_layer, axis=1, keepdims=True)\n",
    "            return tf.divide(out_layer, row_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_l2(a, b, w):\n",
    "    with tf.name_scope('weighted_l2') as scope:\n",
    "        # https://stackoverflow.com/a/8861999/1218213\n",
    "        q = tf.subtract(a, b, name=\"q\")\n",
    "        # return np.sqrt((w * q * q).sum())\n",
    "        pow_q = tf.cast(tf.pow(q, 2), tf.float32, name=\"q-power\")\n",
    "\n",
    "        return tf.reduce_sum(tf.multiply(w, pow_q), axis=1, name=\"o\", keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_penalty(expected, taken, total):\n",
    "    with tf.name_scope('penalty') as scope:\n",
    "        penalty = tf.divide(tf.subtract(expected, taken), total)\n",
    "        return tf.cast(penalty, tf.float32)\n",
    "\n",
    "\n",
    "def neural_net_wrap(x, previous_out):\n",
    "    with tf.name_scope('nn_wrapper') as scope:\n",
    "        lt = previous_out.shape.as_list()[0]  # vertical size of the tensor\n",
    "        lh = previous_out[0].shape.as_list()[0]  # horizontal size of the tensor\n",
    "        \n",
    "        split_n = int(x[0].shape.as_list()[0]/(2*lh))\n",
    "        seed, target = tf.split(x, split_n, axis=1)\n",
    "        \n",
    "        \n",
    "        print(couples[0].shape)\n",
    "        bs = tf.equal(seed, -2.)\n",
    "        bt = tf.equal(target, -2.)\n",
    "\n",
    "        _ones = tf.ones_like(previous_out, tf.float32)\n",
    "        max_distance = weighted_l2(_ones, _ones * -1., previous_out)\n",
    "\n",
    "        bad_mask = tf.logical_or(bs, bt)\n",
    "        good_mask = tf.logical_not(bad_mask)\n",
    "\n",
    "        bs_count = tf.count_nonzero(tf.logical_not(bs), axis=1, keepdims=True)\n",
    "        good_count = tf.count_nonzero(good_mask, axis=1, keepdims=True)\n",
    "\n",
    "        _zeros = tf.zeros_like(previous_out, tf.float32)\n",
    "        _seed = tf.where(good_mask, seed, _zeros)\n",
    "        _target = tf.where(good_mask, target, _zeros)\n",
    "\n",
    "        # distance\n",
    "        d = weighted_l2(_seed, _target, previous_out)\n",
    "\n",
    "        # how much info I am not finding\n",
    "        penalty = compute_penalty(bs_count, good_count, lh)\n",
    "        multiplier = tf.subtract(1., penalty)\n",
    "        \n",
    "        # score\n",
    "        s = tf.divide(tf.subtract(max_distance, d), max_distance)\n",
    "        return tf.multiply(s, multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 34)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-e1d7a1fd853b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Construct model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-178-cd04159a8e2b>\u001b[0m in \u001b[0;36mneural_net_wrap\u001b[0;34m(x, previous_out)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcouples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "intermediate = neural_net(X)\n",
    "logits = neural_net_wrap(X, intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "# loss_op = MSE\n",
    "loss_op = tf.reduce_mean(tf.square(tf.subtract(logits, Y)))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.less(tf.subtract(logits, Y), 0.1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning\n",
      "Step 1, Minibatch Loss= 10790.4355, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 100, Minibatch Loss= 11132.3525, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 200, Minibatch Loss= 10656.1084, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 300, Minibatch Loss= 10265.3965, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 400, Minibatch Loss= 10410.1777, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 500, Minibatch Loss= 10549.5762, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 600, Minibatch Loss= 10571.0059, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 700, Minibatch Loss= 10854.9785, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 800, Minibatch Loss= 10396.2041, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 900, Minibatch Loss= 10441.6855, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Step 1000, Minibatch Loss= 10994.9844, Training Accuracy= 1.000\n",
      "My weights [0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (3000, 139) for Tensor 'X:0', which has shape '(?, 136)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-533d810c661d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     print(\"Testing Accuracy:\",\n\u001b[0;32m---> 26\u001b[0;31m           sess.run(accuracy, feed_dict={X: test_vector, Y: test_label}))\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pasquale/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pasquale/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1105\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (3000, 139) for Tensor 'X:0', which has shape '(?, 136)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    print(\"Start learning\")\n",
    "    for step in range(1, num_steps + 1):\n",
    "        batch_x, batch_y = next_batch(batch_size, train_vector, train_label)\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            preds, my_weights, loss, acc = sess.run([logits, intermediate, loss_op, accuracy],\n",
    "                                                    feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "            # print(\"Predictions %s VS %s\" % (preds[0], batch_y[0]))\n",
    "            np.set_printoptions(precision=2)\n",
    "            print(\"My weights %s\" % np.mean(my_weights, axis=0))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    print(\"Testing Accuracy:\",\n",
    "          sess.run(accuracy, feed_dict={X: test_vector, Y: test_label}))\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
